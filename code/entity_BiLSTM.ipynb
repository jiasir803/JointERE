{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "tag_to_ix = {UNKOWN_TAG: 0, PAD_TAG:1, \"B-Func\": 2, \"I-Func\": 3, \"O\": 4}\n",
    "\n",
    "tagset_size = len(tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM1 = 10\n",
    "HIDDEN_DIM2 = 8\n",
    "LABEL_EMBED_DIM = 3\n",
    "DENSE_OUT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sentence = ['這','次','F', 'G', '商', '品', '市','調','為','美','肌','之','誌','玻','尿','酸','肌','因','保','濕','生','物'\n",
    "              ,'纖','維', '面', '膜','3','枚','入','<PAD>','<PAD>','<PAD>','<PAD>','<PAD>','<PAD>','<PAD>','<PAD>',\n",
    "              '<PAD>','<PAD>','<PAD>','<PAD>','<PAD>','<PAD>', '<PAD>','<PAD>','<PAD>','<PAD>','<PAD>','<PAD>',\n",
    "              '<PAD>', '<PAD>', '<PAD>', '<PAD>','<PAD>', '<PAD>', '<PAD>','<PAD>', '<PAD>', '<PAD>', '<PAD>', \n",
    "              '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', \n",
    "              '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', \n",
    "              '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', \n",
    "              '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_list.append(word_set[0])\n",
    "        tag_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, tag_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "\n",
    "    for i, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, tags = get_word_and_label(content, init, i)\n",
    "            init = i+1\n",
    "            word_list.append(words)\n",
    "            tag_list.append(tags)\n",
    "            \n",
    "    return word_list, tag_list\n",
    "    \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, tag_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_tag = list(tag_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_tag\n",
    "\n",
    "def pad_seq(seq):\n",
    "    seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_tag):\n",
    "    input_padded = [pad_seq(s) for s in filter_word]\n",
    "    target_padded = [pad_seq(s) for s in filter_tag]\n",
    "    \n",
    "    return input_padded, target_padded\n",
    "\n",
    "#======================================\n",
    "def dataload(input_var, target_var):\n",
    "    torch_dataset = Data.TensorDataset(input_var, target_var)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=2,       \n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim):\n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.label_embed_dim = label_embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        \n",
    "        self.lstm = nn.LSTM(DENSE_OUT+label_embed_dim, hidden_dim2, batch_first=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.tagset_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        self.label_embed = nn.Linear(self.tagset_size, self.label_embed_dim)\n",
    "        \n",
    "#         self.hidden1 = self.init_hidden1()\n",
    "#         self.hidden2 = self.init_hidden2()\n",
    "#         self.to_label_embed = self.init_label_embed()\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, BATCH_SIZE, self.hidden_dim1 // 2)   \n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(1, BATCH_SIZE, self.hidden_dim2)        \n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.randn(BATCH_SIZE, MAX_LEN, self.label_embed_dim)\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        self.hidden1 = self.init_hidden1()\n",
    "        self.hidden2 = self.init_hidden2()\n",
    "        self.to_label_embed = self.init_label_embed()\n",
    "        \n",
    "        embeds = self.word_embeds(sentence)\n",
    "        bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        dense_out = self.dense(bilstm_out)\n",
    "#         combine_lstm = torch.cat((dense_out, to_label_embed), 2)\n",
    "        combine_lstm = torch.cat((dense_out, self.to_label_embed), 2)  \n",
    "        lstm_out, self.hidden2 = self.lstm(combine_lstm, self.hidden2)  \n",
    "        to_tags = self.hidden2tag(lstm_out)\n",
    "        output = self.softmax(to_tags)\n",
    "        self.to_label_embed = self.label_embed(output)\n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return output.view(BATCH_SIZE*MAX_LEN, self.tagset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_tag = dict_inverse(tag_to_ix)\n",
    "#===============================================\n",
    "content = readfile(train_data)\n",
    "word_list, tag_list = split_to_list(content)\n",
    "word_to_ix = word2index(word_list)\n",
    "reserved_index = filter_len(word_list)\n",
    "filter_word, filter_tag = filter_sentence(reserved_index, word_list, tag_list)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "#================================================\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)\n",
    "#================================================\n",
    "vocab_size = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataload(input_var, target_var)\n",
    "model = Entity_Typing(vocab_size, tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:02<01:55,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss 0.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:05<02:06,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:08<02:10,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:11<02:11,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss 0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:14<02:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:17<02:10,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [00:20<02:07,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:23<02:03,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:26<01:58,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:28<01:55,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:31<01:50,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:33<01:46,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [00:35<01:41,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:38<01:37,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:40<01:34,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:42<01:31,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:45<01:27,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [00:47<01:24,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:49<01:20,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [00:51<01:17,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [00:55<01:16,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | loss 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [00:58<01:13,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | loss 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [01:00<01:11,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | loss 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [01:03<01:08,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | loss 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [01:05<01:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | loss 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [01:08<01:03,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | loss 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | loss 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [01:13<00:58,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | loss 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [01:16<00:55,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | loss 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [01:18<00:52,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | loss 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [01:21<00:49,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | loss 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [01:23<00:47,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | loss 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [01:26<00:44,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | loss 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [01:28<00:41,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | loss 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [01:30<00:38,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | loss 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [01:32<00:36,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | loss 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [01:35<00:33,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | loss 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [01:37<00:30,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | loss 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [01:39<00:28,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | loss 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [01:41<00:25,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | loss 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [01:44<00:22,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | loss 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [01:45<00:20,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | loss 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | loss 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [01:49<00:14,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | loss 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [01:51<00:12,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | loss 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [01:52<00:09,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | loss 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [01:54<00:07,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | loss 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [01:56<00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | loss 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [01:58<00:02,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | loss 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [02:00<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | loss 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 10\n",
    "print_every = 10\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(50)):  \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x.cuda() if USE_CUDA else batch_x)\n",
    "        batch_y = batch_y.view(BATCH_SIZE*MAX_LEN)\n",
    "        loss = criterion(output, batch_y.cuda() if USE_CUDA else batch_y)\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % print_every == 1:\n",
    "            all_losses.append(loss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "    print(\"epoch: %d | loss %.4f\" % (epoch,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_losses[:100])\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one input\n",
    "def easy_pad(easy_sent, easy_tar):\n",
    "    easy_sent += [PAD_TAG for i in range(MAX_LEN-len(easy_sent))]\n",
    "    easy_tar += [PAD_TAG for i in range(MAX_LEN-len(easy_tar))]\n",
    "    \n",
    "    return easy_sent, easy_tar\n",
    "\n",
    "def easy_test(_input):\n",
    "    _input = torch.unsqueeze(_input, 0).expand(128,100)\n",
    "    return _input\n",
    "\n",
    "def easy_output(output):\n",
    "    output = output.view(128,100,5)[0].argmax(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = readfile(test_data)\n",
    "word_list_test, tag_list_test = split_to_list(test_content)\n",
    "\n",
    "#===================================\n",
    "easy_sent, easy_tar = easy_pad(word_list_test[3],tag_list_test[3])\n",
    "input_test = prepare_sequence(easy_sent, word_to_ix)\n",
    "# input_test = prepare_sequence(t_sentence, word_to_ix)\n",
    "\n",
    "target_test = prepare_sequence(easy_tar, tag_to_ix)\n",
    "\n",
    "_input = easy_test(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = model(_input.cuda() if USE_CUDA else _input)\n",
    "    output = easy_output(output)\n",
    "    \n",
    "    print('predict :', output)\n",
    "    print('true :', target_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence__(seq, to_ix):\n",
    "    gg = []\n",
    "    \n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            return seq\n",
    "\n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "#     return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all__(seqs, to_ix):\n",
    "    get_index = []\n",
    "    notinseq = []\n",
    "    for i in range(len(seqs)):\n",
    "        a = prepare_sequence__(seqs[i], to_ix)\n",
    "        if a != None:\n",
    "            notinseq.append( a)\n",
    "            get_index.append(i)\n",
    "#         seq_list.append(prepare_sequence__(seqs[i], to_ix))\n",
    "        \n",
    "#     notinseq = torch.stack(notinseq)\n",
    "        \n",
    "    return notinseq, get_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch input\n",
    "reserved_index_test = filter_len(word_list_test[:143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reserved_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word, filter_tag = filter_sentence(reserved_index_test, word_list_test, tag_list_test)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_output(output):\n",
    "    output = output.view(128,100,5).argmax(2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  2,  3,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n",
      "\n",
      "predict : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Func', 'I-Func', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "true : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Loss : 0.0145\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = model(input_var.cuda() if USE_CUDA else _input)\n",
    "    \n",
    "    loss = criterion(output.cpu(), target_var.view(128*100))\n",
    "    output = total_output(output)\n",
    "    \n",
    "    print('predict :', output[37])\n",
    "    print('true :', target_var[37])\n",
    "    print()\n",
    "    print('predict :', index2tag(output[37], ix_to_tag))\n",
    "    print('true :', index2tag(target_var[37], ix_to_tag))\n",
    "    print()\n",
    "    \n",
    "    print(\"Loss : %.4f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_varr, indexxx = prepare_all__(input_padded, word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 52]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這',\n",
       " '次',\n",
       " 'F',\n",
       " 'G',\n",
       " '商',\n",
       " '品',\n",
       " '市',\n",
       " '調',\n",
       " '為',\n",
       " '美',\n",
       " '肌',\n",
       " '之',\n",
       " '誌',\n",
       " '玻',\n",
       " '尿',\n",
       " '酸',\n",
       " '肌',\n",
       " '因',\n",
       " '保',\n",
       " '濕',\n",
       " '生',\n",
       " '物',\n",
       " '纖',\n",
       " '維',\n",
       " '面',\n",
       " '膜',\n",
       " '3',\n",
       " '枚',\n",
       " '入',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_padded[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  14,  113,  787,  659,  464,  287,  463,  147,  341,    4,\n",
       "          34,  202,  749,  205,  206,   91,   34,   32,   12,   13,\n",
       "          30,  209,  210,  185,   48,   49,  661,    0,  528,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_var[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['除',\n",
       " '了',\n",
       " '追',\n",
       " '求',\n",
       " '保',\n",
       " '濕',\n",
       " '或',\n",
       " '美',\n",
       " '白',\n",
       " '的',\n",
       " '功',\n",
       " '效',\n",
       " '外',\n",
       " '，',\n",
       " '其',\n",
       " '實',\n",
       " '是',\n",
       " '因',\n",
       " '為',\n",
       " '冰',\n",
       " '冰',\n",
       " '涼',\n",
       " '涼',\n",
       " '的',\n",
       " '很',\n",
       " '舒',\n",
       " '服',\n",
       " '~',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_padded[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
