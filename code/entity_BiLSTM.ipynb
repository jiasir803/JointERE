{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def schema_load(schema_root):\n",
    "    raw_dict = \"\".join(readfile(schema_root))\n",
    "    dict2json = \"\".join(raw_dict.split()[2:])\n",
    "\n",
    "    json_acceptable_string = dict2json.replace(\"'\", \"\\\"\")\n",
    "    schema = json.loads(json_acceptable_string)\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def define_entity(schema):\n",
    "    tag_type = list(schema['tagging'])\n",
    "    \n",
    "    entity_tag = []\n",
    "    for k in list(schema['entity'].keys()):\n",
    "        entity_tag.append(schema['entity'][k]['tag'])\n",
    "        \n",
    "    TAG = []\n",
    "    for t in tag_type:\n",
    "        for e in entity_tag:\n",
    "            if t!='O':\n",
    "                TAG.append(t+'-'+e)  \n",
    "                \n",
    "    TAG = [UNKOWN_TAG, PAD_TAG] + TAG + ['O']   \n",
    "\n",
    "    return TAG\n",
    "\n",
    "def tag2ix(TAG):\n",
    "    tag_to_ix={t:i for i,t in enumerate(TAG)}\n",
    "    return tag_to_ix\n",
    "\n",
    "def define_relation(schema):\n",
    "    relation_type = list(schema['relation'])\n",
    "    \n",
    "    relation_tag = []\n",
    "    for k in list(schema['relation'].keys()):\n",
    "        relation_tag.append(schema['relation'][k]['tag'])\n",
    "    \n",
    "    relation_tag = [REL_PAD] + [REL_NONE] + relation_tag\n",
    "        \n",
    "    return relation_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_set = word_set.split()\n",
    "        if len(word_set)==1:\n",
    "            word_list.append(' ')\n",
    "            ent_list.append('O')\n",
    "            rel_list.append(REL_NONE)\n",
    "        \n",
    "        else:\n",
    "            word_list.append(word_set[0])\n",
    "            ent_list.append(word_set[1])\n",
    "\n",
    "            try:\n",
    "                testerror = word_set[2]\n",
    "            except IndexError:\n",
    "                rel_list.append(REL_NONE)\n",
    "            else:\n",
    "                rel_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "\n",
    "    for now_token, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, ents, rels = get_word_and_label(content, init, now_token)\n",
    "            init = now_token+1\n",
    "            word_list.append(words)\n",
    "            ent_list.append(ents)\n",
    "            rel_list.append(rels)\n",
    "            \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, ent_list, rel_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_ent = list(ent_list[i] for i in reserved_index)\n",
    "    filter_rel = list(rel_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_ent, filter_rel\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq, isrel):\n",
    "    if isrel:\n",
    "        seq += [REL_NONE for i in range(MAX_LEN-len(seq))]\n",
    "    else:\n",
    "        seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_ent, filter_rel):\n",
    "    input_padded = [pad_seq(s, False) for s in filter_word]\n",
    "    ent_padded = [pad_seq(s, False) for s in filter_ent]\n",
    "    rel_padded = [pad_seq(s, True) for s in filter_rel]\n",
    "    \n",
    "    return input_padded, ent_padded, rel_padded\n",
    "\n",
    "def deep_copy_lists(filter_word, filter_ent, filter_rel):\n",
    "    f_w = copy.deepcopy(filter_word)\n",
    "    f_e = copy.deepcopy(filter_ent)\n",
    "    f_r = copy.deepcopy(filter_rel)\n",
    "    \n",
    "    return f_w, f_e, f_r\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "\n",
    "\n",
    "def prepare_rel(rel_padded, to_ix):\n",
    "    \n",
    "    rel_ptr = torch.zeros(len(rel_padded), MAX_LEN, MAX_LEN, dtype=torch.long) \n",
    "    \n",
    "    # 對當前的token，去比較之前所有出現過的entity，是否有關係，建成矩陣\n",
    "    # [B*ML*ML]，第二維ML是當前token，第三維ML是根據當前token對之前出現過的entity紀錄關係，以index紀錄\n",
    "    for i, rel_seq in enumerate(rel_padded):\n",
    "        rel_dict = {}\n",
    "        for j, token_seq in enumerate(rel_seq):\n",
    "            rel_ptr[i][j][:j+1] = 1\n",
    "            if token_seq != REL_NONE:\n",
    "                for k, rel in enumerate(token_seq):\n",
    "\n",
    "                    # if 是第一次出現，紀錄後面數字(標第幾對)和關係位置(A OR B)\n",
    "                    # 假如下次出現又是同個關係位置(A)，依然紀錄\n",
    "                    # 直到下次出現關係位置B，依照之前紀錄的A位置的字，然後在第三維去標關係\n",
    "\n",
    "                    rel_token = rel.split('-')\n",
    "                    if rel_token[1] not in rel_dict:\n",
    "                        rel_dict[rel_token[1]] = {'rel':rel_token[0], 'loc':rel_token[2], 'idx':[j]}\n",
    "\n",
    "                    elif rel_token[1] in rel_dict and rel_dict[rel_token[1]]['loc']==rel_token[2]:\n",
    "                        rel_dict[rel_token[1]]['idx'].append(j)\n",
    "\n",
    "                    else:\n",
    "                        record_loc = rel_dict[rel_token[1]]['idx']\n",
    "                        for idxx in record_loc:\n",
    "                            rel_ptr[i][j][idxx] = to_ix[rel_token[0]]\n",
    "                            \n",
    "    return rel_ptr\n",
    "                \n",
    "\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def dataload(input_var, ent_var, rel_var, raw_input):\n",
    "    torch_dataset = Data.TensorDataset(input_var, ent_var, rel_var, raw_input)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=0,       \n",
    "#         drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_entity(entity):\n",
    "    entity = entity.view(BATCH_SIZE,ent_size).argmax(1)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output, rel_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        self.rel_size = rel_size\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.w2 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(self.attn_output, self.rel_size, bias=False)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        \n",
    "        decoder = encoder_outputs[:,-1,:].unsqueeze(1)                       #B*1*(ts+LE) [128,1,8]\n",
    "        encoder_score = self.w1(encoder_outputs)                             #B*now len*ATTN_OUT\n",
    "        decoder_score = self.w2(decoder)                                     #B*1*ATTN_OUT\n",
    "        energy = self.tanh(encoder_score+decoder_score)                      #B*now len*ATTN_OUT            \n",
    "        \n",
    "        energy = self.v(energy)                                              #B*now len*rel_size\n",
    "        \n",
    "        \n",
    "        # 針對每個entity做softmax，去顯示他們的關係權重\n",
    "        # 主要都會是rel_none\n",
    "        # 對第二維(rel)做softmax\n",
    "        p = self.softmax(energy)                                         #B*now len*rel_size\n",
    "        \n",
    "        return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, ent_tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim, rel_tag_to_ix):\n",
    "        \n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.ent_to_ix = ent_tag_to_ix\n",
    "        self.ent_size = len(ent_tag_to_ix)                   #es\n",
    "        self.rel_to_ix = rel_tag_to_ix\n",
    "        self.rel_size = len(rel_tag_to_ix)                   #rs           \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim1, momentum=0.5, affine=False)\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "#                             num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)        \n",
    "        self.bilstm = nn.GRU(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.ent_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.ent_size, self.label_embed_dim)\n",
    "        \n",
    "        self.attn = Attn(ATTN_IN, ATTN_OUT, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, self.batch, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(self.batch, self.hidden_dim2)              #B*h2\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(self.batch, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_entity(self):\n",
    "        output_tensor = torch.zeros(self.batch, MAX_LEN, self.ent_size)  #B*ML*es\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "    \n",
    "    def create_rel_matrix(self):\n",
    "        rel_tensor = torch.zeros(self.batch, MAX_LEN, MAX_LEN, self.rel_size)  #B*ML*ML*rs\n",
    "        return rel_tensor.cuda()if USE_CUDA else rel_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, batch_ent, isTrain=True):\n",
    "        \n",
    "        self.batch = sentence.size(0)\n",
    "#         self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        entity_tensor = self.create_entity()                    #B*ML*es\n",
    "        rel_tensor = self.create_rel_matrix()                   #B*ML*ML*rs\n",
    "        \n",
    "        \n",
    "\n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "#         bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        bilstm_out, hidden1 = self.bilstm(embeds)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        # bn\n",
    "        bilstm_out = self.bn(bilstm_out)\n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence_l = [] \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            \n",
    "            if length==0:\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*es,[128, 5]            \n",
    "            ent_output = self.softmax(to_tags)                               #B*es,[128, 5]  \n",
    "            s_ent_output = self.softmax_entity(ent_output)\n",
    "            ent_onehot = self.one_hot(s_ent_output)\n",
    "            \n",
    "            \n",
    "            if isTrain:\n",
    "                label = self.label_embed(ent_onehot)                             #B*LE,[128, 3]\n",
    "#                 label = self.label_embed(ent_output) \n",
    "            else:\n",
    "                batch_ent_onehot = self.one_hot(batch_ent[:,length])\n",
    "                label = self.label_embed(batch_ent_onehot)\n",
    "            \n",
    "     \n",
    "            \n",
    "            # Assignments to Variables are in-place operations.\n",
    "            # Use that variable in lots of other contexts \n",
    "            # and some of the functions require it to not change. \n",
    "            to_tags_clone = to_tags.clone()\n",
    "            label_clone = label.clone()\n",
    "            \n",
    "            \n",
    "#             for i, tag in enumerate(s_ent_output):\n",
    "#                 if tag==ent_tag_to_ix['O']:\n",
    "#                     to_tags_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "#                     label_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "                    \n",
    "            # relation layer\n",
    "#             encoder_sequence_l.append(torch.cat((to_tags,label),1)) \n",
    "            encoder_sequence_l.append(torch.cat((h_next,label),1))  \n",
    "            encoder_sequence = torch.stack(encoder_sequence_l).t()     #B*len*(es+LE), [128,1,8]          \n",
    "\n",
    "            # Calculate attention weights \n",
    "            attn_weights = self.attn(encoder_sequence)\n",
    "\n",
    "        \n",
    "            entity_tensor[:,length,:] = ent_output\n",
    "            \n",
    "            # rel_tensor[:,length, 頭~當前 ,:]\n",
    "            rel_tensor[:,length,:length+1,:] = attn_weights\n",
    "\n",
    "        \n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return entity_tensor.view(self.batch*MAX_LEN, self.ent_size), \\\n",
    "               rel_tensor.view(self.batch*MAX_LEN*MAX_LEN, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def softmax_entity(self, entity):\n",
    "        entity = entity.view(self.batch,ent_size).argmax(1)\n",
    "        return entity\n",
    "    \n",
    "    \n",
    "    def one_hot(self, batch_ent):   \n",
    "        batchsize = batch_ent.size(0)\n",
    "        nb_digits = len(ent_tag_to_ix)\n",
    "        batch_ent = torch.unsqueeze(batch_ent, 1)\n",
    "        y_onehot = torch.cuda.FloatTensor(batchsize, nb_digits)        \n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, batch_ent, 1)    \n",
    "\n",
    "        return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "\n",
    "relation_data = root+'facial_r3.train'\n",
    "schema_root = root+'schema_2.txt'\n",
    "dev_data = root+'facial_r3.dev'\n",
    "test_data = root+'skincare.dev'\n",
    "\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "REL_NONE = 'Rel-None'\n",
    "REL_PAD = 'Rel-Pad'\n",
    "rule = ('FUNC', 'ApplyTo', 'STAT')\n",
    "\n",
    "schema = schema_load(schema_root)\n",
    "ENT_TAG = define_entity(schema)\n",
    "REL_TAG = define_relation(schema)\n",
    "ent_tag_to_ix = tag2ix(ENT_TAG)\n",
    "'''{'<PAD>': 1,\n",
    " '<UNKNOWN>': 0,\n",
    " 'B-FUNC': 2,\n",
    " 'B-STAT': 3,\n",
    " 'I-FUNC': 4,\n",
    " 'I-STAT': 5,\n",
    " 'O': 6}'''\n",
    "rel_tag_to_ix = tag2ix(REL_TAG)\n",
    "'''{'ApplyTo': 2, 'Rel-None': 1, 'Rel-Pad': 0}'''\n",
    "\n",
    "# ========hyper-parameter-set==========\n",
    "\n",
    "ent_size = len(ent_tag_to_ix)\n",
    "rel_size = len(rel_tag_to_ix)\n",
    "MAX_LEN = 70     # original 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "EMBEDDING_DIM = 40   # original 20\n",
    "HIDDEN_DIM1 = 20     # original 10\n",
    "HIDDEN_DIM2 = 16     # original 8\n",
    "LABEL_EMBED_DIM = ent_size\n",
    "DENSE_OUT = 100\n",
    "\n",
    "# ATTN_IN = ent_size+LABEL_EMBED_DIM\n",
    "ATTN_IN = HIDDEN_DIM2+LABEL_EMBED_DIM\n",
    "\n",
    "ATTN_OUT = 6        # original 6       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    content = readfile(data)\n",
    "    word_list, ent_list, rel_list = split_to_list(content)\n",
    "    word_to_ix = word2index(word_list)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    #================================================\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, vocab_size, word_to_ix, reserved_index, word_list\n",
    "\n",
    "def dev_preprocess(dev_data):\n",
    "    dev_content = readfile(dev_data)\n",
    "    word_list, ent_list, rel_list = split_to_list(dev_content)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, reserved_index, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_ent_tag = dict_inverse(ent_tag_to_ix)\n",
    "ix_to_rel_tag = dict_inverse(rel_tag_to_ix)\n",
    "#===============================================\n",
    "input_var, ent_var, rel_var, vocab_size, word_to_ix, raw_index, raw_input = preprocess(relation_data)\n",
    "loader = dataload(input_var, ent_var, rel_var, raw_index)\n",
    "\n",
    "input_dev, ent_dev, rel_dev, raw_index_dev, raw_input_dev = dev_preprocess(dev_data)\n",
    "dev_loader = dataload(input_dev, ent_dev, rel_dev, raw_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "# criterion_rel = nn.NLLLoss(ignore_index=rel_tag_to_ix[REL_PAD])\n",
    "criterion_rel = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:04<15:07,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | ent loss 0.6612 | rel loss 0.0725 | total loss 0.7337\n",
      "         | val ent loss 0.5143 | val rel loss 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/200 [00:09<15:03,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | ent loss 0.3981 | rel loss 0.0230 | total loss 0.4210\n",
      "         | val ent loss 0.3239 | val rel loss 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/200 [00:13<15:03,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | ent loss 0.3542 | rel loss 0.0165 | total loss 0.3707\n",
      "         | val ent loss 0.2191 | val rel loss 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/200 [00:18<15:03,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | ent loss 0.2000 | rel loss 0.0111 | total loss 0.2111\n",
      "         | val ent loss 0.2326 | val rel loss 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 5/200 [00:22<14:56,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | ent loss 0.1960 | rel loss 0.0126 | total loss 0.2086\n",
      "         | val ent loss 0.3133 | val rel loss 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/200 [00:27<14:50,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | ent loss 0.1335 | rel loss 0.0102 | total loss 0.1437\n",
      "         | val ent loss 0.1162 | val rel loss 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 7/200 [00:32<14:50,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | ent loss 0.1056 | rel loss 0.0101 | total loss 0.1158\n",
      "         | val ent loss 0.0855 | val rel loss 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/200 [00:37<14:49,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | ent loss 0.0890 | rel loss 0.0099 | total loss 0.0988\n",
      "         | val ent loss 0.1371 | val rel loss 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/200 [00:41<14:45,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | ent loss 0.0900 | rel loss 0.0096 | total loss 0.0996\n",
      "         | val ent loss 0.0646 | val rel loss 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 10/200 [00:46<14:43,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | ent loss 0.1132 | rel loss 0.0092 | total loss 0.1225\n",
      "          | val ent loss 0.0871 | val rel loss 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 11/200 [00:51<14:40,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | ent loss 0.0848 | rel loss 0.0065 | total loss 0.0913\n",
      "          | val ent loss 0.1172 | val rel loss 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 12/200 [00:55<14:37,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | ent loss 0.0518 | rel loss 0.0072 | total loss 0.0590\n",
      "          | val ent loss 0.1060 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 13/200 [01:00<14:33,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | ent loss 0.0479 | rel loss 0.0070 | total loss 0.0550\n",
      "          | val ent loss 0.1093 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 14/200 [01:05<14:30,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | ent loss 0.0407 | rel loss 0.0053 | total loss 0.0459\n",
      "          | val ent loss 0.0557 | val rel loss 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 15/200 [01:10<14:26,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | ent loss 0.0124 | rel loss 0.0059 | total loss 0.0183\n",
      "          | val ent loss 0.0091 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 16/200 [01:14<14:22,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | ent loss 0.0148 | rel loss 0.0051 | total loss 0.0199\n",
      "          | val ent loss 0.0311 | val rel loss 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 17/200 [01:19<14:18,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | ent loss 0.0183 | rel loss 0.0045 | total loss 0.0228\n",
      "          | val ent loss 0.0317 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 18/200 [01:24<14:14,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | ent loss 0.0251 | rel loss 0.0048 | total loss 0.0300\n",
      "          | val ent loss 0.0154 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 19/200 [01:29<14:11,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | ent loss 0.0103 | rel loss 0.0063 | total loss 0.0167\n",
      "          | val ent loss 0.0420 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 20/200 [01:34<14:06,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | ent loss 0.0254 | rel loss 0.0043 | total loss 0.0297\n",
      "          | val ent loss 0.0976 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 21/200 [01:38<14:02,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | ent loss 0.0234 | rel loss 0.0053 | total loss 0.0287\n",
      "          | val ent loss 0.0804 | val rel loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 22/200 [01:43<13:57,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | ent loss 0.0088 | rel loss 0.0034 | total loss 0.0122\n",
      "          | val ent loss 0.0608 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 23/200 [01:48<13:53,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | ent loss 0.0055 | rel loss 0.0029 | total loss 0.0084\n",
      "          | val ent loss 0.1162 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 24/200 [01:53<13:48,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | ent loss 0.0166 | rel loss 0.0039 | total loss 0.0205\n",
      "          | val ent loss 0.0207 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 25/200 [01:57<13:45,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | ent loss 0.0085 | rel loss 0.0028 | total loss 0.0113\n",
      "          | val ent loss 0.0765 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 26/200 [02:02<13:41,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | ent loss 0.0047 | rel loss 0.0030 | total loss 0.0077\n",
      "          | val ent loss 0.0642 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 27/200 [02:07<13:37,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | ent loss 0.0044 | rel loss 0.0030 | total loss 0.0074\n",
      "          | val ent loss 0.0335 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 28/200 [02:12<13:33,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | ent loss 0.0030 | rel loss 0.0023 | total loss 0.0053\n",
      "          | val ent loss 0.0128 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 29/200 [02:17<13:29,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | ent loss 0.0021 | rel loss 0.0019 | total loss 0.0039\n",
      "          | val ent loss 0.0308 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 30/200 [02:22<13:25,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | ent loss 0.0038 | rel loss 0.0027 | total loss 0.0064\n",
      "          | val ent loss 0.1132 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 31/200 [02:26<13:20,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | ent loss 0.0023 | rel loss 0.0019 | total loss 0.0042\n",
      "          | val ent loss 0.0923 | val rel loss 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 32/200 [02:31<13:15,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | ent loss 0.0033 | rel loss 0.0021 | total loss 0.0054\n",
      "          | val ent loss 0.0195 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 33/200 [02:36<13:11,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | ent loss 0.0049 | rel loss 0.0019 | total loss 0.0068\n",
      "          | val ent loss 0.1978 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 34/200 [02:41<13:06,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | ent loss 0.0134 | rel loss 0.0024 | total loss 0.0158\n",
      "          | val ent loss 0.0639 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 35/200 [02:45<13:02,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | ent loss 0.0195 | rel loss 0.0014 | total loss 0.0209\n",
      "          | val ent loss 0.0756 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 36/200 [02:50<12:57,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | ent loss 0.0047 | rel loss 0.0020 | total loss 0.0067\n",
      "          | val ent loss 0.0394 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 37/200 [02:55<12:53,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | ent loss 0.0079 | rel loss 0.0017 | total loss 0.0096\n",
      "          | val ent loss 0.0961 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 38/200 [03:00<12:49,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | ent loss 0.0069 | rel loss 0.0016 | total loss 0.0085\n",
      "          | val ent loss 0.0455 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 39/200 [03:05<12:44,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | ent loss 0.0065 | rel loss 0.0019 | total loss 0.0085\n",
      "          | val ent loss 0.0728 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 40/200 [03:10<12:40,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | ent loss 0.0045 | rel loss 0.0016 | total loss 0.0062\n",
      "          | val ent loss 0.0428 | val rel loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 41/200 [03:14<12:35,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | ent loss 0.0025 | rel loss 0.0014 | total loss 0.0038\n",
      "          | val ent loss 0.0430 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 42/200 [03:19<12:30,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | ent loss 0.0050 | rel loss 0.0017 | total loss 0.0067\n",
      "          | val ent loss 0.0232 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 43/200 [03:24<12:26,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | ent loss 0.0284 | rel loss 0.0021 | total loss 0.0305\n",
      "          | val ent loss 0.0084 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 44/200 [03:29<12:21,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | ent loss 0.0226 | rel loss 0.0032 | total loss 0.0258\n",
      "          | val ent loss 0.0527 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 45/200 [03:33<12:16,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | ent loss 0.0060 | rel loss 0.0017 | total loss 0.0076\n",
      "          | val ent loss 0.1510 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 46/200 [03:38<12:12,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | ent loss 0.0103 | rel loss 0.0015 | total loss 0.0118\n",
      "          | val ent loss 0.1376 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 47/200 [03:43<12:07,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | ent loss 0.0044 | rel loss 0.0014 | total loss 0.0059\n",
      "          | val ent loss 0.0030 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 48/200 [03:48<12:02,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | ent loss 0.0075 | rel loss 0.0014 | total loss 0.0089\n",
      "          | val ent loss 0.0138 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 49/200 [03:53<11:58,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | ent loss 0.0073 | rel loss 0.0017 | total loss 0.0090\n",
      "          | val ent loss 0.0805 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 50/200 [03:57<11:53,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 | ent loss 0.0452 | rel loss 0.0014 | total loss 0.0466\n",
      "          | val ent loss 0.0491 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 51/200 [04:02<11:49,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 | ent loss 0.0036 | rel loss 0.0023 | total loss 0.0058\n",
      "          | val ent loss 0.1146 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 52/200 [04:07<11:44,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 | ent loss 0.0097 | rel loss 0.0017 | total loss 0.0115\n",
      "          | val ent loss 0.0025 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 53/200 [04:12<11:40,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 | ent loss 0.0014 | rel loss 0.0011 | total loss 0.0025\n",
      "          | val ent loss 0.0507 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 54/200 [04:17<11:35,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 | ent loss 0.0021 | rel loss 0.0013 | total loss 0.0033\n",
      "          | val ent loss 0.0424 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 55/200 [04:22<11:30,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 | ent loss 0.0048 | rel loss 0.0015 | total loss 0.0062\n",
      "          | val ent loss 0.0026 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 56/200 [04:26<11:25,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 | ent loss 0.0126 | rel loss 0.0013 | total loss 0.0139\n",
      "          | val ent loss 0.0447 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 57/200 [04:31<11:21,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 | ent loss 0.0072 | rel loss 0.0013 | total loss 0.0085\n",
      "          | val ent loss 0.1534 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 58/200 [04:36<11:16,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 | ent loss 0.0019 | rel loss 0.0014 | total loss 0.0032\n",
      "          | val ent loss 0.0547 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 59/200 [04:41<11:11,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 | ent loss 0.0253 | rel loss 0.0017 | total loss 0.0270\n",
      "          | val ent loss 0.0519 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 60/200 [04:45<11:07,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 | ent loss 0.0036 | rel loss 0.0011 | total loss 0.0047\n",
      "          | val ent loss 0.0376 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 61/200 [04:50<11:02,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 | ent loss 0.0029 | rel loss 0.0012 | total loss 0.0041\n",
      "          | val ent loss 0.0169 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 62/200 [04:55<10:57,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 | ent loss 0.0019 | rel loss 0.0010 | total loss 0.0029\n",
      "          | val ent loss 0.0580 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 63/200 [05:00<10:52,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 | ent loss 0.0015 | rel loss 0.0013 | total loss 0.0027\n",
      "          | val ent loss 0.2679 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 64/200 [05:04<10:47,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 | ent loss 0.0049 | rel loss 0.0018 | total loss 0.0067\n",
      "          | val ent loss 0.1306 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 65/200 [05:09<10:42,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 | ent loss 0.0168 | rel loss 0.0015 | total loss 0.0183\n",
      "          | val ent loss 0.1644 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 66/200 [05:14<10:37,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 | ent loss 0.0038 | rel loss 0.0014 | total loss 0.0052\n",
      "          | val ent loss 0.1102 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 67/200 [05:18<10:32,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 | ent loss 0.0107 | rel loss 0.0017 | total loss 0.0124\n",
      "          | val ent loss 0.0596 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 68/200 [05:23<10:27,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 | ent loss 0.0032 | rel loss 0.0010 | total loss 0.0041\n",
      "          | val ent loss 0.0025 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 69/200 [05:28<10:22,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 | ent loss 0.0020 | rel loss 0.0016 | total loss 0.0036\n",
      "          | val ent loss 0.1261 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 70/200 [05:32<10:18,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 | ent loss 0.0018 | rel loss 0.0014 | total loss 0.0033\n",
      "          | val ent loss 0.1620 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 71/200 [05:37<10:13,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71 | ent loss 0.0013 | rel loss 0.0012 | total loss 0.0025\n",
      "          | val ent loss 0.0673 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 72/200 [05:42<10:08,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 | ent loss 0.0211 | rel loss 0.0020 | total loss 0.0230\n",
      "          | val ent loss 0.1483 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 73/200 [05:47<10:04,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 | ent loss 0.0016 | rel loss 0.0009 | total loss 0.0025\n",
      "          | val ent loss 0.0522 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 74/200 [05:52<09:59,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 | ent loss 0.0042 | rel loss 0.0012 | total loss 0.0054\n",
      "          | val ent loss 0.0554 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 75/200 [05:56<09:54,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 | ent loss 0.0058 | rel loss 0.0013 | total loss 0.0071\n",
      "          | val ent loss 0.0167 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 76/200 [06:01<09:50,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76 | ent loss 0.0041 | rel loss 0.0016 | total loss 0.0058\n",
      "          | val ent loss 0.1325 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 77/200 [06:06<09:45,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 | ent loss 0.0023 | rel loss 0.0012 | total loss 0.0035\n",
      "          | val ent loss 0.0654 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 78/200 [06:11<09:40,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78 | ent loss 0.0040 | rel loss 0.0016 | total loss 0.0056\n",
      "          | val ent loss 0.0552 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 79/200 [06:16<09:36,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 | ent loss 0.0009 | rel loss 0.0013 | total loss 0.0022\n",
      "          | val ent loss 0.1124 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 80/200 [06:20<09:31,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80 | ent loss 0.0066 | rel loss 0.0008 | total loss 0.0075\n",
      "          | val ent loss 0.0294 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 81/200 [06:25<09:26,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81 | ent loss 0.0009 | rel loss 0.0012 | total loss 0.0021\n",
      "          | val ent loss 0.2343 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 82/200 [06:30<09:22,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82 | ent loss 0.0020 | rel loss 0.0009 | total loss 0.0029\n",
      "          | val ent loss 0.0708 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 83/200 [06:35<09:17,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83 | ent loss 0.0008 | rel loss 0.0010 | total loss 0.0018\n",
      "          | val ent loss 0.0011 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 84/200 [06:40<09:12,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 | ent loss 0.0006 | rel loss 0.0007 | total loss 0.0013\n",
      "          | val ent loss 0.0972 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 85/200 [06:45<09:07,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85 | ent loss 0.0008 | rel loss 0.0006 | total loss 0.0015\n",
      "          | val ent loss 0.1211 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 86/200 [06:49<09:03,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86 | ent loss 0.0009 | rel loss 0.0010 | total loss 0.0019\n",
      "          | val ent loss 0.1524 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 87/200 [06:54<08:58,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 | ent loss 0.0167 | rel loss 0.0014 | total loss 0.0181\n",
      "          | val ent loss 0.0459 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 88/200 [06:59<08:53,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88 | ent loss 0.0075 | rel loss 0.0011 | total loss 0.0086\n",
      "          | val ent loss 0.0237 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 89/200 [07:03<08:48,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89 | ent loss 0.0027 | rel loss 0.0009 | total loss 0.0036\n",
      "          | val ent loss 0.2255 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 90/200 [07:07<08:42,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90 | ent loss 0.0221 | rel loss 0.0016 | total loss 0.0237\n",
      "          | val ent loss 0.1759 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 91/200 [07:11<08:36,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 | ent loss 0.0088 | rel loss 0.0013 | total loss 0.0101\n",
      "          | val ent loss 0.0902 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 92/200 [07:15<08:31,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 | ent loss 0.0131 | rel loss 0.0016 | total loss 0.0147\n",
      "          | val ent loss 0.0776 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 93/200 [07:20<08:26,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93 | ent loss 0.0292 | rel loss 0.0019 | total loss 0.0312\n",
      "          | val ent loss 0.1050 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 94/200 [07:24<08:21,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 | ent loss 0.0098 | rel loss 0.0009 | total loss 0.0106\n",
      "          | val ent loss 0.0568 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 95/200 [07:28<08:15,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 | ent loss 0.0392 | rel loss 0.0012 | total loss 0.0404\n",
      "          | val ent loss 0.0515 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 96/200 [07:32<08:10,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96 | ent loss 0.0071 | rel loss 0.0012 | total loss 0.0084\n",
      "          | val ent loss 0.1206 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 97/200 [07:37<08:05,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 | ent loss 0.0022 | rel loss 0.0011 | total loss 0.0032\n",
      "          | val ent loss 0.0503 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 98/200 [07:41<08:00,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98 | ent loss 0.0123 | rel loss 0.0011 | total loss 0.0134\n",
      "          | val ent loss 0.0366 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 99/200 [07:46<07:55,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 | ent loss 0.0017 | rel loss 0.0009 | total loss 0.0027\n",
      "          | val ent loss 0.1072 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 100/200 [07:51<07:51,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 | ent loss 0.0041 | rel loss 0.0008 | total loss 0.0050\n",
      "           | val ent loss 0.0553 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 101/200 [07:56<07:46,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 101 | ent loss 0.0014 | rel loss 0.0008 | total loss 0.0022\n",
      "           | val ent loss 0.0629 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 102/200 [08:00<07:42,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 102 | ent loss 0.0008 | rel loss 0.0011 | total loss 0.0019\n",
      "           | val ent loss 0.0478 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 103/200 [08:05<07:37,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103 | ent loss 0.0010 | rel loss 0.0011 | total loss 0.0022\n",
      "           | val ent loss 0.0146 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 104/200 [08:10<07:32,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 104 | ent loss 0.0011 | rel loss 0.0009 | total loss 0.0020\n",
      "           | val ent loss 0.0632 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 105/200 [08:15<07:28,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 105 | ent loss 0.0149 | rel loss 0.0006 | total loss 0.0154\n",
      "           | val ent loss 0.0687 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 106/200 [08:20<07:23,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106 | ent loss 0.0173 | rel loss 0.0018 | total loss 0.0191\n",
      "           | val ent loss 0.1109 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 107/200 [08:25<07:18,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 | ent loss 0.0059 | rel loss 0.0021 | total loss 0.0080\n",
      "           | val ent loss 0.2209 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 108/200 [08:29<07:14,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108 | ent loss 0.0222 | rel loss 0.0012 | total loss 0.0233\n",
      "           | val ent loss 0.0849 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 109/200 [08:34<07:09,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109 | ent loss 0.0195 | rel loss 0.0013 | total loss 0.0208\n",
      "           | val ent loss 0.1561 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 110/200 [08:39<07:04,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 110 | ent loss 0.0065 | rel loss 0.0014 | total loss 0.0079\n",
      "           | val ent loss 0.1176 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 111/200 [08:44<07:00,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 111 | ent loss 0.0026 | rel loss 0.0011 | total loss 0.0037\n",
      "           | val ent loss 0.2559 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 112/200 [08:48<06:55,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 | ent loss 0.0010 | rel loss 0.0010 | total loss 0.0020\n",
      "           | val ent loss 0.0010 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 113/200 [08:53<06:50,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113 | ent loss 0.0010 | rel loss 0.0010 | total loss 0.0021\n",
      "           | val ent loss 0.1468 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 114/200 [08:58<06:46,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 114 | ent loss 0.0007 | rel loss 0.0010 | total loss 0.0017\n",
      "           | val ent loss 0.0711 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 115/200 [09:03<06:41,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115 | ent loss 0.0006 | rel loss 0.0009 | total loss 0.0015\n",
      "           | val ent loss 0.0351 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 116/200 [09:08<06:37,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116 | ent loss 0.0012 | rel loss 0.0012 | total loss 0.0024\n",
      "           | val ent loss 0.1615 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 117/200 [09:13<06:32,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 117 | ent loss 0.0015 | rel loss 0.0007 | total loss 0.0022\n",
      "           | val ent loss 0.2912 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 118/200 [09:18<06:27,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118 | ent loss 0.0012 | rel loss 0.0013 | total loss 0.0025\n",
      "           | val ent loss 0.0515 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 119/200 [09:22<06:22,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119 | ent loss 0.0007 | rel loss 0.0009 | total loss 0.0016\n",
      "           | val ent loss 0.1127 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 120/200 [09:27<06:18,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120 | ent loss 0.0008 | rel loss 0.0007 | total loss 0.0016\n",
      "           | val ent loss 0.0949 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 121/200 [09:32<06:13,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121 | ent loss 0.0006 | rel loss 0.0008 | total loss 0.0015\n",
      "           | val ent loss 0.1231 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 122/200 [09:37<06:09,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 122 | ent loss 0.0008 | rel loss 0.0007 | total loss 0.0015\n",
      "           | val ent loss 0.0423 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 123/200 [09:42<06:04,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 123 | ent loss 0.0219 | rel loss 0.0011 | total loss 0.0230\n",
      "           | val ent loss 0.0804 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 124/200 [09:47<05:59,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124 | ent loss 0.0394 | rel loss 0.0006 | total loss 0.0400\n",
      "           | val ent loss 0.0630 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 125/200 [09:51<05:55,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 125 | ent loss 0.0115 | rel loss 0.0014 | total loss 0.0130\n",
      "           | val ent loss 0.1953 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 126/200 [09:56<05:50,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 126 | ent loss 0.0210 | rel loss 0.0012 | total loss 0.0222\n",
      "           | val ent loss 0.1151 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 127/200 [10:01<05:45,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127 | ent loss 0.0048 | rel loss 0.0006 | total loss 0.0054\n",
      "           | val ent loss 0.0868 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 128/200 [10:06<05:41,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 128 | ent loss 0.0028 | rel loss 0.0012 | total loss 0.0040\n",
      "           | val ent loss 0.3133 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 129/200 [10:11<05:36,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 129 | ent loss 0.0083 | rel loss 0.0007 | total loss 0.0090\n",
      "           | val ent loss 0.3955 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 130/200 [10:16<05:31,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130 | ent loss 0.0013 | rel loss 0.0007 | total loss 0.0020\n",
      "           | val ent loss 0.0869 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 131/200 [10:21<05:27,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 131 | ent loss 0.0046 | rel loss 0.0007 | total loss 0.0053\n",
      "           | val ent loss 0.0832 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 132/200 [10:25<05:22,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132 | ent loss 0.0034 | rel loss 0.0015 | total loss 0.0048\n",
      "           | val ent loss 0.1033 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 133/200 [10:30<05:17,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133 | ent loss 0.0012 | rel loss 0.0008 | total loss 0.0020\n",
      "           | val ent loss 0.0452 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 134/200 [10:35<05:13,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 134 | ent loss 0.0047 | rel loss 0.0008 | total loss 0.0055\n",
      "           | val ent loss 0.0350 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 135/200 [10:40<05:08,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135 | ent loss 0.0160 | rel loss 0.0016 | total loss 0.0175\n",
      "           | val ent loss 0.3672 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 136/200 [10:45<05:03,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136 | ent loss 0.0019 | rel loss 0.0012 | total loss 0.0030\n",
      "           | val ent loss 0.1084 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 137/200 [10:49<04:58,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137 | ent loss 0.0093 | rel loss 0.0012 | total loss 0.0105\n",
      "           | val ent loss 0.0466 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 138/200 [10:54<04:54,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138 | ent loss 0.0017 | rel loss 0.0010 | total loss 0.0027\n",
      "           | val ent loss 0.0995 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 139/200 [10:59<04:49,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 139 | ent loss 0.0018 | rel loss 0.0010 | total loss 0.0028\n",
      "           | val ent loss 0.2170 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 140/200 [11:04<04:44,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140 | ent loss 0.0011 | rel loss 0.0011 | total loss 0.0022\n",
      "           | val ent loss 0.0941 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 141/200 [11:09<04:40,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 141 | ent loss 0.0059 | rel loss 0.0010 | total loss 0.0068\n",
      "           | val ent loss 0.1435 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 142/200 [11:14<04:35,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 142 | ent loss 0.0014 | rel loss 0.0009 | total loss 0.0023\n",
      "           | val ent loss 0.1704 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 143/200 [11:19<04:30,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143 | ent loss 0.0007 | rel loss 0.0011 | total loss 0.0018\n",
      "           | val ent loss 0.2093 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 144/200 [11:24<04:26,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 144 | ent loss 0.0009 | rel loss 0.0010 | total loss 0.0019\n",
      "           | val ent loss 0.2590 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 145/200 [11:28<04:21,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 145 | ent loss 0.0018 | rel loss 0.0011 | total loss 0.0029\n",
      "           | val ent loss 0.0011 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 146/200 [11:33<04:16,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 146 | ent loss 0.0041 | rel loss 0.0008 | total loss 0.0049\n",
      "           | val ent loss 0.1167 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 147/200 [11:38<04:11,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 147 | ent loss 0.0009 | rel loss 0.0007 | total loss 0.0016\n",
      "           | val ent loss 0.1367 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 148/200 [11:43<04:07,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 148 | ent loss 0.0017 | rel loss 0.0008 | total loss 0.0025\n",
      "           | val ent loss 0.0872 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 149/200 [11:48<04:02,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 149 | ent loss 0.0008 | rel loss 0.0007 | total loss 0.0015\n",
      "           | val ent loss 0.0586 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 150/200 [11:53<03:57,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150 | ent loss 0.0574 | rel loss 0.0026 | total loss 0.0600\n",
      "           | val ent loss 0.0094 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 151/200 [11:57<03:52,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 151 | ent loss 0.0036 | rel loss 0.0008 | total loss 0.0043\n",
      "           | val ent loss 0.1053 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 152/200 [12:02<03:48,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 152 | ent loss 0.0054 | rel loss 0.0014 | total loss 0.0068\n",
      "           | val ent loss 0.1119 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 153/200 [12:07<03:43,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 153 | ent loss 0.0022 | rel loss 0.0010 | total loss 0.0032\n",
      "           | val ent loss 0.0608 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 154/200 [12:12<03:38,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 154 | ent loss 0.0240 | rel loss 0.0017 | total loss 0.0257\n",
      "           | val ent loss 0.1109 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 155/200 [12:17<03:34,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 | ent loss 0.0019 | rel loss 0.0011 | total loss 0.0030\n",
      "           | val ent loss 0.1155 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 156/200 [12:21<03:29,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 156 | ent loss 0.0255 | rel loss 0.0008 | total loss 0.0262\n",
      "           | val ent loss 0.0870 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 157/200 [12:26<03:24,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 157 | ent loss 0.0033 | rel loss 0.0008 | total loss 0.0041\n",
      "           | val ent loss 0.0523 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 158/200 [12:31<03:19,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 158 | ent loss 0.0016 | rel loss 0.0007 | total loss 0.0023\n",
      "           | val ent loss 0.1404 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 159/200 [12:36<03:15,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 159 | ent loss 0.0016 | rel loss 0.0006 | total loss 0.0023\n",
      "           | val ent loss 0.0401 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 160/200 [12:41<03:10,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160 | ent loss 0.0012 | rel loss 0.0011 | total loss 0.0023\n",
      "           | val ent loss 0.0935 | val rel loss 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 161/200 [12:45<03:05,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 161 | ent loss 0.0044 | rel loss 0.0011 | total loss 0.0054\n",
      "           | val ent loss 0.0055 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 162/200 [12:49<03:00,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 162 | ent loss 0.0022 | rel loss 0.0014 | total loss 0.0036\n",
      "           | val ent loss 0.1838 | val rel loss 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 163/200 [12:54<02:55,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 163 | ent loss 0.0009 | rel loss 0.0011 | total loss 0.0020\n",
      "           | val ent loss 0.1045 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 164/200 [12:59<02:51,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164 | ent loss 0.0006 | rel loss 0.0007 | total loss 0.0013\n",
      "           | val ent loss 0.0758 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 165/200 [13:04<02:46,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 165 | ent loss 0.0037 | rel loss 0.0009 | total loss 0.0046\n",
      "           | val ent loss 0.1978 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 166/200 [13:09<02:41,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 166 | ent loss 0.0007 | rel loss 0.0009 | total loss 0.0016\n",
      "           | val ent loss 0.0640 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 167/200 [13:13<02:36,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 167 | ent loss 0.0006 | rel loss 0.0006 | total loss 0.0013\n",
      "           | val ent loss 0.2336 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 168/200 [13:18<02:32,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 168 | ent loss 0.0007 | rel loss 0.0008 | total loss 0.0015\n",
      "           | val ent loss 0.0617 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 169/200 [13:23<02:27,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 169 | ent loss 0.0018 | rel loss 0.0013 | total loss 0.0031\n",
      "           | val ent loss 0.0751 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 170/200 [13:27<02:22,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 | ent loss 0.0006 | rel loss 0.0007 | total loss 0.0014\n",
      "           | val ent loss 0.0008 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 171/200 [13:32<02:17,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 171 | ent loss 0.0006 | rel loss 0.0008 | total loss 0.0014\n",
      "           | val ent loss 0.0348 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 172/200 [13:36<02:12,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 172 | ent loss 0.0054 | rel loss 0.0015 | total loss 0.0069\n",
      "           | val ent loss 0.1728 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 173/200 [13:41<02:08,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 173 | ent loss 0.0067 | rel loss 0.0014 | total loss 0.0081\n",
      "           | val ent loss 0.0256 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 174/200 [13:46<02:03,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 174 | ent loss 0.0006 | rel loss 0.0008 | total loss 0.0014\n",
      "           | val ent loss 0.1977 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 175/200 [13:51<01:58,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175 | ent loss 0.0006 | rel loss 0.0006 | total loss 0.0012\n",
      "           | val ent loss 0.1795 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 176/200 [13:55<01:53,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 176 | ent loss 0.0154 | rel loss 0.0012 | total loss 0.0166\n",
      "           | val ent loss 0.1296 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 177/200 [14:00<01:49,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 177 | ent loss 0.0042 | rel loss 0.0006 | total loss 0.0048\n",
      "           | val ent loss 0.1085 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 178/200 [14:05<01:44,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 178 | ent loss 0.0045 | rel loss 0.0008 | total loss 0.0053\n",
      "           | val ent loss 0.0228 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 179/200 [14:10<01:39,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 179 | ent loss 0.0020 | rel loss 0.0010 | total loss 0.0031\n",
      "           | val ent loss 0.0991 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 180/200 [14:14<01:34,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180 | ent loss 0.0507 | rel loss 0.0015 | total loss 0.0522\n",
      "           | val ent loss 0.1392 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 181/200 [14:19<01:30,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181 | ent loss 0.0014 | rel loss 0.0011 | total loss 0.0025\n",
      "           | val ent loss 0.0009 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 182/200 [14:24<01:25,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 182 | ent loss 0.0025 | rel loss 0.0008 | total loss 0.0033\n",
      "           | val ent loss 0.0724 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 183/200 [14:29<01:20,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 183 | ent loss 0.0262 | rel loss 0.0010 | total loss 0.0271\n",
      "           | val ent loss 0.2707 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 184/200 [14:34<01:16,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 184 | ent loss 0.0022 | rel loss 0.0005 | total loss 0.0027\n",
      "           | val ent loss 0.0062 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 185/200 [14:39<01:11,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 | ent loss 0.0045 | rel loss 0.0010 | total loss 0.0055\n",
      "           | val ent loss 0.1241 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 186/200 [14:43<01:06,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 186 | ent loss 0.0014 | rel loss 0.0005 | total loss 0.0018\n",
      "           | val ent loss 0.0750 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 187/200 [14:48<01:01,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 187 | ent loss 0.0009 | rel loss 0.0009 | total loss 0.0018\n",
      "           | val ent loss 0.1397 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 188/200 [14:53<00:57,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 188 | ent loss 0.0017 | rel loss 0.0006 | total loss 0.0023\n",
      "           | val ent loss 0.0167 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 189/200 [14:58<00:52,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 189 | ent loss 0.0046 | rel loss 0.0010 | total loss 0.0056\n",
      "           | val ent loss 0.1989 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 190/200 [15:02<00:47,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 190 | ent loss 0.0033 | rel loss 0.0010 | total loss 0.0043\n",
      "           | val ent loss 0.2053 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 191/200 [15:07<00:42,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191 | ent loss 0.0007 | rel loss 0.0007 | total loss 0.0014\n",
      "           | val ent loss 0.0612 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 192/200 [15:12<00:38,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 192 | ent loss 0.0007 | rel loss 0.0012 | total loss 0.0019\n",
      "           | val ent loss 0.2001 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 193/200 [15:16<00:33,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 193 | ent loss 0.0006 | rel loss 0.0006 | total loss 0.0012\n",
      "           | val ent loss 0.0091 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 194/200 [15:21<00:28,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 194 | ent loss 0.0163 | rel loss 0.0011 | total loss 0.0174\n",
      "           | val ent loss 0.0894 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 195/200 [15:25<00:23,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195 | ent loss 0.0018 | rel loss 0.0006 | total loss 0.0023\n",
      "           | val ent loss 0.1617 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 196/200 [15:30<00:18,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 196 | ent loss 0.0010 | rel loss 0.0008 | total loss 0.0018\n",
      "           | val ent loss 0.0859 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 197/200 [15:35<00:14,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 197 | ent loss 0.0062 | rel loss 0.0010 | total loss 0.0071\n",
      "           | val ent loss 0.0205 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 198/200 [15:40<00:09,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 198 | ent loss 0.0586 | rel loss 0.0006 | total loss 0.0592\n",
      "           | val ent loss 0.0146 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 199/200 [15:45<00:04,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199 | ent loss 0.0027 | rel loss 0.0009 | total loss 0.0035\n",
      "           | val ent loss 0.0697 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 200/200 [15:50<00:00,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200 | ent loss 0.0184 | rel loss 0.0009 | total loss 0.0193\n",
      "           | val ent loss 0.1553 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 200\n",
    "print_every = 12\n",
    "\n",
    "train_entloss_l = []\n",
    "val_entloss_l = []\n",
    "train_relloss_l = []\n",
    "val_relloss_l = []\n",
    "\n",
    "loss = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(n_iters)):  \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "        batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "        \n",
    "        entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "        relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "        loss = entloss+relloss\n",
    "        \n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    train_entloss_l.append(entloss.cpu())\n",
    "    train_relloss_l.append(relloss.cpu())\n",
    "    #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "        \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "        model.eval()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "        val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "        \n",
    "    val_entloss_l.append(val_entloss.cpu())\n",
    "    val_relloss_l.append(val_relloss.cpu())\n",
    "    \n",
    "    \n",
    "    print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "          % (epoch+1, entloss, relloss, loss))\n",
    "    print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "          % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "torch.save(model.state_dict(), 'relation_extraction_1_new.pkl')\n",
    "\n",
    "# model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "#               LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "# model.load_state_dict(torch.load('relation_extraction.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_entloss_l, label='train_ent_loss')\n",
    "plt.plot(val_entloss_l, label='val_ent_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entity Loss\") \n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_relloss_l, label='train_rel_loss')\n",
    "plt.plot(val_relloss_l, label='val_rel_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relation Loss\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_choose(input_var):\n",
    "    r_choose = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        r_choose.append(random.randint(0,len(input_var)))\n",
    "    return r_choose\n",
    "        \n",
    "def ent_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,ent_size).argmax(2)\n",
    "    return output\n",
    "\n",
    "def rel_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,MAX_LEN,rel_size).argmax(3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict : ['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "true : ['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Entity loss : 0.0021\n",
      "Relation loss : 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    r_choose = random_choose(input_var)\n",
    "    model.eval()\n",
    "    ent_output, rel_output = model(input_var[r_choose].cuda() if USE_CUDA else input_var, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "    \n",
    "    batchsize = input_var[r_choose].size(0)\n",
    "    \n",
    "    ent_loss = criterion_tag(ent_output.cpu(), ent_var[r_choose].view(BATCH_SIZE*MAX_LEN))\n",
    "    ent_output = ent_argmax(ent_output, batchsize)\n",
    "    \n",
    "    rel_loss = criterion_rel(rel_output.cpu(), rel_var[r_choose].view(BATCH_SIZE*MAX_LEN*MAX_LEN))\n",
    "    \n",
    "    print()\n",
    "    print('predict :', index2tag(ent_output[0], ix_to_ent_tag))\n",
    "    print('true :', index2tag(ent_var[r_choose[0]], ix_to_ent_tag))\n",
    "    \n",
    "    print()\n",
    "    print(\"Entity loss : %.4f\" % ent_loss)\n",
    "    print(\"Relation loss : %.4f\" % rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "def evaluate_data(data_loader, raw_input, isTrain=False, silent=False):\n",
    "    tps, fps, tns, fns = 0, 0, 0, 0\n",
    "    y_ent_true_all, y_ent_pred_all = [], []\n",
    "    y_rel_true_all, y_rel_pred_all = [], []\n",
    "    print_every_batch = 5\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(data_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            ent_loss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN))\n",
    "            ent_output = ent_argmax(ent_output, batchsize)\n",
    "\n",
    "            rel_loss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "            rel_output = rel_argmax(rel_output, batchsize)\n",
    "\n",
    "            \n",
    "            if not silent:\n",
    "                print()    \n",
    "                print(\"Entity loss : %.4f\" % ent_loss)\n",
    "                print(\"Relation loss : %.4f\" % rel_loss)\n",
    "                print()\n",
    "                print('===========================================')\n",
    "                \n",
    "#             elif step%print_every_batch==0:\n",
    "#                 print()    \n",
    "#                 print(\"Entity loss : %.4f\" % ent_loss)\n",
    "#                 print(\"Relation loss : %.4f\" % rel_loss)\n",
    "#                 print()\n",
    "#                 print('===========================================')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel = \\\n",
    "            batch_decode(ent_output, rel_output, batch_index, raw_input, batch_ent, batch_rel, silent)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            y_ent_true_all.extend(y_true_ent)\n",
    "            y_ent_pred_all.extend(y_pred_ent)\n",
    "\n",
    "            y_rel_true_all.extend(y_true_rel)\n",
    "            y_rel_pred_all.extend(y_pred_rel)\n",
    "            \n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            tns += tn\n",
    "            fns += fn\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"Entity detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_ent_true_all, y_ent_pred_all, average='micro', \n",
    "                                                  labels=range(len(schema['entity'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"Relation detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_rel_true_all, y_rel_pred_all, average='micro', \n",
    "                                              labels=range(len(schema['relation'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"ReferenceEntity+Relation score\")\n",
    "        print(\"%s \\t %s \\t %s \\t    %s %s %s %s\" % ('precision ', 'recall ', 'fbeta_score ', 'tp', 'fp', 'tn', 'fn'))\n",
    "        p_r_f1 = p_r_fscore(tps, fps, tns, fns)\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t\\t    %d %d %d %d' % (p_r_f1[0], p_r_f1[1], p_r_f1[2], tps, fps, tns, fns))\n",
    "\n",
    "            \n",
    "            \n",
    "def batch_decode(ent_output, rel_output, batch_index, word_lists, true_ent, true_rel, silent):\n",
    "    \n",
    "    eval_ent_list_true_l, eval_rel_list_true_l = [], []\n",
    "    eval_ent_list_pred_l, eval_rel_list_pred_l = [], []\n",
    "    \n",
    "    for e,r,i,te,tr in zip(ent_output, rel_output, batch_index, true_ent, true_rel):\n",
    "        \n",
    "        # 算句子長度\n",
    "        len_of_list = len(word_lists[i])\n",
    "        word_list = word_lists[i]\n",
    "        true_ent = index2tag(te, ix_to_ent_tag)[:len_of_list]\n",
    "        pridict_ent = index2tag(e, ix_to_ent_tag)[:len_of_list]     \n",
    "        \n",
    "        # 單句decode關係\n",
    "        true_r_list, appear_error = decode_rel(te, tr)   # true\n",
    "        pre_r_list, appear_error = decode_rel(e, r)      # predict\n",
    "        \n",
    "        true_r_list = [list(set(i)) if type(i) is list else i for i in true_r_list]\n",
    "        pre_r_list = [list(set(i)) if type(i) is list else i for i in pre_r_list]\n",
    "        \n",
    "        # 出現error，跳過這句\n",
    "        if appear_error:\n",
    "            continue\n",
    "        \n",
    "        true_r_list = true_r_list[:len_of_list]\n",
    "        pre_r_list = pre_r_list[:len_of_list]\n",
    "        \n",
    "        \n",
    "        # 評分用\n",
    "        eval_ent_list_true, err_count = decode_ent(true_ent, schema)\n",
    "        eval_rel_list_true = decode_rel_to_eval(true_r_list, schema, eval_ent_list_true)\n",
    "        \n",
    "        eval_ent_list_pred, err_count = decode_ent(pridict_ent, schema)\n",
    "        eval_rel_list_pred = decode_rel_to_eval(pre_r_list, schema, eval_ent_list_pred)\n",
    "        \n",
    "        if not silent:\n",
    "            print(word_list)\n",
    "            print(true_ent)\n",
    "            print(true_r_list)\n",
    "            print()\n",
    "            print('Predict output')\n",
    "            print(pridict_ent)\n",
    "            print(pre_r_list)\n",
    "            print()\n",
    "            print('True')\n",
    "            print(eval_ent_list_true)\n",
    "            print(eval_rel_list_true)\n",
    "            print('predict')\n",
    "            print(eval_ent_list_pred)\n",
    "            print(eval_rel_list_pred)\n",
    "            print(\"=====================================\")\n",
    "        \n",
    "        eval_ent_list_true_l.append(eval_ent_list_true)\n",
    "        eval_rel_list_true_l.append(eval_rel_list_true)\n",
    "        eval_ent_list_pred_l.append(eval_ent_list_pred)\n",
    "        eval_rel_list_pred_l.append(eval_rel_list_pred)\n",
    "    \n",
    "    \n",
    "    e_score, y_true_ent, y_pred_ent = get_scores(eval_ent_list_true_l, eval_ent_list_pred_l, \\\n",
    "                                                 range(len(schema['entity'])),output_y=True)\n",
    "    r_score, y_true_rel, y_pred_rel = get_scores(eval_rel_list_true_l, eval_rel_list_pred_l, \\\n",
    "                                                 range(len(schema['relation'])),output_y=True)\n",
    "    \n",
    "    tp, fp, tn, fn = relation_error_analysis(eval_rel_list_true_l, eval_rel_list_pred_l)\n",
    "    \n",
    "    if not silent:\n",
    "        print('Batch entity score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(e_score)\n",
    "        print()\n",
    "        print('Batch relation score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(r_score)\n",
    "        print()\n",
    "        print('p_r_fscore')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tp, fp, tn, fn), tp, fp, tn, fn)\n",
    "        print('===========================================')\n",
    "    \n",
    "    return tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def decode_ent(pred_ent, schema):\n",
    "    '''\n",
    "    Aggregate entities from predicted tags\n",
    "    Input:\n",
    "    pred_ent=a list of entity tags in a sentence\n",
    "    schema=the dictionary defining entities and relations\n",
    "    Output: \n",
    "    ent_list=[(ent_start, ent_end, ent_type=eid_in_schema)]\n",
    "    err_count=the number of bad tags\n",
    "    '''\n",
    "    ent_list = []\n",
    "    ent_start = 0\n",
    "    ent_end = 0\n",
    "    state = {\n",
    "        'ENT_SPAN': 0,\n",
    "        'NO_ENT': 1\n",
    "    }\n",
    "    err_count = 0\n",
    "    ent_type = ''\n",
    "    sid = state['NO_ENT']\n",
    "    for idx, e_tag in enumerate(pred_ent):\n",
    "        bio = e_tag[0]\n",
    "        type_tag = e_tag.split('-')[-1]\n",
    "        if sid == state['NO_ENT']:\n",
    "            if bio == 'B':\n",
    "                ent_start = idx\n",
    "                ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                sid = state['ENT_SPAN']\n",
    "            elif bio == 'I':\n",
    "                err_count += 1\n",
    "        elif sid == state['ENT_SPAN']:\n",
    "            if bio != 'I':\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                if bio == 'B':\n",
    "                    ent_start = idx\n",
    "                    ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                else:\n",
    "                    sid = state['NO_ENT']\n",
    "            elif ent_type != get_eid_from_tag(type_tag, schema):\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                err_count += 1\n",
    "                sid = state['NO_ENT']\n",
    "    if sid == state['ENT_SPAN']:\n",
    "        ent_end = len(pred_ent) - 1\n",
    "        ent_list.append((ent_start, ent_end, ent_type))\n",
    "    return ent_list, err_count\n",
    "\n",
    "def get_eid_from_tag(tag, schema):\n",
    "    '''\n",
    "    Assume schema is a dictionary in schema.txt\n",
    "    return eid or -1 if no match is found\n",
    "    '''\n",
    "    for content in schema['entity'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['eid']\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def decode_rel_to_eval(r_list, schema, ent_list):\n",
    "    \n",
    "    max_pair = 0\n",
    "    for r in r_list:\n",
    "        if type(r) is list:\n",
    "            for single_r in r:\n",
    "                if int(single_r[-3])>max_pair:\n",
    "                    max_pair = int(single_r[-3])\n",
    "    \n",
    "\n",
    "    pair_idx = {}\n",
    "    for pair in range(max_pair+1):\n",
    "        for i, r in enumerate(r_list):\n",
    "            if type(r) is list:\n",
    "                for single_r in r:\n",
    "                    if int(single_r[-3])==pair:\n",
    "                        if pair not in pair_idx:\n",
    "                            pair_idx[pair] = [i]\n",
    "                        else:\n",
    "                            pair_idx[pair].append(i)\n",
    "    \n",
    "    \n",
    "#     # 算兩兩不同tag的數目\n",
    "#     e_type_dict = {}\n",
    "#     for e_pair in ent_list:\n",
    "#         if e_pair[-1] not in e_type_dict:\n",
    "#             e_type_dict[e_pair[-1]] = 1\n",
    "#         else:\n",
    "#             e_type_dict[e_pair[-1]] += 1\n",
    "    \n",
    "#     total_pair = 0\n",
    "#     e_type_l = list(e_type_dict.values())\n",
    "#     for i, ent_type_num_1 in enumerate(e_type_l):\n",
    "#         for j, ent_type_num_2 in enumerate(e_type_l[i+1:]):\n",
    "#             pair_num = ent_type_num_1*ent_type_num_2\n",
    "#             total_pair += pair_num\n",
    "\n",
    "    pair_list = []\n",
    "    for i, e_pair_1 in enumerate(ent_list):\n",
    "        for j, e_pair_2 in enumerate(ent_list[i+1:]):\n",
    "            if e_pair_1[-1]!=e_pair_2[-1]:\n",
    "                pair_list.append([e_pair_1, e_pair_2])\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    eval_rel_list = []\n",
    "    for pair in pair_idx:\n",
    "        rel_loc = pair_idx[pair]\n",
    "        for e_pairs in pair_list:\n",
    "            check_pair = True\n",
    "            first_start = e_pairs[0][0]\n",
    "            first_end = e_pairs[0][1]\n",
    "            sec_start = e_pairs[1][0]\n",
    "            sec_end = e_pairs[1][1]\n",
    "            \n",
    "            first_l = list(range(first_start, first_end+1))\n",
    "            sec_l = list(range(sec_start, sec_end+1))\n",
    "            combine_l = first_l+sec_l\n",
    "\n",
    "            \n",
    "            check_in_entity = []\n",
    "            for x in combine_l:\n",
    "                if x in rel_loc:\n",
    "                    check_in_entity.append(True)\n",
    "                else:\n",
    "                    check_in_entity.append(False)\n",
    "                    check_pair = False\n",
    "                    break             \n",
    "\n",
    "            if all(check_in_entity)==True:\n",
    "                for r in r_list[first_start]:\n",
    "                    r_info = r.split('-')\n",
    "                    \n",
    "                    if int(r_info[1])==pair:\n",
    "                        r_tag = get_rid_from_tag(r_info[0], schema)\n",
    "                        e_pairs_copy = e_pairs\n",
    "                        e_pairs_copy.append(r_tag)\n",
    "                        eval_rel_list.append(tuple(e_pairs_copy))\n",
    "    \n",
    "    return eval_rel_list\n",
    "    \n",
    "        \n",
    "def get_rid_from_tag(tag, schema):   \n",
    "    for content in schema['relation'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['rid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rel_info(ent_output):\n",
    "    r_list = []     # 存放完整關係\n",
    "    r_dict = {}     # 記錄關係資訊\n",
    "    appear_error = False\n",
    "\n",
    "    pred_ent = index2tag(ent_output, ix_to_ent_tag)\n",
    "    \n",
    "\n",
    "    e_loc = 0       # 當前遇到的entity的位置\n",
    "    for loc, e in enumerate(pred_ent):\n",
    "        if e[0]=='B':\n",
    "            e_loc = loc\n",
    "            r_dict[loc] = {\n",
    "                '_2ndtag':e[2:],\n",
    "                'end':loc,\n",
    "            }\n",
    "            r_list.append([])\n",
    "                   \n",
    "        elif e[0]=='I':\n",
    "            # 錯誤來自於，entity預測錯誤，沒有預測到B tag，直接跳到I tag\n",
    "            # 所以沒有紀錄e_loc\n",
    "            try: \n",
    "                r_dict[e_loc]['end'] = loc\n",
    "            except KeyError:\n",
    "                appear_error = True\n",
    "                break\n",
    "            \n",
    "            r_list.append([])\n",
    "            \n",
    "        else:\n",
    "            r_list.append(\"\")\n",
    "              \n",
    "    return r_list, r_dict, appear_error\n",
    "        \n",
    "        \n",
    "def decode_rel(ent_output, rel_output):\n",
    "\n",
    "    r_list, r_dict, appear_error = create_rel_info(ent_output) \n",
    "    \n",
    "    IsB = False           # 是否遇到B tag的lock\n",
    "    IsNext = False        # 是否為B tag後面的tag 的lock\n",
    "    num_reocrd = -1       # 紀錄pair數\n",
    "    now_loc = 0\n",
    "    pre_rel_end_loc = 0\n",
    "    now_rel_end_loc = 0\n",
    "    \n",
    "    rel_keyerror = False\n",
    "    \n",
    "    for now in range(len(rel_output)):\n",
    "        for loc, rel in enumerate(rel_output[now][:now+1]):\n",
    "            rel = rel.cpu().numpy()\n",
    "            \n",
    "#             print(rel, IsB, IsNext)\n",
    "            \n",
    "            # 有關係存在，且為B tag \n",
    "            if rel!=rel_tag_to_ix[REL_NONE] and IsB==False and IsNext==False:\n",
    "\n",
    "                IsB = True\n",
    "                IsNext = True\n",
    "                tag = ix_to_rel_tag[int(rel)]\n",
    "                num_reocrd+=1\n",
    "                now_loc = loc\n",
    "                \n",
    "                # 錯誤來自於，now_loc找不到，也就是說，rel預測出來是有關係存在\n",
    "                # 但預測是'O'\n",
    "                # 而在entity中卻沒有預測出來，所以r_dict中沒有紀錄\n",
    "                try:\n",
    "                    pre_rel_end_loc = r_dict[now_loc]['end']\n",
    "\n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    now_rel_end_loc = r_dict[now]['end']\n",
    "                    \n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                second_tag = r_dict[now_loc]['_2ndtag']\n",
    "                preAorB = check_rel_loc(second_tag, schema)\n",
    "                nowAorB = 'B' if preAorB=='A' else 'A'\n",
    "                \n",
    "                pre_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+preAorB\n",
    "                now_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+nowAorB\n",
    "                \n",
    "                # 將以前的token填上關係\n",
    "                for token in range(now_loc, pre_rel_end_loc+1):\n",
    "                    \n",
    "                    # 出現以下error\n",
    "                    '''AttributeError: 'str' object has no attribute 'append'''\n",
    "                    # 為 r_list 前處理中沒有給予可能有關係的位置空的list\n",
    "                    try:\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "                    except AttributeError:\n",
    "                        r_list[token] = []\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "\n",
    "             \n",
    "                # 當前token填上關係\n",
    "                r_list[now].append(now_complete_rel)\n",
    "                \n",
    "\n",
    "            \n",
    "            # 關係前位中B tag後面的tag\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsB:\n",
    "                # 如果還在這個entity的範圍內\n",
    "                if loc<=pre_rel_end_loc:\n",
    "                    pass\n",
    "                \n",
    "                # 超出現在這個entity的範圍，改lock\n",
    "                else:\n",
    "                    IsB = False\n",
    "\n",
    "            \n",
    "            # B tag後面的tag的關係，依照前面的關係複製\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsNext:\n",
    "                r_list[now] = r_list[now-1]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if now<=now_rel_end_loc:\n",
    "                    IsB = False\n",
    "                else:\n",
    "                    IsB = False\n",
    "                    IsNext = False\n",
    "\n",
    "        \n",
    "        if rel_keyerror:\n",
    "            rel_keyerror = False\n",
    "            break\n",
    "                \n",
    "                \n",
    "    return r_list, appear_error\n",
    "                \n",
    "\n",
    "# 是三元關係中的前者還是後者                  \n",
    "def check_rel_loc(second_tag, schema):\n",
    "    convert_tag = ''\n",
    "\n",
    "    for ent_content in schema['entity']:\n",
    "        if schema['entity'][ent_content]['tag']==second_tag:\n",
    "            convert_tag = ent_content\n",
    "    \n",
    "    rel_types = schema['relation'].values()\n",
    "\n",
    "    for rel_content in schema['relation'].values():\n",
    "        for AorB in rel_content['arguments']:\n",
    "            if rel_content['arguments'][AorB]==convert_tag:\n",
    "                return AorB\n",
    "            \n",
    "\n",
    "            \n",
    "def get_scores(true_lists, pred_lists, labels, output_y=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for t_list, p_list in zip(true_lists, pred_lists):\n",
    "        yt, yp = align_yt_yp(t_list, p_list, labels)\n",
    "        y_true.extend(yt)\n",
    "        y_pred.extend(yp)\n",
    "        \n",
    "    scores = precision_recall_fscore_support(y_true, y_pred, average='micro', labels=labels)\n",
    "    return scores, y_true, y_pred if output_y else scores\n",
    "\n",
    "def align_yt_yp(truths, predictions, labels):\n",
    "    '''\n",
    "    Input:\n",
    "        truths/predictions: list of true and predicted tuples, \n",
    "        with the leading entries as the structure and the last entry as the class,\n",
    "        e.g., [(e1, e2, rel), ...]\n",
    "        labels: sequence of valid class\n",
    "    Output:\n",
    "        yt: list of true class given a structure\n",
    "        yp: list of predicted class given a structure\n",
    "    '''\n",
    "    yt, yp = [], []\n",
    "    _ID_NONE = len(labels)\n",
    "    true_dict = { t[:-1]: t[-1] for t in truths }\n",
    "    for p in predictions:\n",
    "        yt.append(true_dict.pop(p[:-1], _ID_NONE))\n",
    "        yp.append(p[-1])\n",
    "    for target in true_dict.values():\n",
    "        yt.append(target)\n",
    "        yp.append(_ID_NONE)\n",
    "    return yt, yp\n",
    "\n",
    "\n",
    "\n",
    "def is_neg_triple(t):\n",
    "    return np.imag(t[-1]) > 0\n",
    "\n",
    "def negate_triple(t):\n",
    "    # Mark negative triples with imaginary relation id\n",
    "    return (t[0], t[1], np.real(t[-1]).item() + 1j)\n",
    "\n",
    "def posit_triple(t):\n",
    "    return (t[0], t[1], np.real(t[-1]).item())\n",
    "\n",
    "def has_edge(base_ptrs, rel, e):\n",
    "    '''\n",
    "    Assume a relation exist between an entity pair, \n",
    "    if all the tokens in the base entity point to those in entity e.\n",
    "    '''\n",
    "    tok_has_ptr_to_e = [tok_ptrs[rel].ge(e[0]).dot(tok_ptrs[rel].le(e[1])).item() > 0 \n",
    "                        for tok_ptrs in base_ptrs]\n",
    "    return len(tok_has_ptr_to_e) > 0 and all(tok_has_ptr_to_e)\n",
    "\n",
    "\n",
    "def relation_error_analysis(true_rel_lists, rel_lists):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, r_list in enumerate(rel_lists):\n",
    "        true_pos = len([t for t in r_list if t in true_rel_lists[i]])\n",
    "        all_true = len([t for t in true_rel_lists[i] if not is_neg_triple(t)])\n",
    "        all_pos = len(r_list)\n",
    "        tp += true_pos\n",
    "        fn += all_true - true_pos\n",
    "        fp += all_pos - true_pos\n",
    "        tn += len([t for t in true_rel_lists[i] if is_neg_triple(t) and posit_triple(t) not in r_list])\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def p_r_fscore(tp, fp, tn, fn, beta=1, eps=1e-8):\n",
    "    p = tp / (tp + fp + eps)\n",
    "    r = tp / (tp + fn + eps)\n",
    "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r + eps))\n",
    "    return p, r, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.1128\n",
      "Relation loss : 0.0019\n",
      "\n",
      "===========================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[((25, 27, 1), (48, 49, 0), 0)]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[((17, 18, 0), (29, 32, 1), 0)]\n",
      "=====================================\n",
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(6, 7, 0), (29, 30, 0), (43, 47, 1)]\n",
      "[((6, 7, 0), (43, 47, 1), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[((15, 18, 1), (30, 31, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0), ((10, 14, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[((2, 3, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 11, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 11, 1), (23, 24, 0), 0), ((7, 11, 1), (36, 37, 0), 0)]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8333333333333334, 0.9615384615384616, 0.8928571428571429, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.35714285714285715, 0.7142857142857143, 0.4761904761904762, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3571428568877551, 0.7142857132653061, 0.47619047129251707) 5 9 0 2\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1021\n",
      "Relation loss : 0.0017\n",
      "\n",
      "===========================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[((5, 7, 1), (29, 30, 0), 0)]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[((29, 30, 0), (37, 38, 1), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((21, 22, 0), (25, 26, 1), 0), ((25, 26, 1), (32, 33, 0), 0)]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8888888888888888, 0.9696969696969697, 0.927536231884058, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6153846153846154, 0.8888888888888888, 0.7272727272727274, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6153846149112425, 0.8888888879012344, 0.7272727217768595) 8 5 0 1\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1018\n",
      "Relation loss : 0.0016\n",
      "\n",
      "===========================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], [], '']\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 51, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (9, 13, 1)]\n",
      "[((2, 3, 0), (9, 13, 1), 0)]\n",
      "=====================================\n",
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (49, 52, 1)]\n",
      "[((9, 10, 0), (49, 52, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7, 0.875, 0.7777777777777777, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5, 0.6666666666666666, 0.5714285714285715, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.49999999875, 0.6666666644444444, 0.5714285648979592) 2 2 0 1\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.842 \t\t 0.955 \t\t 0.895 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.484 \t\t 0.789 \t\t 0.600 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.484 \t\t 0.789 \t\t 0.600 \t\t    15 16 0 4\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = root+'facial_r2.test'\n",
    "input_test, ent_test, rel_test, raw_index_test, raw_input_test = dev_preprocess(test_data)\n",
    "test_loader = dataload(input_test, ent_test, rel_test, raw_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.832 \t\t 0.912 \t\t 0.870 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.537 \t\t 0.824 \t\t 0.651 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.537 \t\t 0.824 \t\t 0.651 \t\t    108 93 0 23\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_train():\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "    criterion_rel = nn.NLLLoss()\n",
    "    \n",
    "    n_iters = 10\n",
    "    print_every = 12\n",
    "\n",
    "    train_entloss_l = []\n",
    "    val_entloss_l = []\n",
    "    train_relloss_l = []\n",
    "    val_relloss_l = []\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for epoch in tqdm(range(n_iters)):  \n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "            batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "\n",
    "            entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "            relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "            loss = entloss+relloss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        train_entloss_l.append(entloss.cpu())\n",
    "        train_relloss_l.append(relloss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "            val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "\n",
    "        val_entloss_l.append(val_entloss.cpu())\n",
    "        val_relloss_l.append(val_relloss.cpu())\n",
    "\n",
    "        \n",
    "        \n",
    "        evaluate_data(loader, raw_input, isTrain=True, silent=True)\n",
    "        \n",
    "        print()\n",
    "        print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "              % (epoch+1, entloss, relloss, loss))\n",
    "        print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "              % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.1161\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 11, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 11, 1), (23, 24, 0), 0), ((7, 11, 1), (36, 37, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[((25, 27, 1), (48, 49, 0), 0)]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], [], '']\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 51, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', [], [], '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7878787878787878, 0.896551724137931, 0.8387096774193549, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6, 0.6666666666666666, 0.631578947368421, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5999999993999999, 0.6666666659259258, 0.6315789417174515) 6 4 0 3\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1200\n",
      "Relation loss : 0.0019\n",
      "\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[((29, 30, 0), (37, 38, 1), 0)]\n",
      "=====================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (9, 13, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n",
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(6, 7, 0), (29, 30, 0), (43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0), ((10, 14, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8387096774193549, 1.0, 0.9122807017543859, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.625, 0.7142857142857143, 0.6666666666666666, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6249999992187499, 0.7142857132653061, 0.6666666608) 5 3 0 2\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0028\n",
      "Relation loss : 0.0028\n",
      "\n",
      "===========================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(1.0, 1.0, 1.0, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.75, 1.0, 0.8571428571428571, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7499999981250001, 0.9999999966666667, 0.8571428497959185) 3 1 0 0\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.842 \t\t 0.955 \t\t 0.895 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.636 \t\t 0.737 \t\t 0.683 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.636 \t\t 0.737 \t\t 0.683 \t\t    14 8 0 5\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.832 \t\t 0.912 \t\t 0.870 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.727 \t\t 0.832 \t\t 0.776 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.727 \t\t 0.832 \t\t 0.776 \t\t    109 41 0 22\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=False, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 37, 297)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_var), len(input_dev), len(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
