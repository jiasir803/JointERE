{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def schema_load(schema_root):\n",
    "    raw_dict = \"\".join(readfile(schema_root))\n",
    "    dict2json = \"\".join(raw_dict.split()[2:])\n",
    "\n",
    "    json_acceptable_string = dict2json.replace(\"'\", \"\\\"\")\n",
    "    schema = json.loads(json_acceptable_string)\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def define_entity(schema):\n",
    "    tag_type = list(schema['tagging'])\n",
    "    \n",
    "    entity_tag = []\n",
    "    for k in list(schema['entity'].keys()):\n",
    "        entity_tag.append(schema['entity'][k]['tag'])\n",
    "        \n",
    "    TAG = []\n",
    "    for t in tag_type:\n",
    "        for e in entity_tag:\n",
    "            if t!='O':\n",
    "                TAG.append(t+'-'+e)  \n",
    "                \n",
    "    TAG = [UNKOWN_TAG, PAD_TAG] + TAG + ['O']   \n",
    "\n",
    "    return TAG\n",
    "\n",
    "def tag2ix(TAG):\n",
    "    tag_to_ix={t:i for i,t in enumerate(TAG)}\n",
    "    return tag_to_ix\n",
    "\n",
    "def define_relation(schema):\n",
    "    relation_type = list(schema['relation'])\n",
    "    \n",
    "    relation_tag = []\n",
    "    for k in list(schema['relation'].keys()):\n",
    "        relation_tag.append(schema['relation'][k]['tag'])\n",
    "    \n",
    "    relation_tag = [REL_PAD] + [REL_NONE] + relation_tag\n",
    "        \n",
    "    return relation_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_set = word_set.split()\n",
    "        if len(word_set)==1:\n",
    "            word_list.append(' ')\n",
    "            ent_list.append('O')\n",
    "            rel_list.append(REL_NONE)\n",
    "        \n",
    "        else:\n",
    "            word_list.append(word_set[0])\n",
    "            ent_list.append(word_set[1])\n",
    "\n",
    "            try:\n",
    "                testerror = word_set[2]\n",
    "            except IndexError:\n",
    "                rel_list.append(REL_NONE)\n",
    "            else:\n",
    "                rel_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "\n",
    "    for now_token, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, ents, rels = get_word_and_label(content, init, now_token)\n",
    "            init = now_token+1\n",
    "            word_list.append(words)\n",
    "            ent_list.append(ents)\n",
    "            rel_list.append(rels)\n",
    "            \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, ent_list, rel_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_ent = list(ent_list[i] for i in reserved_index)\n",
    "    filter_rel = list(rel_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_ent, filter_rel\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq, isrel):\n",
    "    if isrel:\n",
    "        seq += [REL_NONE for i in range(MAX_LEN-len(seq))]\n",
    "    else:\n",
    "        seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_ent, filter_rel):\n",
    "    input_padded = [pad_seq(s, False) for s in filter_word]\n",
    "    ent_padded = [pad_seq(s, False) for s in filter_ent]\n",
    "    rel_padded = [pad_seq(s, True) for s in filter_rel]\n",
    "    \n",
    "    return input_padded, ent_padded, rel_padded\n",
    "\n",
    "def deep_copy_lists(filter_word, filter_ent, filter_rel):\n",
    "    f_w = copy.deepcopy(filter_word)\n",
    "    f_e = copy.deepcopy(filter_ent)\n",
    "    f_r = copy.deepcopy(filter_rel)\n",
    "    \n",
    "    return f_w, f_e, f_r\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "\n",
    "\n",
    "def prepare_rel(rel_padded, to_ix):\n",
    "    \n",
    "    rel_ptr = torch.zeros(len(rel_padded), MAX_LEN, MAX_LEN, dtype=torch.long) \n",
    "    \n",
    "    # 對當前的token，去比較之前所有出現過的entity，是否有關係，建成矩陣\n",
    "    # [B*ML*ML]，第二維ML是當前token，第三維ML是根據當前token對之前出現過的entity紀錄關係，以index紀錄\n",
    "    for i, rel_seq in enumerate(rel_padded):\n",
    "        rel_dict = {}\n",
    "        for j, token_seq in enumerate(rel_seq):\n",
    "            rel_ptr[i][j][:j+1] = 1\n",
    "            if token_seq != REL_NONE:\n",
    "                for k, rel in enumerate(token_seq):\n",
    "\n",
    "                    # if 是第一次出現，紀錄後面數字(標第幾對)和關係位置(A OR B)\n",
    "                    # 假如下次出現又是同個關係位置(A)，依然紀錄\n",
    "                    # 直到下次出現關係位置B，依照之前紀錄的A位置的字，然後在第三維去標關係\n",
    "\n",
    "                    rel_token = rel.split('-')\n",
    "                    if rel_token[1] not in rel_dict:\n",
    "                        rel_dict[rel_token[1]] = {'rel':rel_token[0], 'loc':rel_token[2], 'idx':[j]}\n",
    "\n",
    "                    elif rel_token[1] in rel_dict and rel_dict[rel_token[1]]['loc']==rel_token[2]:\n",
    "                        rel_dict[rel_token[1]]['idx'].append(j)\n",
    "\n",
    "                    else:\n",
    "                        record_loc = rel_dict[rel_token[1]]['idx']\n",
    "                        for idxx in record_loc:\n",
    "                            rel_ptr[i][j][idxx] = to_ix[rel_token[0]]\n",
    "                            \n",
    "    return rel_ptr\n",
    "                \n",
    "\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def dataload(input_var, ent_var, rel_var, raw_input):\n",
    "    torch_dataset = Data.TensorDataset(input_var, ent_var, rel_var, raw_input)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=0,       \n",
    "#         drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_entity(entity):\n",
    "    entity = entity.view(BATCH_SIZE,ent_size).argmax(1)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output, rel_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        self.rel_size = rel_size\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.w2 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(self.attn_output, self.rel_size, bias=False)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        \n",
    "        decoder = encoder_outputs[:,-1,:].unsqueeze(1)                       #B*1*(ts+LE) [128,1,8]\n",
    "        encoder_score = self.w1(encoder_outputs)                             #B*now len*ATTN_OUT\n",
    "        decoder_score = self.w2(decoder)                                     #B*1*ATTN_OUT\n",
    "        energy = self.tanh(encoder_score+decoder_score)                      #B*now len*ATTN_OUT            \n",
    "        \n",
    "        energy = self.v(energy)                                              #B*now len*rel_size\n",
    "        \n",
    "        \n",
    "        # 針對每個entity做softmax，去顯示他們的關係權重\n",
    "        # 主要都會是rel_none\n",
    "        # 對第二維(rel)做softmax\n",
    "        p = self.softmax(energy)                                         #B*now len*rel_size\n",
    "        \n",
    "        return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, ent_tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim, rel_tag_to_ix):\n",
    "        \n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.ent_to_ix = ent_tag_to_ix\n",
    "        self.ent_size = len(ent_tag_to_ix)                   #es\n",
    "        self.rel_to_ix = rel_tag_to_ix\n",
    "        self.rel_size = len(rel_tag_to_ix)                   #rs           \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim1, momentum=0.5, affine=False)\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "#                             num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)        \n",
    "        self.bilstm = nn.GRU(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.ent_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.ent_size, self.label_embed_dim)\n",
    "        \n",
    "        self.attn = Attn(ATTN_IN, ATTN_OUT, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, self.batch, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(self.batch, self.hidden_dim2)              #B*h2\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(self.batch, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_entity(self):\n",
    "        output_tensor = torch.zeros(self.batch, MAX_LEN, self.ent_size)  #B*ML*es\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "    \n",
    "    def create_rel_matrix(self):\n",
    "        rel_tensor = torch.zeros(self.batch, MAX_LEN, MAX_LEN, self.rel_size)  #B*ML*ML*rs\n",
    "        return rel_tensor.cuda()if USE_CUDA else rel_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, batch_ent, isTrain=True):\n",
    "        \n",
    "        self.batch = sentence.size(0)\n",
    "#         self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        entity_tensor = self.create_entity()                    #B*ML*es\n",
    "        rel_tensor = self.create_rel_matrix()                   #B*ML*ML*rs\n",
    "        \n",
    "        \n",
    "\n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "#         bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        bilstm_out, hidden1 = self.bilstm(embeds)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        # bn\n",
    "        bilstm_out = self.bn(bilstm_out)\n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence_l = [] \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            \n",
    "            if length==0:\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*es,[128, 5]            \n",
    "            ent_output = self.softmax(to_tags)                               #B*es,[128, 5]  \n",
    "            s_ent_output = self.softmax_entity(ent_output)\n",
    "            ent_onehot = self.one_hot(s_ent_output)\n",
    "            \n",
    "            \n",
    "            if isTrain:\n",
    "                label = self.label_embed(ent_onehot)                             #B*LE,[128, 3]\n",
    "#                 label = self.label_embed(ent_output) \n",
    "            else:\n",
    "                batch_ent_onehot = self.one_hot(batch_ent[:,length])\n",
    "                label = self.label_embed(batch_ent_onehot)\n",
    "            \n",
    "     \n",
    "            \n",
    "            # Assignments to Variables are in-place operations.\n",
    "            # Use that variable in lots of other contexts \n",
    "            # and some of the functions require it to not change. \n",
    "            to_tags_clone = to_tags.clone()\n",
    "            label_clone = label.clone()\n",
    "            \n",
    "            \n",
    "#             for i, tag in enumerate(s_ent_output):\n",
    "#                 if tag==ent_tag_to_ix['O']:\n",
    "#                     to_tags_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "#                     label_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "                    \n",
    "            # relation layer\n",
    "#             encoder_sequence_l.append(torch.cat((to_tags,label),1)) \n",
    "            encoder_sequence_l.append(torch.cat((h_next,label),1))  \n",
    "            encoder_sequence = torch.stack(encoder_sequence_l).t()     #B*len*(es+LE), [128,1,8]          \n",
    "\n",
    "            # Calculate attention weights \n",
    "            attn_weights = self.attn(encoder_sequence)\n",
    "\n",
    "        \n",
    "            entity_tensor[:,length,:] = ent_output\n",
    "            \n",
    "            # rel_tensor[:,length, 頭~當前 ,:]\n",
    "            rel_tensor[:,length,:length+1,:] = attn_weights\n",
    "\n",
    "        \n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return entity_tensor.view(self.batch*MAX_LEN, self.ent_size), \\\n",
    "               rel_tensor.view(self.batch*MAX_LEN*MAX_LEN, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def softmax_entity(self, entity):\n",
    "        entity = entity.view(self.batch,ent_size).argmax(1)\n",
    "        return entity\n",
    "    \n",
    "    \n",
    "    def one_hot(self, batch_ent):   \n",
    "        batchsize = batch_ent.size(0)\n",
    "        nb_digits = len(ent_tag_to_ix)\n",
    "        batch_ent = torch.unsqueeze(batch_ent, 1)\n",
    "        y_onehot = torch.cuda.FloatTensor(batchsize, nb_digits)        \n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, batch_ent, 1)    \n",
    "\n",
    "        return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "\n",
    "# schema_root = root+'schema_2.txt'\n",
    "# relation_data = root+'facial_r3.train'\n",
    "# dev_data = root+'facial_r3.dev'\n",
    "# test_data = root+'skincare.dev'\n",
    "\n",
    "schema_root = root+'schema_2.txt'\n",
    "relation_data = root+'facial_r3_len60.train'\n",
    "dev_data = root+'facial_r3_len60.dev'\n",
    "test_data = root+'facial_r3_len60.test'\n",
    "\n",
    "# schema_root = root+'schema_2.txt'\n",
    "# relation_data = root+'facial_r3_len70.train'\n",
    "# dev_data = root+'facial_r3_len70.dev'\n",
    "# test_data = root+'facial_r3_len70.test'\n",
    "\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "REL_NONE = 'Rel-None'\n",
    "REL_PAD = 'Rel-Pad'\n",
    "\n",
    "schema = schema_load(schema_root)\n",
    "ENT_TAG = define_entity(schema)\n",
    "REL_TAG = define_relation(schema)\n",
    "ent_tag_to_ix = tag2ix(ENT_TAG)\n",
    "'''{'<PAD>': 1,\n",
    " '<UNKNOWN>': 0,\n",
    " 'B-FUNC': 2,\n",
    " 'B-STAT': 3,\n",
    " 'I-FUNC': 4,\n",
    " 'I-STAT': 5,\n",
    " 'O': 6}'''\n",
    "rel_tag_to_ix = tag2ix(REL_TAG)\n",
    "'''{'ApplyTo': 2, 'Rel-None': 1, 'Rel-Pad': 0}'''\n",
    "\n",
    "# ========hyper-parameter-set==========\n",
    "\n",
    "ent_size = len(ent_tag_to_ix)\n",
    "rel_size = len(rel_tag_to_ix)\n",
    "MAX_LEN = 60     # original 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "EMBEDDING_DIM = 40   # original 20\n",
    "HIDDEN_DIM1 = 20     # original 10\n",
    "HIDDEN_DIM2 = 16     # original 8\n",
    "LABEL_EMBED_DIM = ent_size\n",
    "DENSE_OUT = 100\n",
    "\n",
    "# ATTN_IN = ent_size+LABEL_EMBED_DIM\n",
    "ATTN_IN = HIDDEN_DIM2+LABEL_EMBED_DIM\n",
    "ATTN_OUT = 6        # original 6       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    content = readfile(data)\n",
    "    word_list, ent_list, rel_list = split_to_list(content)\n",
    "    word_to_ix = word2index(word_list)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    #================================================\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, vocab_size, word_to_ix, reserved_index, word_list\n",
    "\n",
    "def dev_preprocess(dev_data):\n",
    "    dev_content = readfile(dev_data)\n",
    "    word_list, ent_list, rel_list = split_to_list(dev_content)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, reserved_index, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_ent_tag = dict_inverse(ent_tag_to_ix)\n",
    "ix_to_rel_tag = dict_inverse(rel_tag_to_ix)\n",
    "#===============================================\n",
    "input_var, ent_var, rel_var, vocab_size, word_to_ix, raw_index, raw_input = preprocess(relation_data)\n",
    "loader = dataload(input_var, ent_var, rel_var, raw_index)\n",
    "\n",
    "input_dev, ent_dev, rel_dev, raw_index_dev, raw_input_dev = dev_preprocess(dev_data)\n",
    "dev_loader = dataload(input_dev, ent_dev, rel_dev, raw_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "# criterion_rel = nn.NLLLoss(ignore_index=rel_tag_to_ix[REL_PAD])\n",
    "criterion_rel = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:03<11:59,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | ent loss 0.6318 | rel loss 0.0825 | total loss 0.7142\n",
      "         | val ent loss 0.6162 | val rel loss 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/200 [00:07<11:58,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | ent loss 0.4092 | rel loss 0.0265 | total loss 0.4356\n",
      "         | val ent loss 0.3290 | val rel loss 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/200 [00:10<11:59,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | ent loss 0.2881 | rel loss 0.0169 | total loss 0.3050\n",
      "         | val ent loss 0.2323 | val rel loss 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/200 [00:14<12:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | ent loss 0.2076 | rel loss 0.0145 | total loss 0.2221\n",
      "         | val ent loss 0.1432 | val rel loss 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 5/200 [00:18<11:55,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | ent loss 0.2105 | rel loss 0.0150 | total loss 0.2255\n",
      "         | val ent loss 0.2137 | val rel loss 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/200 [00:22<11:52,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | ent loss 0.1301 | rel loss 0.0155 | total loss 0.1456\n",
      "         | val ent loss 0.2243 | val rel loss 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 7/200 [00:25<11:48,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | ent loss 0.1867 | rel loss 0.0109 | total loss 0.1976\n",
      "         | val ent loss 0.2031 | val rel loss 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/200 [00:28<11:30,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | ent loss 0.0787 | rel loss 0.0142 | total loss 0.0929\n",
      "         | val ent loss 0.0591 | val rel loss 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/200 [00:31<11:12,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | ent loss 0.0814 | rel loss 0.0125 | total loss 0.0938\n",
      "         | val ent loss 0.0583 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 10/200 [00:34<10:57,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | ent loss 0.0618 | rel loss 0.0117 | total loss 0.0735\n",
      "          | val ent loss 0.0351 | val rel loss 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 11/200 [00:38<10:58,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | ent loss 0.0228 | rel loss 0.0108 | total loss 0.0336\n",
      "          | val ent loss 0.2213 | val rel loss 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 12/200 [00:42<10:58,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | ent loss 0.0354 | rel loss 0.0107 | total loss 0.0461\n",
      "          | val ent loss 0.0134 | val rel loss 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 13/200 [00:45<10:57,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | ent loss 0.1139 | rel loss 0.0110 | total loss 0.1249\n",
      "          | val ent loss 0.1328 | val rel loss 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 14/200 [00:49<10:55,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | ent loss 0.0217 | rel loss 0.0105 | total loss 0.0323\n",
      "          | val ent loss 0.0553 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 15/200 [00:53<10:54,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | ent loss 0.0221 | rel loss 0.0079 | total loss 0.0301\n",
      "          | val ent loss 0.1222 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 16/200 [00:56<10:51,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | ent loss 0.0112 | rel loss 0.0079 | total loss 0.0190\n",
      "          | val ent loss 0.0562 | val rel loss 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 17/200 [01:00<10:47,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | ent loss 0.0171 | rel loss 0.0055 | total loss 0.0226\n",
      "          | val ent loss 0.0083 | val rel loss 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 18/200 [01:03<10:43,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | ent loss 0.0737 | rel loss 0.0052 | total loss 0.0789\n",
      "          | val ent loss 0.2131 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 19/200 [01:05<10:25,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | ent loss 0.0276 | rel loss 0.0072 | total loss 0.0347\n",
      "          | val ent loss 0.0462 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 20/200 [01:08<10:12,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | ent loss 0.0710 | rel loss 0.0042 | total loss 0.0752\n",
      "          | val ent loss 0.0105 | val rel loss 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 21/200 [01:11<10:11,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | ent loss 0.0215 | rel loss 0.0045 | total loss 0.0261\n",
      "          | val ent loss 0.0055 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 22/200 [01:15<10:09,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | ent loss 0.0081 | rel loss 0.0047 | total loss 0.0129\n",
      "          | val ent loss 0.0508 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 23/200 [01:18<10:07,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | ent loss 0.0189 | rel loss 0.0051 | total loss 0.0239\n",
      "          | val ent loss 0.1486 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 24/200 [01:22<10:04,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | ent loss 0.0282 | rel loss 0.0043 | total loss 0.0325\n",
      "          | val ent loss 0.1816 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 25/200 [01:26<10:02,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | ent loss 0.0067 | rel loss 0.0040 | total loss 0.0108\n",
      "          | val ent loss 0.0593 | val rel loss 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 26/200 [01:29<09:59,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | ent loss 0.0065 | rel loss 0.0029 | total loss 0.0094\n",
      "          | val ent loss 0.1048 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 27/200 [01:33<09:57,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | ent loss 0.0076 | rel loss 0.0037 | total loss 0.0113\n",
      "          | val ent loss 0.0035 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 28/200 [01:36<09:54,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | ent loss 0.0036 | rel loss 0.0025 | total loss 0.0061\n",
      "          | val ent loss 0.4330 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 29/200 [01:40<09:51,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | ent loss 0.0107 | rel loss 0.0018 | total loss 0.0125\n",
      "          | val ent loss 0.0047 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 30/200 [01:44<09:49,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | ent loss 0.0236 | rel loss 0.0043 | total loss 0.0279\n",
      "          | val ent loss 0.2222 | val rel loss 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 31/200 [01:47<09:46,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | ent loss 0.0050 | rel loss 0.0028 | total loss 0.0078\n",
      "          | val ent loss 0.0916 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 32/200 [01:51<09:42,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | ent loss 0.0029 | rel loss 0.0031 | total loss 0.0060\n",
      "          | val ent loss 0.2113 | val rel loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 33/200 [01:54<09:40,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | ent loss 0.0024 | rel loss 0.0022 | total loss 0.0046\n",
      "          | val ent loss 0.0205 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 34/200 [01:58<09:37,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | ent loss 0.0028 | rel loss 0.0021 | total loss 0.0049\n",
      "          | val ent loss 0.2527 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 35/200 [02:01<09:34,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | ent loss 0.0078 | rel loss 0.0036 | total loss 0.0113\n",
      "          | val ent loss 0.0017 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 36/200 [02:04<09:28,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | ent loss 0.0039 | rel loss 0.0018 | total loss 0.0057\n",
      "          | val ent loss 0.0049 | val rel loss 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 37/200 [02:06<09:18,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | ent loss 0.0032 | rel loss 0.0027 | total loss 0.0059\n",
      "          | val ent loss 0.0479 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 38/200 [02:08<09:08,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | ent loss 0.0030 | rel loss 0.0029 | total loss 0.0059\n",
      "          | val ent loss 0.0552 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 39/200 [02:10<08:59,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | ent loss 0.0281 | rel loss 0.0022 | total loss 0.0303\n",
      "          | val ent loss 0.0030 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 40/200 [02:12<08:50,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | ent loss 0.0018 | rel loss 0.0018 | total loss 0.0036\n",
      "          | val ent loss 0.0174 | val rel loss 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 41/200 [02:14<08:42,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | ent loss 0.0025 | rel loss 0.0017 | total loss 0.0041\n",
      "          | val ent loss 0.0058 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 42/200 [02:16<08:34,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | ent loss 0.0051 | rel loss 0.0018 | total loss 0.0069\n",
      "          | val ent loss 0.1364 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 43/200 [02:18<08:26,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | ent loss 0.0031 | rel loss 0.0024 | total loss 0.0055\n",
      "          | val ent loss 0.0130 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 44/200 [02:20<08:19,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | ent loss 0.0042 | rel loss 0.0024 | total loss 0.0066\n",
      "          | val ent loss 0.1518 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 45/200 [02:22<08:11,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | ent loss 0.0073 | rel loss 0.0026 | total loss 0.0099\n",
      "          | val ent loss 0.0494 | val rel loss 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 46/200 [02:24<08:04,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | ent loss 0.0047 | rel loss 0.0029 | total loss 0.0076\n",
      "          | val ent loss 0.0037 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 47/200 [02:26<07:57,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | ent loss 0.0378 | rel loss 0.0030 | total loss 0.0408\n",
      "          | val ent loss 0.0520 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 48/200 [02:28<07:51,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | ent loss 0.0027 | rel loss 0.0017 | total loss 0.0044\n",
      "          | val ent loss 0.0533 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 49/200 [02:30<07:45,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | ent loss 0.0109 | rel loss 0.0021 | total loss 0.0130\n",
      "          | val ent loss 0.0024 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 50/200 [02:34<07:43,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 | ent loss 0.0048 | rel loss 0.0023 | total loss 0.0071\n",
      "          | val ent loss 0.1764 | val rel loss 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 51/200 [02:37<07:41,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 | ent loss 0.0414 | rel loss 0.0018 | total loss 0.0432\n",
      "          | val ent loss 0.0147 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 52/200 [02:41<07:39,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 | ent loss 0.0032 | rel loss 0.0015 | total loss 0.0046\n",
      "          | val ent loss 0.0168 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 53/200 [02:44<07:37,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 | ent loss 0.0023 | rel loss 0.0021 | total loss 0.0044\n",
      "          | val ent loss 0.0812 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 54/200 [02:48<07:35,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 | ent loss 0.0020 | rel loss 0.0027 | total loss 0.0047\n",
      "          | val ent loss 0.1928 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 55/200 [02:51<07:33,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 | ent loss 0.0248 | rel loss 0.0016 | total loss 0.0264\n",
      "          | val ent loss 0.1007 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 56/200 [02:55<07:31,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 | ent loss 0.0019 | rel loss 0.0015 | total loss 0.0034\n",
      "          | val ent loss 0.5755 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 57/200 [02:59<07:29,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 | ent loss 0.0028 | rel loss 0.0018 | total loss 0.0046\n",
      "          | val ent loss 0.0919 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 58/200 [03:02<07:26,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 | ent loss 0.0014 | rel loss 0.0015 | total loss 0.0029\n",
      "          | val ent loss 0.1256 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 59/200 [03:06<07:24,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 | ent loss 0.0015 | rel loss 0.0013 | total loss 0.0027\n",
      "          | val ent loss 0.2812 | val rel loss 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 60/200 [03:09<07:22,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 | ent loss 0.0042 | rel loss 0.0020 | total loss 0.0062\n",
      "          | val ent loss 0.0017 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 61/200 [03:13<07:19,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 | ent loss 0.0012 | rel loss 0.0012 | total loss 0.0024\n",
      "          | val ent loss 0.2046 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 62/200 [03:16<07:17,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 | ent loss 0.0023 | rel loss 0.0013 | total loss 0.0035\n",
      "          | val ent loss 0.0216 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 63/200 [03:19<07:14,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 | ent loss 0.0018 | rel loss 0.0014 | total loss 0.0032\n",
      "          | val ent loss 0.0035 | val rel loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 64/200 [03:23<07:12,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 | ent loss 0.0079 | rel loss 0.0018 | total loss 0.0097\n",
      "          | val ent loss 0.0047 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 65/200 [03:27<07:10,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 | ent loss 0.0083 | rel loss 0.0015 | total loss 0.0097\n",
      "          | val ent loss 0.0043 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 66/200 [03:30<07:07,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 | ent loss 0.0033 | rel loss 0.0013 | total loss 0.0046\n",
      "          | val ent loss 0.0029 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 67/200 [03:34<07:05,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 | ent loss 0.0015 | rel loss 0.0011 | total loss 0.0027\n",
      "          | val ent loss 0.1371 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 68/200 [03:37<07:03,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 | ent loss 0.0014 | rel loss 0.0025 | total loss 0.0039\n",
      "          | val ent loss 0.0258 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 69/200 [03:41<07:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 | ent loss 0.0033 | rel loss 0.0018 | total loss 0.0052\n",
      "          | val ent loss 0.1566 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 70/200 [03:45<06:58,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 | ent loss 0.0022 | rel loss 0.0016 | total loss 0.0038\n",
      "          | val ent loss 0.0572 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 71/200 [03:48<06:55,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71 | ent loss 0.0017 | rel loss 0.0014 | total loss 0.0031\n",
      "          | val ent loss 0.0027 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 72/200 [03:52<06:53,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 | ent loss 0.0038 | rel loss 0.0014 | total loss 0.0052\n",
      "          | val ent loss 0.0035 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 73/200 [03:55<06:50,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 | ent loss 0.0020 | rel loss 0.0014 | total loss 0.0034\n",
      "          | val ent loss 0.3196 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 74/200 [03:59<06:47,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 | ent loss 0.0024 | rel loss 0.0020 | total loss 0.0043\n",
      "          | val ent loss 0.0024 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 75/200 [04:03<06:45,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 | ent loss 0.0027 | rel loss 0.0012 | total loss 0.0039\n",
      "          | val ent loss 0.2200 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 76/200 [04:06<06:42,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76 | ent loss 0.0012 | rel loss 0.0013 | total loss 0.0025\n",
      "          | val ent loss 0.1173 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 77/200 [04:10<06:39,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 | ent loss 0.0014 | rel loss 0.0017 | total loss 0.0031\n",
      "          | val ent loss 0.0342 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 78/200 [04:13<06:36,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78 | ent loss 0.0010 | rel loss 0.0010 | total loss 0.0020\n",
      "          | val ent loss 0.0121 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 79/200 [04:17<06:33,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 | ent loss 0.0013 | rel loss 0.0012 | total loss 0.0026\n",
      "          | val ent loss 0.1182 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 80/200 [04:20<06:31,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80 | ent loss 0.0015 | rel loss 0.0019 | total loss 0.0034\n",
      "          | val ent loss 0.0012 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 81/200 [04:24<06:28,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81 | ent loss 0.1291 | rel loss 0.0044 | total loss 0.1335\n",
      "          | val ent loss 0.2339 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 82/200 [04:28<06:25,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82 | ent loss 0.0047 | rel loss 0.0034 | total loss 0.0081\n",
      "          | val ent loss 0.0291 | val rel loss 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 83/200 [04:31<06:22,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83 | ent loss 0.0053 | rel loss 0.0014 | total loss 0.0066\n",
      "          | val ent loss 0.1046 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 84/200 [04:35<06:20,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 | ent loss 0.0415 | rel loss 0.0021 | total loss 0.0436\n",
      "          | val ent loss 0.1578 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 85/200 [04:38<06:17,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85 | ent loss 0.0145 | rel loss 0.0016 | total loss 0.0161\n",
      "          | val ent loss 0.0016 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 86/200 [04:42<06:14,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86 | ent loss 0.0028 | rel loss 0.0013 | total loss 0.0041\n",
      "          | val ent loss 0.2513 | val rel loss 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 87/200 [04:46<06:11,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 | ent loss 0.0266 | rel loss 0.0013 | total loss 0.0278\n",
      "          | val ent loss 0.3463 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 88/200 [04:49<06:08,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88 | ent loss 0.0055 | rel loss 0.0016 | total loss 0.0071\n",
      "          | val ent loss 0.0742 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 89/200 [04:53<06:05,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89 | ent loss 0.0028 | rel loss 0.0009 | total loss 0.0037\n",
      "          | val ent loss 0.1546 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 90/200 [04:56<06:02,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90 | ent loss 0.0013 | rel loss 0.0012 | total loss 0.0026\n",
      "          | val ent loss 0.1890 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 91/200 [05:00<05:59,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 | ent loss 0.0011 | rel loss 0.0008 | total loss 0.0019\n",
      "          | val ent loss 0.0032 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 92/200 [05:03<05:56,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 | ent loss 0.0009 | rel loss 0.0013 | total loss 0.0022\n",
      "          | val ent loss 0.1605 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 93/200 [05:07<05:53,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93 | ent loss 0.0019 | rel loss 0.0016 | total loss 0.0034\n",
      "          | val ent loss 0.0915 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 94/200 [05:11<05:50,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 | ent loss 0.0295 | rel loss 0.0015 | total loss 0.0310\n",
      "          | val ent loss 0.0006 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 95/200 [05:14<05:47,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 | ent loss 0.0041 | rel loss 0.0020 | total loss 0.0061\n",
      "          | val ent loss 0.0195 | val rel loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 96/200 [05:17<05:44,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96 | ent loss 0.0033 | rel loss 0.0017 | total loss 0.0049\n",
      "          | val ent loss 0.3664 | val rel loss 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 97/200 [05:21<05:41,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 | ent loss 0.0012 | rel loss 0.0014 | total loss 0.0025\n",
      "          | val ent loss 0.0009 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 98/200 [05:25<05:38,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98 | ent loss 0.0011 | rel loss 0.0014 | total loss 0.0025\n",
      "          | val ent loss 0.3927 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 99/200 [05:28<05:35,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 | ent loss 0.0011 | rel loss 0.0008 | total loss 0.0019\n",
      "          | val ent loss 0.1981 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 100/200 [05:32<05:32,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 | ent loss 0.0024 | rel loss 0.0014 | total loss 0.0038\n",
      "           | val ent loss 0.0375 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 101/200 [05:35<05:28,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 101 | ent loss 0.0010 | rel loss 0.0011 | total loss 0.0021\n",
      "           | val ent loss 0.0157 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 102/200 [05:38<05:25,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 102 | ent loss 0.0009 | rel loss 0.0009 | total loss 0.0018\n",
      "           | val ent loss 0.0009 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 103/200 [05:42<05:22,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103 | ent loss 0.0015 | rel loss 0.0011 | total loss 0.0026\n",
      "           | val ent loss 0.0046 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 104/200 [05:45<05:18,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 104 | ent loss 0.0012 | rel loss 0.0009 | total loss 0.0021\n",
      "           | val ent loss 0.0007 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 105/200 [05:48<05:15,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 105 | ent loss 0.0038 | rel loss 0.0014 | total loss 0.0052\n",
      "           | val ent loss 0.2225 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 106/200 [05:50<05:10,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106 | ent loss 0.0062 | rel loss 0.0016 | total loss 0.0078\n",
      "           | val ent loss 0.1504 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 107/200 [05:53<05:07,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 | ent loss 0.0016 | rel loss 0.0010 | total loss 0.0026\n",
      "           | val ent loss 0.0041 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 108/200 [05:57<05:04,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108 | ent loss 0.0034 | rel loss 0.0014 | total loss 0.0048\n",
      "           | val ent loss 0.0027 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 109/200 [06:00<05:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109 | ent loss 0.0114 | rel loss 0.0010 | total loss 0.0124\n",
      "           | val ent loss 0.2232 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 110/200 [06:03<04:57,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 110 | ent loss 0.0088 | rel loss 0.0018 | total loss 0.0106\n",
      "           | val ent loss 0.0809 | val rel loss 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 111/200 [06:06<04:54,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 111 | ent loss 0.0109 | rel loss 0.0019 | total loss 0.0128\n",
      "           | val ent loss 0.0051 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 112/200 [06:10<04:50,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 | ent loss 0.0033 | rel loss 0.0011 | total loss 0.0043\n",
      "           | val ent loss 0.2134 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 113/200 [06:13<04:47,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113 | ent loss 0.0080 | rel loss 0.0021 | total loss 0.0102\n",
      "           | val ent loss 0.1440 | val rel loss 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 114/200 [06:17<04:44,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 114 | ent loss 0.0027 | rel loss 0.0012 | total loss 0.0039\n",
      "           | val ent loss 0.0253 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 115/200 [06:20<04:41,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115 | ent loss 0.0014 | rel loss 0.0011 | total loss 0.0024\n",
      "           | val ent loss 0.0033 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 116/200 [06:24<04:38,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116 | ent loss 0.0018 | rel loss 0.0011 | total loss 0.0028\n",
      "           | val ent loss 0.0020 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 117/200 [06:27<04:34,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 117 | ent loss 0.0054 | rel loss 0.0016 | total loss 0.0070\n",
      "           | val ent loss 0.0026 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 118/200 [06:30<04:31,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118 | ent loss 0.0019 | rel loss 0.0012 | total loss 0.0031\n",
      "           | val ent loss 0.0719 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 119/200 [06:34<04:28,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119 | ent loss 0.0010 | rel loss 0.0017 | total loss 0.0026\n",
      "           | val ent loss 0.0040 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 120/200 [06:37<04:25,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120 | ent loss 0.0039 | rel loss 0.0017 | total loss 0.0056\n",
      "           | val ent loss 0.0239 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 121/200 [06:41<04:22,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121 | ent loss 0.0295 | rel loss 0.0013 | total loss 0.0308\n",
      "           | val ent loss 0.4753 | val rel loss 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 122/200 [06:45<04:18,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 122 | ent loss 0.0220 | rel loss 0.0017 | total loss 0.0237\n",
      "           | val ent loss 0.4041 | val rel loss 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 123/200 [06:48<04:15,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 123 | ent loss 0.0028 | rel loss 0.0014 | total loss 0.0042\n",
      "           | val ent loss 0.0024 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 124/200 [06:52<04:12,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124 | ent loss 0.0251 | rel loss 0.0015 | total loss 0.0266\n",
      "           | val ent loss 0.0011 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 125/200 [06:55<04:09,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 125 | ent loss 0.0017 | rel loss 0.0018 | total loss 0.0035\n",
      "           | val ent loss 0.4975 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 126/200 [06:59<04:06,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 126 | ent loss 0.0011 | rel loss 0.0010 | total loss 0.0020\n",
      "           | val ent loss 0.2495 | val rel loss 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 127/200 [07:02<04:03,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127 | ent loss 0.0014 | rel loss 0.0013 | total loss 0.0027\n",
      "           | val ent loss 0.0105 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 128/200 [07:06<03:59,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 128 | ent loss 0.0022 | rel loss 0.0013 | total loss 0.0036\n",
      "           | val ent loss 0.0462 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 129/200 [07:10<03:56,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 129 | ent loss 0.0007 | rel loss 0.0008 | total loss 0.0015\n",
      "           | val ent loss 0.0005 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 130/200 [07:13<03:53,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130 | ent loss 0.0143 | rel loss 0.0023 | total loss 0.0167\n",
      "           | val ent loss 0.0039 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 131/200 [07:17<03:50,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 131 | ent loss 0.0007 | rel loss 0.0012 | total loss 0.0020\n",
      "           | val ent loss 0.0160 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 132/200 [07:21<03:47,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132 | ent loss 0.0009 | rel loss 0.0008 | total loss 0.0017\n",
      "           | val ent loss 0.2996 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 133/200 [07:24<03:44,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133 | ent loss 0.0015 | rel loss 0.0023 | total loss 0.0039\n",
      "           | val ent loss 0.0017 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 134/200 [07:28<03:40,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 134 | ent loss 0.0013 | rel loss 0.0013 | total loss 0.0026\n",
      "           | val ent loss 0.2639 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 135/200 [07:31<03:37,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135 | ent loss 0.0013 | rel loss 0.0014 | total loss 0.0027\n",
      "           | val ent loss 0.4649 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 136/200 [07:35<03:34,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136 | ent loss 0.0010 | rel loss 0.0016 | total loss 0.0026\n",
      "           | val ent loss 0.1503 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 137/200 [07:39<03:31,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137 | ent loss 0.0009 | rel loss 0.0012 | total loss 0.0021\n",
      "           | val ent loss 0.0034 | val rel loss 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 138/200 [07:42<03:27,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138 | ent loss 0.0070 | rel loss 0.0011 | total loss 0.0080\n",
      "           | val ent loss 0.0015 | val rel loss 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 139/200 [07:46<03:24,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 139 | ent loss 0.0006 | rel loss 0.0011 | total loss 0.0017\n",
      "           | val ent loss 0.1188 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 140/200 [07:49<03:21,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140 | ent loss 0.0062 | rel loss 0.0012 | total loss 0.0074\n",
      "           | val ent loss 0.6229 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 141/200 [07:53<03:18,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 141 | ent loss 0.0017 | rel loss 0.0007 | total loss 0.0024\n",
      "           | val ent loss 0.0453 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 142/200 [07:57<03:14,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 142 | ent loss 0.0012 | rel loss 0.0009 | total loss 0.0021\n",
      "           | val ent loss 0.0471 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 143/200 [08:00<03:11,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143 | ent loss 0.0012 | rel loss 0.0014 | total loss 0.0027\n",
      "           | val ent loss 0.1514 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 144/200 [08:04<03:08,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 144 | ent loss 0.0010 | rel loss 0.0015 | total loss 0.0025\n",
      "           | val ent loss 0.0052 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 145/200 [08:07<03:05,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 145 | ent loss 0.0008 | rel loss 0.0014 | total loss 0.0022\n",
      "           | val ent loss 0.2489 | val rel loss 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 146/200 [08:11<03:01,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 146 | ent loss 0.0072 | rel loss 0.0017 | total loss 0.0090\n",
      "           | val ent loss 0.0734 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 147/200 [08:14<02:58,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 147 | ent loss 0.0095 | rel loss 0.0012 | total loss 0.0108\n",
      "           | val ent loss 0.0005 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 148/200 [08:18<02:55,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 148 | ent loss 0.0019 | rel loss 0.0009 | total loss 0.0027\n",
      "           | val ent loss 0.0586 | val rel loss 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 149/200 [08:21<02:51,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 149 | ent loss 0.0106 | rel loss 0.0007 | total loss 0.0113\n",
      "           | val ent loss 0.0024 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 150/200 [08:25<02:48,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150 | ent loss 0.0012 | rel loss 0.0006 | total loss 0.0018\n",
      "           | val ent loss 0.1722 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 151/200 [08:28<02:44,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 151 | ent loss 0.0033 | rel loss 0.0010 | total loss 0.0043\n",
      "           | val ent loss 0.0034 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 152/200 [08:32<02:41,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 152 | ent loss 0.0020 | rel loss 0.0006 | total loss 0.0025\n",
      "           | val ent loss 0.0008 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 153/200 [08:35<02:38,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 153 | ent loss 0.0062 | rel loss 0.0010 | total loss 0.0071\n",
      "           | val ent loss 0.1749 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 154/200 [08:39<02:35,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 154 | ent loss 0.0056 | rel loss 0.0013 | total loss 0.0069\n",
      "           | val ent loss 0.1966 | val rel loss 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 155/200 [08:42<02:31,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 | ent loss 0.0127 | rel loss 0.0025 | total loss 0.0153\n",
      "           | val ent loss 0.1760 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 156/200 [08:46<02:28,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 156 | ent loss 0.0086 | rel loss 0.0014 | total loss 0.0100\n",
      "           | val ent loss 0.0044 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 157/200 [08:49<02:25,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 157 | ent loss 0.0046 | rel loss 0.0017 | total loss 0.0063\n",
      "           | val ent loss 0.0027 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 158/200 [08:53<02:21,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 158 | ent loss 0.0115 | rel loss 0.0012 | total loss 0.0126\n",
      "           | val ent loss 0.0045 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 159/200 [08:57<02:18,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 159 | ent loss 0.0010 | rel loss 0.0018 | total loss 0.0028\n",
      "           | val ent loss 0.0005 | val rel loss 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 160/200 [09:00<02:15,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160 | ent loss 0.0008 | rel loss 0.0009 | total loss 0.0016\n",
      "           | val ent loss 0.0008 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 161/200 [09:04<02:11,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 161 | ent loss 0.0014 | rel loss 0.0010 | total loss 0.0024\n",
      "           | val ent loss 0.0058 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 162/200 [09:07<02:08,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 162 | ent loss 0.0013 | rel loss 0.0009 | total loss 0.0022\n",
      "           | val ent loss 0.1499 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 163/200 [09:11<02:05,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 163 | ent loss 0.0007 | rel loss 0.0012 | total loss 0.0019\n",
      "           | val ent loss 0.0653 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 164/200 [09:14<02:01,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164 | ent loss 0.0016 | rel loss 0.0011 | total loss 0.0028\n",
      "           | val ent loss 0.0049 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 165/200 [09:16<01:58,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 165 | ent loss 0.0018 | rel loss 0.0006 | total loss 0.0024\n",
      "           | val ent loss 0.0192 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 166/200 [09:18<01:54,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 166 | ent loss 0.0060 | rel loss 0.0012 | total loss 0.0072\n",
      "           | val ent loss 0.0039 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 167/200 [09:20<01:50,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 167 | ent loss 0.0013 | rel loss 0.0014 | total loss 0.0026\n",
      "           | val ent loss 0.0195 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 168/200 [09:22<01:47,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 168 | ent loss 0.0013 | rel loss 0.0010 | total loss 0.0023\n",
      "           | val ent loss 0.0013 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 169/200 [09:24<01:43,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 169 | ent loss 0.0013 | rel loss 0.0008 | total loss 0.0021\n",
      "           | val ent loss 0.0009 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 170/200 [09:26<01:39,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 | ent loss 0.0069 | rel loss 0.0011 | total loss 0.0081\n",
      "           | val ent loss 0.0030 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 171/200 [09:28<01:36,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 171 | ent loss 0.0013 | rel loss 0.0007 | total loss 0.0020\n",
      "           | val ent loss 0.0016 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 172/200 [09:30<01:32,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 172 | ent loss 0.0010 | rel loss 0.0011 | total loss 0.0022\n",
      "           | val ent loss 0.0461 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 173/200 [09:32<01:29,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 173 | ent loss 0.0021 | rel loss 0.0011 | total loss 0.0033\n",
      "           | val ent loss 0.1719 | val rel loss 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 174/200 [09:34<01:25,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 174 | ent loss 0.0014 | rel loss 0.0013 | total loss 0.0027\n",
      "           | val ent loss 0.1731 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 175/200 [09:36<01:22,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175 | ent loss 0.0175 | rel loss 0.0013 | total loss 0.0188\n",
      "           | val ent loss 0.2047 | val rel loss 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 176/200 [09:38<01:18,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 176 | ent loss 0.0265 | rel loss 0.0010 | total loss 0.0275\n",
      "           | val ent loss 0.0103 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 177/200 [09:40<01:15,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 177 | ent loss 0.0022 | rel loss 0.0017 | total loss 0.0039\n",
      "           | val ent loss 0.0264 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 178/200 [09:42<01:11,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 178 | ent loss 0.0030 | rel loss 0.0015 | total loss 0.0044\n",
      "           | val ent loss 0.0026 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 179/200 [09:44<01:08,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 179 | ent loss 0.0025 | rel loss 0.0013 | total loss 0.0038\n",
      "           | val ent loss 0.1421 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 180/200 [09:46<01:05,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180 | ent loss 0.0013 | rel loss 0.0008 | total loss 0.0021\n",
      "           | val ent loss 0.0032 | val rel loss 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 181/200 [09:48<01:01,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181 | ent loss 0.0011 | rel loss 0.0011 | total loss 0.0022\n",
      "           | val ent loss 0.0009 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 182/200 [09:50<00:58,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 182 | ent loss 0.0010 | rel loss 0.0013 | total loss 0.0022\n",
      "           | val ent loss 0.2431 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 183/200 [09:52<00:55,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 183 | ent loss 0.0096 | rel loss 0.0015 | total loss 0.0111\n",
      "           | val ent loss 0.0023 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 184/200 [09:54<00:51,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 184 | ent loss 0.0114 | rel loss 0.0012 | total loss 0.0126\n",
      "           | val ent loss 0.0006 | val rel loss 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 185/200 [09:56<00:48,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 | ent loss 0.0103 | rel loss 0.0016 | total loss 0.0119\n",
      "           | val ent loss 0.3544 | val rel loss 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 186/200 [09:59<00:45,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 186 | ent loss 0.0076 | rel loss 0.0026 | total loss 0.0102\n",
      "           | val ent loss 0.1713 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 187/200 [10:01<00:41,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 187 | ent loss 0.0040 | rel loss 0.0017 | total loss 0.0057\n",
      "           | val ent loss 0.0313 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 188/200 [10:03<00:38,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 188 | ent loss 0.0230 | rel loss 0.0014 | total loss 0.0244\n",
      "           | val ent loss 0.0048 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 189/200 [10:05<00:35,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 189 | ent loss 0.0210 | rel loss 0.0009 | total loss 0.0219\n",
      "           | val ent loss 0.0023 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 190/200 [10:07<00:31,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 190 | ent loss 0.0022 | rel loss 0.0013 | total loss 0.0035\n",
      "           | val ent loss 0.0968 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 191/200 [10:09<00:28,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191 | ent loss 0.0390 | rel loss 0.0018 | total loss 0.0408\n",
      "           | val ent loss 0.1993 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 192/200 [10:11<00:25,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 192 | ent loss 0.0013 | rel loss 0.0007 | total loss 0.0020\n",
      "           | val ent loss 0.0022 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 193/200 [10:13<00:22,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 193 | ent loss 0.0012 | rel loss 0.0006 | total loss 0.0018\n",
      "           | val ent loss 0.0018 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 194/200 [10:15<00:19,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 194 | ent loss 0.0009 | rel loss 0.0008 | total loss 0.0017\n",
      "           | val ent loss 0.0022 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 195/200 [10:17<00:15,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195 | ent loss 0.0336 | rel loss 0.0014 | total loss 0.0350\n",
      "           | val ent loss 0.0005 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 196/200 [10:19<00:12,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 196 | ent loss 0.0021 | rel loss 0.0023 | total loss 0.0044\n",
      "           | val ent loss 0.0005 | val rel loss 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 197/200 [10:21<00:09,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 197 | ent loss 0.0016 | rel loss 0.0014 | total loss 0.0030\n",
      "           | val ent loss 0.1389 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 198/200 [10:23<00:06,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 198 | ent loss 0.0022 | rel loss 0.0006 | total loss 0.0029\n",
      "           | val ent loss 0.1709 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 199/200 [10:25<00:03,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199 | ent loss 0.0007 | rel loss 0.0010 | total loss 0.0018\n",
      "           | val ent loss 0.0005 | val rel loss 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 200/200 [10:27<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200 | ent loss 0.0012 | rel loss 0.0008 | total loss 0.0020\n",
      "           | val ent loss 0.0006 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 200\n",
    "print_every = 12\n",
    "\n",
    "train_entloss_l = []\n",
    "val_entloss_l = []\n",
    "train_relloss_l = []\n",
    "val_relloss_l = []\n",
    "\n",
    "loss = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(n_iters)):  \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "        batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "        \n",
    "        entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "        relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "        loss = entloss+relloss\n",
    "        \n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    train_entloss_l.append(entloss.cpu())\n",
    "    train_relloss_l.append(relloss.cpu())\n",
    "    #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "        \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "        model.eval()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "        val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "        \n",
    "    val_entloss_l.append(val_entloss.cpu())\n",
    "    val_relloss_l.append(val_relloss.cpu())\n",
    "    \n",
    "    \n",
    "    print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "          % (epoch+1, entloss, relloss, loss))\n",
    "    print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "          % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "torch.save(model.state_dict(), 'relation_extraction_1_new.pkl')\n",
    "\n",
    "# model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "#               LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "# model.load_state_dict(torch.load('relation_extraction.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_entloss_l, label='train_ent_loss')\n",
    "plt.plot(val_entloss_l, label='val_ent_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entity Loss\") \n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_relloss_l, label='train_rel_loss')\n",
    "plt.plot(val_relloss_l, label='val_rel_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relation Loss\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_choose(input_var):\n",
    "    r_choose = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        r_choose.append(random.randint(0,len(input_var)))\n",
    "    return r_choose\n",
    "        \n",
    "def ent_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,ent_size).argmax(2)\n",
    "    return output\n",
    "\n",
    "def rel_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,MAX_LEN,rel_size).argmax(3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check predictions after training\n",
    "# with torch.no_grad():\n",
    "#     r_choose = random_choose(input_var)\n",
    "#     model.eval()\n",
    "#     ent_output, rel_output = model(input_var[r_choose].cuda() if USE_CUDA else input_var, batch_ent.cuda() \\\n",
    "#                                        if USE_CUDA else batch_ent, isTrain=True)\n",
    "    \n",
    "#     batchsize = input_var[r_choose].size(0)\n",
    "    \n",
    "#     ent_loss = criterion_tag(ent_output.cpu(), ent_var[r_choose].view(BATCH_SIZE*MAX_LEN))\n",
    "#     ent_output = ent_argmax(ent_output, batchsize)\n",
    "    \n",
    "#     rel_loss = criterion_rel(rel_output.cpu(), rel_var[r_choose].view(BATCH_SIZE*MAX_LEN*MAX_LEN))\n",
    "    \n",
    "#     print()\n",
    "#     print('predict :', index2tag(ent_output[0], ix_to_ent_tag))\n",
    "#     print('true :', index2tag(ent_var[r_choose[0]], ix_to_ent_tag))\n",
    "    \n",
    "#     print()\n",
    "#     print(\"Entity loss : %.4f\" % ent_loss)\n",
    "#     print(\"Relation loss : %.4f\" % rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "def evaluate_data(data_loader, raw_input, isTrain=False, silent=False):\n",
    "    tps, fps, tns, fns = 0, 0, 0, 0\n",
    "    y_ent_true_all, y_ent_pred_all = [], []\n",
    "    y_rel_true_all, y_rel_pred_all = [], []\n",
    "    print_every_batch = 5\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(data_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            ent_loss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN))\n",
    "            ent_output = ent_argmax(ent_output, batchsize)\n",
    "\n",
    "            rel_loss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "            rel_output = rel_argmax(rel_output, batchsize)\n",
    "\n",
    "            \n",
    "            if not silent:\n",
    "                print()    \n",
    "                print(\"Entity loss : %.4f\" % ent_loss)\n",
    "                print(\"Relation loss : %.4f\" % rel_loss)\n",
    "                print()\n",
    "                print('===========================================')\n",
    "                \n",
    "#             elif step%print_every_batch==0:\n",
    "#                 print()    \n",
    "#                 print(\"Entity loss : %.4f\" % ent_loss)\n",
    "#                 print(\"Relation loss : %.4f\" % rel_loss)\n",
    "#                 print()\n",
    "#                 print('===========================================')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel = \\\n",
    "            batch_decode(ent_output, rel_output, batch_index, raw_input, batch_ent, batch_rel, silent)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            y_ent_true_all.extend(y_true_ent)\n",
    "            y_ent_pred_all.extend(y_pred_ent)\n",
    "\n",
    "            y_rel_true_all.extend(y_true_rel)\n",
    "            y_rel_pred_all.extend(y_pred_rel)\n",
    "            \n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            tns += tn\n",
    "            fns += fn\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"Entity detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_ent_true_all, y_ent_pred_all, average='micro', \n",
    "                                                  labels=range(len(schema['entity'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"Relation detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_rel_true_all, y_rel_pred_all, average='micro', \n",
    "                                              labels=range(len(schema['relation'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"ReferenceEntity+Relation score\")\n",
    "        print(\"%s \\t %s \\t %s \\t    %s %s %s %s\" % ('precision ', 'recall ', 'fbeta_score ', 'tp', 'fp', 'tn', 'fn'))\n",
    "        p_r_f1 = p_r_fscore(tps, fps, tns, fns)\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t\\t    %d %d %d %d' % (p_r_f1[0], p_r_f1[1], p_r_f1[2], tps, fps, tns, fns))\n",
    "\n",
    "            \n",
    "            \n",
    "def batch_decode(ent_output, rel_output, batch_index, word_lists, true_ent, true_rel, silent):\n",
    "    \n",
    "    eval_ent_list_true_l, eval_rel_list_true_l = [], []\n",
    "    eval_ent_list_pred_l, eval_rel_list_pred_l = [], []\n",
    "    \n",
    "    for e,r,i,te,tr in zip(ent_output, rel_output, batch_index, true_ent, true_rel):\n",
    "        \n",
    "        # 算句子長度\n",
    "        len_of_list = len(word_lists[i])\n",
    "        word_list = word_lists[i]\n",
    "        true_ent = index2tag(te, ix_to_ent_tag)[:len_of_list]\n",
    "        pridict_ent = index2tag(e, ix_to_ent_tag)[:len_of_list]     \n",
    "        \n",
    "        # 單句decode關係\n",
    "        true_r_list, appear_error = decode_rel(te, tr)   # true\n",
    "        pre_r_list, appear_error = decode_rel(e, r)      # predict\n",
    "        \n",
    "        true_r_list = [list(set(i)) if type(i) is list else i for i in true_r_list]\n",
    "        pre_r_list = [list(set(i)) if type(i) is list else i for i in pre_r_list]\n",
    "        \n",
    "        # 出現error，跳過這句\n",
    "        if appear_error:\n",
    "            continue\n",
    "        \n",
    "        true_r_list = true_r_list[:len_of_list]\n",
    "        pre_r_list = pre_r_list[:len_of_list]\n",
    "        \n",
    "        \n",
    "        # 評分用\n",
    "        eval_ent_list_true, err_count = decode_ent(true_ent, schema)\n",
    "        eval_rel_list_true = decode_rel_to_eval(true_r_list, schema, eval_ent_list_true)\n",
    "        \n",
    "        eval_ent_list_pred, err_count = decode_ent(pridict_ent, schema)\n",
    "        eval_rel_list_pred = decode_rel_to_eval(pre_r_list, schema, eval_ent_list_pred)\n",
    "        \n",
    "        if not silent:\n",
    "            print(word_list)\n",
    "            print(true_ent)\n",
    "            print(true_r_list)\n",
    "            print()\n",
    "            print('Predict output')\n",
    "            print(pridict_ent)\n",
    "            print(pre_r_list)\n",
    "            print()\n",
    "            print('True')\n",
    "            print(eval_ent_list_true)\n",
    "            print(eval_rel_list_true)\n",
    "            print('predict')\n",
    "            print(eval_ent_list_pred)\n",
    "            print(eval_rel_list_pred)\n",
    "            print(\"=====================================\")\n",
    "        \n",
    "        eval_ent_list_true_l.append(eval_ent_list_true)\n",
    "        eval_rel_list_true_l.append(eval_rel_list_true)\n",
    "        eval_ent_list_pred_l.append(eval_ent_list_pred)\n",
    "        eval_rel_list_pred_l.append(eval_rel_list_pred)\n",
    "    \n",
    "    \n",
    "    e_score, y_true_ent, y_pred_ent = get_scores(eval_ent_list_true_l, eval_ent_list_pred_l, \\\n",
    "                                                 range(len(schema['entity'])),output_y=True)\n",
    "    r_score, y_true_rel, y_pred_rel = get_scores(eval_rel_list_true_l, eval_rel_list_pred_l, \\\n",
    "                                                 range(len(schema['relation'])),output_y=True)\n",
    "    \n",
    "    tp, fp, tn, fn = relation_error_analysis(eval_rel_list_true_l, eval_rel_list_pred_l)\n",
    "    \n",
    "    if not silent:\n",
    "        print('Batch entity score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(e_score)\n",
    "        print()\n",
    "        print('Batch relation score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(r_score)\n",
    "        print()\n",
    "        print('p_r_fscore')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tp, fp, tn, fn), tp, fp, tn, fn)\n",
    "        print('===========================================')\n",
    "    \n",
    "    return tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def decode_ent(pred_ent, schema):\n",
    "    '''\n",
    "    Aggregate entities from predicted tags\n",
    "    Input:\n",
    "    pred_ent=a list of entity tags in a sentence\n",
    "    schema=the dictionary defining entities and relations\n",
    "    Output: \n",
    "    ent_list=[(ent_start, ent_end, ent_type=eid_in_schema)]\n",
    "    err_count=the number of bad tags\n",
    "    '''\n",
    "    ent_list = []\n",
    "    ent_start = 0\n",
    "    ent_end = 0\n",
    "    state = {\n",
    "        'ENT_SPAN': 0,\n",
    "        'NO_ENT': 1\n",
    "    }\n",
    "    err_count = 0\n",
    "    ent_type = ''\n",
    "    sid = state['NO_ENT']\n",
    "    for idx, e_tag in enumerate(pred_ent):\n",
    "        bio = e_tag[0]\n",
    "        type_tag = e_tag.split('-')[-1]\n",
    "        if sid == state['NO_ENT']:\n",
    "            if bio == 'B':\n",
    "                ent_start = idx\n",
    "                ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                sid = state['ENT_SPAN']\n",
    "            elif bio == 'I':\n",
    "                err_count += 1\n",
    "        elif sid == state['ENT_SPAN']:\n",
    "            if bio != 'I':\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                if bio == 'B':\n",
    "                    ent_start = idx\n",
    "                    ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                else:\n",
    "                    sid = state['NO_ENT']\n",
    "            elif ent_type != get_eid_from_tag(type_tag, schema):\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                err_count += 1\n",
    "                sid = state['NO_ENT']\n",
    "    if sid == state['ENT_SPAN']:\n",
    "        ent_end = len(pred_ent) - 1\n",
    "        ent_list.append((ent_start, ent_end, ent_type))\n",
    "    return ent_list, err_count\n",
    "\n",
    "def get_eid_from_tag(tag, schema):\n",
    "    '''\n",
    "    Assume schema is a dictionary in schema.txt\n",
    "    return eid or -1 if no match is found\n",
    "    '''\n",
    "    for content in schema['entity'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['eid']\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def decode_rel_to_eval(r_list, schema, ent_list):\n",
    "    \n",
    "    max_pair = 0\n",
    "    for r in r_list:\n",
    "        if type(r) is list:\n",
    "            for single_r in r:\n",
    "                if int(single_r[-3])>max_pair:\n",
    "                    max_pair = int(single_r[-3])\n",
    "    \n",
    "\n",
    "    pair_idx = {}\n",
    "    for pair in range(max_pair+1):\n",
    "        for i, r in enumerate(r_list):\n",
    "            if type(r) is list:\n",
    "                for single_r in r:\n",
    "                    if int(single_r[-3])==pair:\n",
    "                        if pair not in pair_idx:\n",
    "                            pair_idx[pair] = [i]\n",
    "                        else:\n",
    "                            pair_idx[pair].append(i)\n",
    "    \n",
    "    \n",
    "#     # 算兩兩不同tag的數目\n",
    "#     e_type_dict = {}\n",
    "#     for e_pair in ent_list:\n",
    "#         if e_pair[-1] not in e_type_dict:\n",
    "#             e_type_dict[e_pair[-1]] = 1\n",
    "#         else:\n",
    "#             e_type_dict[e_pair[-1]] += 1\n",
    "    \n",
    "#     total_pair = 0\n",
    "#     e_type_l = list(e_type_dict.values())\n",
    "#     for i, ent_type_num_1 in enumerate(e_type_l):\n",
    "#         for j, ent_type_num_2 in enumerate(e_type_l[i+1:]):\n",
    "#             pair_num = ent_type_num_1*ent_type_num_2\n",
    "#             total_pair += pair_num\n",
    "\n",
    "    pair_list = []\n",
    "    for i, e_pair_1 in enumerate(ent_list):\n",
    "        for j, e_pair_2 in enumerate(ent_list[i+1:]):\n",
    "            if e_pair_1[-1]!=e_pair_2[-1]:\n",
    "                pair_list.append([e_pair_1, e_pair_2])\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    eval_rel_list = []\n",
    "    for pair in pair_idx:\n",
    "        rel_loc = pair_idx[pair]\n",
    "        for e_pairs in pair_list:\n",
    "            check_pair = True\n",
    "            first_start = e_pairs[0][0]\n",
    "            first_end = e_pairs[0][1]\n",
    "            sec_start = e_pairs[1][0]\n",
    "            sec_end = e_pairs[1][1]\n",
    "            \n",
    "            first_l = list(range(first_start, first_end+1))\n",
    "            sec_l = list(range(sec_start, sec_end+1))\n",
    "            combine_l = first_l+sec_l\n",
    "\n",
    "            \n",
    "            check_in_entity = []\n",
    "            for x in combine_l:\n",
    "                if x in rel_loc:\n",
    "                    check_in_entity.append(True)\n",
    "                else:\n",
    "                    check_in_entity.append(False)\n",
    "                    check_pair = False\n",
    "                    break             \n",
    "\n",
    "            if all(check_in_entity)==True:\n",
    "                for r in r_list[first_start]:\n",
    "                    r_info = r.split('-')\n",
    "                    \n",
    "                    if int(r_info[1])==pair:\n",
    "                        r_tag = get_rid_from_tag(r_info[0], schema)\n",
    "                        e_pairs_copy = e_pairs\n",
    "                        e_pairs_copy.append(r_tag)\n",
    "                        eval_rel_list.append(tuple(e_pairs_copy))\n",
    "    \n",
    "    return eval_rel_list\n",
    "    \n",
    "        \n",
    "def get_rid_from_tag(tag, schema):   \n",
    "    for content in schema['relation'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['rid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rel_info(ent_output):\n",
    "    r_list = []     # 存放完整關係\n",
    "    r_dict = {}     # 記錄關係資訊\n",
    "    appear_error = False\n",
    "\n",
    "    pred_ent = index2tag(ent_output, ix_to_ent_tag)\n",
    "    \n",
    "\n",
    "    e_loc = 0       # 當前遇到的entity的位置\n",
    "    for loc, e in enumerate(pred_ent):\n",
    "        if e[0]=='B':\n",
    "            e_loc = loc\n",
    "            r_dict[loc] = {\n",
    "                '_2ndtag':e[2:],\n",
    "                'end':loc,\n",
    "            }\n",
    "            r_list.append([])\n",
    "                   \n",
    "        elif e[0]=='I':\n",
    "            # 錯誤來自於，entity預測錯誤，沒有預測到B tag，直接跳到I tag\n",
    "            # 所以沒有紀錄e_loc\n",
    "            try: \n",
    "                r_dict[e_loc]['end'] = loc\n",
    "            except KeyError:\n",
    "                appear_error = True\n",
    "                break\n",
    "            \n",
    "            r_list.append([])\n",
    "            \n",
    "        else:\n",
    "            r_list.append(\"\")\n",
    "              \n",
    "    return r_list, r_dict, appear_error\n",
    "        \n",
    "        \n",
    "def decode_rel(ent_output, rel_output):\n",
    "\n",
    "    r_list, r_dict, appear_error = create_rel_info(ent_output) \n",
    "    \n",
    "    IsB = False           # 是否遇到B tag的lock\n",
    "    IsNext = False        # 是否為B tag後面的tag 的lock\n",
    "    num_reocrd = -1       # 紀錄pair數\n",
    "    now_loc = 0\n",
    "    pre_rel_end_loc = 0\n",
    "    now_rel_end_loc = 0\n",
    "    \n",
    "    rel_keyerror = False\n",
    "    \n",
    "    for now in range(len(rel_output)):\n",
    "        for loc, rel in enumerate(rel_output[now][:now+1]):\n",
    "            rel = rel.cpu().numpy()\n",
    "            \n",
    "#             print(rel, IsB, IsNext)\n",
    "            \n",
    "            # 有關係存在，且為B tag \n",
    "            if rel!=rel_tag_to_ix[REL_NONE] and IsB==False and IsNext==False:\n",
    "\n",
    "                IsB = True\n",
    "                IsNext = True\n",
    "                tag = ix_to_rel_tag[int(rel)]\n",
    "                num_reocrd+=1\n",
    "                now_loc = loc\n",
    "                \n",
    "                # 錯誤來自於，now_loc找不到，也就是說，rel預測出來是有關係存在\n",
    "                # 但預測是'O'\n",
    "                # 而在entity中卻沒有預測出來，所以r_dict中沒有紀錄\n",
    "                try:\n",
    "                    pre_rel_end_loc = r_dict[now_loc]['end']\n",
    "\n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    now_rel_end_loc = r_dict[now]['end']\n",
    "                    \n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                second_tag = r_dict[now_loc]['_2ndtag']\n",
    "                preAorB = check_rel_loc(second_tag, schema)\n",
    "                nowAorB = 'B' if preAorB=='A' else 'A'\n",
    "                \n",
    "                pre_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+preAorB\n",
    "                now_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+nowAorB\n",
    "                \n",
    "                # 將以前的token填上關係\n",
    "                for token in range(now_loc, pre_rel_end_loc+1):\n",
    "                    \n",
    "                    # 出現以下error\n",
    "                    '''AttributeError: 'str' object has no attribute 'append'''\n",
    "                    # 為 r_list 前處理中沒有給予可能有關係的位置空的list\n",
    "                    try:\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "                    except AttributeError:\n",
    "                        r_list[token] = []\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "\n",
    "             \n",
    "                # 當前token填上關係\n",
    "                r_list[now].append(now_complete_rel)\n",
    "                \n",
    "\n",
    "            \n",
    "            # 關係前位中B tag後面的tag\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsB:\n",
    "                # 如果還在這個entity的範圍內\n",
    "                if loc<=pre_rel_end_loc:\n",
    "                    pass\n",
    "                \n",
    "                # 超出現在這個entity的範圍，改lock\n",
    "                else:\n",
    "                    IsB = False\n",
    "\n",
    "            \n",
    "            # B tag後面的tag的關係，依照前面的關係複製\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsNext:\n",
    "                r_list[now] = r_list[now-1]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if now<=now_rel_end_loc:\n",
    "                    IsB = False\n",
    "                else:\n",
    "                    IsB = False\n",
    "                    IsNext = False\n",
    "\n",
    "        \n",
    "        if rel_keyerror:\n",
    "            rel_keyerror = False\n",
    "            break\n",
    "                \n",
    "                \n",
    "    return r_list, appear_error\n",
    "                \n",
    "\n",
    "# 是三元關係中的前者還是後者                  \n",
    "def check_rel_loc(second_tag, schema):\n",
    "    convert_tag = ''\n",
    "\n",
    "    for ent_content in schema['entity']:\n",
    "        if schema['entity'][ent_content]['tag']==second_tag:\n",
    "            convert_tag = ent_content\n",
    "    \n",
    "    rel_types = schema['relation'].values()\n",
    "\n",
    "    for rel_content in schema['relation'].values():\n",
    "        for AorB in rel_content['arguments']:\n",
    "            if rel_content['arguments'][AorB]==convert_tag:\n",
    "                return AorB\n",
    "            \n",
    "\n",
    "            \n",
    "def get_scores(true_lists, pred_lists, labels, output_y=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for t_list, p_list in zip(true_lists, pred_lists):\n",
    "        yt, yp = align_yt_yp(t_list, p_list, labels)\n",
    "        y_true.extend(yt)\n",
    "        y_pred.extend(yp)\n",
    "        \n",
    "    scores = precision_recall_fscore_support(y_true, y_pred, average='micro', labels=labels)\n",
    "    return scores, y_true, y_pred if output_y else scores\n",
    "\n",
    "def align_yt_yp(truths, predictions, labels):\n",
    "    '''\n",
    "    Input:\n",
    "        truths/predictions: list of true and predicted tuples, \n",
    "        with the leading entries as the structure and the last entry as the class,\n",
    "        e.g., [(e1, e2, rel), ...]\n",
    "        labels: sequence of valid class\n",
    "    Output:\n",
    "        yt: list of true class given a structure\n",
    "        yp: list of predicted class given a structure\n",
    "    '''\n",
    "    yt, yp = [], []\n",
    "    _ID_NONE = len(labels)\n",
    "    true_dict = { t[:-1]: t[-1] for t in truths }\n",
    "    for p in predictions:\n",
    "        yt.append(true_dict.pop(p[:-1], _ID_NONE))\n",
    "        yp.append(p[-1])\n",
    "    for target in true_dict.values():\n",
    "        yt.append(target)\n",
    "        yp.append(_ID_NONE)\n",
    "    return yt, yp\n",
    "\n",
    "\n",
    "\n",
    "def is_neg_triple(t):\n",
    "    return np.imag(t[-1]) > 0\n",
    "\n",
    "def negate_triple(t):\n",
    "    # Mark negative triples with imaginary relation id\n",
    "    return (t[0], t[1], np.real(t[-1]).item() + 1j)\n",
    "\n",
    "def posit_triple(t):\n",
    "    return (t[0], t[1], np.real(t[-1]).item())\n",
    "\n",
    "def has_edge(base_ptrs, rel, e):\n",
    "    '''\n",
    "    Assume a relation exist between an entity pair, \n",
    "    if all the tokens in the base entity point to those in entity e.\n",
    "    '''\n",
    "    tok_has_ptr_to_e = [tok_ptrs[rel].ge(e[0]).dot(tok_ptrs[rel].le(e[1])).item() > 0 \n",
    "                        for tok_ptrs in base_ptrs]\n",
    "    return len(tok_has_ptr_to_e) > 0 and all(tok_has_ptr_to_e)\n",
    "\n",
    "\n",
    "def relation_error_analysis(true_rel_lists, rel_lists):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, r_list in enumerate(rel_lists):\n",
    "        true_pos = len([t for t in r_list if t in true_rel_lists[i]])\n",
    "        all_true = len([t for t in true_rel_lists[i] if not is_neg_triple(t)])\n",
    "        all_pos = len(r_list)\n",
    "        tp += true_pos\n",
    "        fn += all_true - true_pos\n",
    "        fp += all_pos - true_pos\n",
    "        tn += len([t for t in true_rel_lists[i] if is_neg_triple(t) and posit_triple(t) not in r_list])\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def p_r_fscore(tp, fp, tn, fn, beta=1, eps=1e-8):\n",
    "    p = tp / (tp + fp + eps)\n",
    "    r = tp / (tp + fn + eps)\n",
    "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r + eps))\n",
    "    return p, r, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.1585\n",
      "Relation loss : 0.0035\n",
      "\n",
      "===========================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 11, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 11, 1), (23, 24, 0), 0), ((7, 11, 1), (36, 37, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[((2, 3, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "=====================================\n",
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[((8, 12, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((21, 22, 0), (25, 26, 1), 0), ((25, 26, 1), (32, 33, 0), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8484848484848485, 0.875, 0.8615384615384615, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5, 0.6, 0.5454545454545454, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.4999999995833333, 0.5999999993999999, 0.5454545399999999) 6 6 0 4\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0719\n",
      "Relation loss : 0.0021\n",
      "\n",
      "===========================================\n",
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0), ((10, 14, 1), (35, 36, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', [], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1), (16, 17, 0)]\n",
      "[((2, 5, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'I-STAT']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', []]\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O']\n",
      "['', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1), (22, 23, 0)]\n",
      "[((4, 6, 1), (22, 23, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[((15, 18, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[((5, 7, 1), (29, 30, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[((29, 30, 0), (37, 38, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.875, 1.0, 0.9333333333333333, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.4666666666666667, 1.0, 0.6363636363636364, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.46666666635555554, 0.9999999985714286, 0.636363631446281) 7 8 0 0\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0124\n",
      "Relation loss : 0.0004\n",
      "\n",
      "===========================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(1.0, 1.0, 1.0, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.0, 0.0, 0.0) 0 0 0 0\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.864 \t\t 0.934 \t\t 0.898 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.481 \t\t 0.765 \t\t 0.591 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.481 \t\t 0.765 \t\t 0.591 \t\t    13 14 0 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "\n",
    "input_test, ent_test, rel_test, raw_index_test, raw_input_test = dev_preprocess(test_data)\n",
    "test_loader = dataload(input_test, ent_test, rel_test, raw_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.820 \t\t 0.923 \t\t 0.868 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.562 \t\t 0.792 \t\t 0.658 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.562 \t\t 0.792 \t\t 0.658 \t\t    99 77 0 26\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_train():\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "    criterion_rel = nn.NLLLoss()\n",
    "    \n",
    "    n_iters = 10\n",
    "    print_every = 12\n",
    "\n",
    "    train_entloss_l = []\n",
    "    val_entloss_l = []\n",
    "    train_relloss_l = []\n",
    "    val_relloss_l = []\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for epoch in tqdm(range(n_iters)):  \n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "            batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "\n",
    "            entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "            relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "            loss = entloss+relloss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        train_entloss_l.append(entloss.cpu())\n",
    "        train_relloss_l.append(relloss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "            val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "\n",
    "        val_entloss_l.append(val_entloss.cpu())\n",
    "        val_relloss_l.append(val_relloss.cpu())\n",
    "\n",
    "        \n",
    "        \n",
    "        evaluate_data(loader, raw_input, isTrain=True, silent=True)\n",
    "        \n",
    "        print()\n",
    "        print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "              % (epoch+1, entloss, relloss, loss))\n",
    "        print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "              % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.0877\n",
      "Relation loss : 0.0017\n",
      "\n",
      "===========================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'I-STAT']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', []]\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[((8, 12, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((21, 22, 0), (25, 26, 1), 0), ((25, 26, 1), (32, 33, 0), 0)]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.9, 0.9310344827586207, 0.9152542372881356, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7692307692307693, 0.8333333333333334, 0.8, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7692307686390532, 0.8333333326388889, 0.799999994368) 10 3 0 2\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1128\n",
      "Relation loss : 0.0029\n",
      "\n",
      "===========================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', [], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1), (16, 17, 0)]\n",
      "[((2, 5, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 11, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 11, 1), (36, 37, 0), 0)]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[((29, 30, 0), (37, 38, 1), 0)]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1), (22, 23, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0), ((10, 14, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8529411764705882, 0.9354838709677419, 0.8923076923076922, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3333333333333333, 0.6, 0.42857142857142855, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3333333329629629, 0.5999999988, 0.42857142336734694) 3 6 0 2\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1444\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6666666666666666, 1.0, 0.8, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.0, 0.0, 0.0) 0 0 0 0\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.866 \t\t 0.935 \t\t 0.899 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.591 \t\t 0.765 \t\t 0.667 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.591 \t\t 0.765 \t\t 0.667 \t\t    13 9 0 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.818 \t\t 0.923 \t\t 0.867 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.767 \t\t 0.798 \t\t 0.783 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.767 \t\t 0.798 \t\t 0.783 \t\t    99 30 0 25\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=False, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 34, 263)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_var), len(input_dev), len(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old len 70 (254, 37, 297)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
