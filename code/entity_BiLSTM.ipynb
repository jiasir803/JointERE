{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "tag_to_ix = {UNKOWN_TAG: 0, PAD_TAG:1, \"B-Func\": 2, \"I-Func\": 3, \"O\": 4}\n",
    "\n",
    "tagset_size = len(tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM1 = 10\n",
    "HIDDEN_DIM2 = 8\n",
    "LABEL_EMBED_DIM = 3\n",
    "DENSE_OUT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_list.append(word_set[0])\n",
    "        tag_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, tag_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "\n",
    "    for i, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, tags = get_word_and_label(content, init, i)\n",
    "            init = i+1\n",
    "            word_list.append(words)\n",
    "            tag_list.append(tags)\n",
    "            \n",
    "    return word_list, tag_list\n",
    "    \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, tag_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_tag = list(tag_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_tag\n",
    "\n",
    "def pad_seq(seq):\n",
    "    seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_tag):\n",
    "    input_padded = [pad_seq(s) for s in filter_word]\n",
    "    target_padded = [pad_seq(s) for s in filter_tag]\n",
    "    \n",
    "    return input_padded, target_padded\n",
    "\n",
    "#======================================\n",
    "def dataload(input_var, target_var):\n",
    "    torch_dataset = Data.TensorDataset(input_var, target_var)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=2,       \n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim):\n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.label_embed_dim = label_embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(DENSE_OUT+label_embed_dim, hidden_dim2, batch_first=True)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.tagset_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.tagset_size, self.label_embed_dim)\n",
    "        \n",
    "#         self.hidden1 = self.init_hidden1()\n",
    "#         self.hidden2 = self.init_hidden2()\n",
    "#         self.to_label_embed = self.init_label_embed()\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, BATCH_SIZE, self.hidden_dim1 // 2)   \n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(BATCH_SIZE, self.hidden_dim2)        \n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(BATCH_SIZE, self.label_embed_dim)\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_output(self):\n",
    "        output_tensor = torch.zeros(BATCH_SIZE, MAX_LEN, self.tagset_size)\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        self.hidden1 = self.init_hidden1()\n",
    "        output_tensor = self.create_output()\n",
    "        \n",
    "        embeds = self.word_embeds(sentence)\n",
    "        bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        dense_out = self.dense(bilstm_out)\n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            if length==0:\n",
    "                \n",
    "#                 fake_hidden=(100)\n",
    "#                 noise_x = random(100)\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)\n",
    "            else:\n",
    "#                 fake_hidden=h\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)\n",
    "            to_tags = self.hidden2tag(h_next)\n",
    "            output = self.softmax(to_tags)\n",
    "            label = self.label_embed(output)\n",
    "            \n",
    "            output_tensor[:,length,:] = output\n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return output_tensor.view(BATCH_SIZE*MAX_LEN, self.tagset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_tag = dict_inverse(tag_to_ix)\n",
    "#===============================================\n",
    "content = readfile(train_data)\n",
    "word_list, tag_list = split_to_list(content)\n",
    "word_to_ix = word2index(word_list)\n",
    "reserved_index = filter_len(word_list)\n",
    "filter_word, filter_tag = filter_sentence(reserved_index, word_list, tag_list)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "#================================================\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)\n",
    "#================================================\n",
    "vocab_size = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataload(input_var, target_var)\n",
    "model = Entity_Typing(vocab_size, tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:13<04:21, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss 0.0980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:27<04:08, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:41<03:53, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:53<03:35, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [01:06<03:18, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [01:18<03:03, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [01:30<02:48, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [01:43<02:34, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [01:55<02:21, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [02:07<02:07, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [02:20<01:54, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [02:32<01:41, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [02:45<01:28, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [02:57<01:16, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [03:09<01:03, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [03:21<00:50, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [03:34<00:37, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [03:46<00:25, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [03:58<00:12, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [04:10<00:00, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 10\n",
    "print_every = 10\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(20)):  \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x.cuda() if USE_CUDA else batch_x)\n",
    "        batch_y = batch_y.view(BATCH_SIZE*MAX_LEN)\n",
    "        loss = criterion(output, batch_y.cuda() if USE_CUDA else batch_y)\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % print_every == 1:\n",
    "            all_losses.append(loss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "    print(\"epoch: %d | loss %.4f\" % (epoch,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEOCAYAAABmVAtTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAH6RJREFUeJzt3X2UXHd93/H3587TPutxLVl+JOKZQG2smmACMQHHtOEE3LpwiPNAk1OXJE5ccpyQhoRD09OW5ISTtEmgEjkkBDgNaYNip3FsiwfXtlwbrwAbQzGRHTCWEFrLel7t7M7Mt3/cu6ORNLPalXVnpb2f1zl7zs7eO3O/v92d+dzf73cfFBGYmZkBJEtdgJmZnTscCmZm1uZQMDOzNoeCmZm1ORTMzKzNoWBmZm0OBTMza3MomJlZm0PBzMzayktdwGKtXbs2Lr/88qUuw8zsvLJjx45nI2L8dOudd6Fw+eWXMzExsdRlmJmdVyR9ZyHrefjIzMzaHApmZtbmUDAzszaHgpmZtTkUzMyszaFgZmZtDgUzM2srTCg8secwH77nCfYdqS91KWZm56y+hYKkUUmX9mt7J3ty8gh/9IWdTDoUzMx6yj0UJK2StBXYCbyjy/K1km6X9LCke/Kqo1pKmzrTaOW1CTOz814/LnPRAD4IXAms7bL8I8BHI+IuScqriGrZoWBmdjq59xQi4nBEPNptmaQLgdGIuCtbN/KqYy4U6g4FM7Oelnqi+QeB70n6a0n3S7q520qSbpY0IWlicnLyjDbknoKZ2ektdSisBV4J/BzwY8DPSHr5yStFxJaI2BQRm8bHT3vl165q7imYmZ3WUofCJHB/RByMiGPA3cAr8tjQXCjMNB0KZma9LHUoPARcLWlAUgK8Fngsjw1VSyXAw0dmZvPJ/egjSauBzwLrgYqktwJfBLZFxIOSPgx8AWgBn46IJ/Kow3MKZmanl3soRMRzwLXzLN8KbM27juOh0Mx7U2Zm562lHj7qm6rnFMzMTqs4oeAzms3MTqswoVAppSdL+5BUM7PeChMKkqiWE/cUzMzmUZhQgPRcBfcUzMx6K1woeKLZzKy3QoVCteThIzOz+RQrFDynYGY2L4eCmZm1FS8UPKdgZtZTsULBcwpmZvMqVih4+MjMbF4FC4USdV8Qz8ysp2KFQsknr5mZzadvoSBpVNKl/dpeN7WKJ5rNzOaTeyhIWiVpK7ATeEePdQYkfUPSbXnWUvNEs5nZvHK/yQ7QAD4IXAms7bHObwOP5F2IJ5rNzOaXe08hIg5HxKO9lkt6FemtOr+Ydy0+T8HMbH5LOtEsKQE+BLzvNOvdLGlC0sTk5OQZb8/nKZiZzW+pjz76FeAzEfHsfCtFxJaI2BQRm8bHx894Yx4+MjObXz/mFObzTuCgpHcBFwEVSTsj4m/y2Fi1nNBoBc1WUEqUxybMzM5rSxoKEfHaue8lvRtYm1cgQBoKkN6nebBaymszZmbnrdxDQdJq4LOkk8kVSW8lnVTeFhEP5r39TtWSQ8HMbD65h0JEPAdcu4D1/jzvWmpZT6HebAKVvDdnZnbeWeqJ5r6qldPegSebzcy6K1QodM4pmJnZqYoZCj6Bzcysq2KFQsk9BTOz+RQrFDx8ZGY2L4eCmZm1FTIU6p5TMDPrqlihkM0p1GcdCmZm3RQqFGo++sjMbF4FCwWfvGZmNp9ChYInms3M5lfQUGgucSVmZuemYoaC5xTMzLoqVij4jGYzs3kVKhQqpfRuaw4FM7Pu+hYKkkYlXdqv7fWogWo58clrZmY95B4KklZJ2grsBN5x0rKSpD+QdK+kHZLem3c9tVLik9fMzHroR0+hAXwQeF+XZWXg7yPiWuBq4Kckrc+zmGo58USzmVkPuYdCRByOiEd7LKtHxD3Z903gKWA0z3qq5cRzCmZmPZwzE81ZD2E8Iv6hy7KbJU1ImpicnHxe26k5FMzMejonQkHSEPBJ4NZuyyNiS0RsiohN4+Pjz2tb7imYmfW25KEgqQb8JfB7vYaZzibPKZiZ9bakoSCpDHwK2BIR2/qxzWrJPQUzs17KeW9A0mrgs8B6oCLprcAXgW3AK4EfAcYl3ZY95aaI2JVXPR4+MjPrLfdQiIjngGt7LH4Q2Jx3DZ2q5RIHj832c5NmZueNJZ9T6DcPH5mZ9Va4UKiVE+q+dLaZWVeFCwXPKZiZ9Va4UPDJa2ZmvRUuFHyegplZb8ULBU80m5n1VLxQ8PCRmVlPhQyFRitotWKpSzEzO+cUMhQAzyuYmXVRvFAopU2uewjJzOwUhQuFWnkuFHwCm5nZyQoXCu3hI/cUzMxO4VAwM7O2woVCrVwCPNFsZtZN30JB0qikS/u1vV7mJprdUzAzO1XuoSBplaStwE7gHV2W3yRph6SHJd2Qdz0ePjIz6y33m+wADeCDwJXA2s4FksaAW4FrgBrwoKQ7I6KeVzEOBTOz3nLvKUTE4Yh4tMfi64E7IqIeEYeA7cDVedYzFwp1zymYmZ1iqSeaLwae7ni8i/RezieQdLOkCUkTk5OTz2uDnlMwM+ttqUOhCnSeRdbKvk4QEVsiYlNEbBofH39eGzx+8ppDwczsZEsdCnuADR2PLwKeyXODnlMwM+ttqUNhG3CjpIqkFaST0Y/kuUGHgplZb7kffSRpNfBZ0rmCiqS3Al8EtkXEg5I+DjxAGlDvj4hcP62Pzyn42kdmZifLPRQi4jng2nmWbwY2513HnFrFZzSbmfWy1MNHfeejj8zMeitcKFRKAhwKZmbdFC4UJFEtJz55zcysi8KFAkCtlLinYGbWRSFDoVp2KJiZdVPYUPAZzWZmpypsKLinYGZ2qmKGgucUzMy6KmQo1CqJT14zM+tiwaEg6T2Sytn3vyBpq6Qfyq+0/LinYGbW3WJ6CjdFREPSq4F/Afwa8B/zKStfnlMwM+tuUcNHkl4K/GfgNyNiJzCYS1U5q5ZLPnnNzKyLxYTCbcDvAndFxCOS1gBfz6esfHn4yMysuwVfJTUiHgbeBiBpBLg4Iv5tXoXlqVZOfOlsM7MuFhwKkr4EXJM9537gcUkHI+KWvIrLi09eMzPrbjHDR7MR0QDeA3w6In4aeGk+ZeXLw0dmZt0tJhS+IukzwL8GPpIdnrp6IU+UdJOkHZIelnTDSct+UtJ2SV+SdNsi6jlj1bLPUzAz62Yxd177ZeAKYGdETEkaJQ2IeUkaA24lHXqqAQ9KujMi6pIqwPtJ783cAL4s6WMRcXCxDVkMH5JqZtbdYnoKZeD1wJ9J+ivgxoh4dAHPux64IyLqEXEI2A5cnS1rAQFUgCrQBI4toqYzUnMomJl1tZhQ+BNgDfA+4DeAF0j63QU872Lg6Y7Hu4D1ABHRJO2BfA74AnBbRMyc/AKSbpY0IWlicnJyESV3Vy0nNFpBqxXP+7XMzJaTxQwfvSQibu54/AFJn1/A8+Z6AHNa2ReSSsC7gd8ERoD3SLo/m9Bui4gtwBaATZs2Pe9P8mo5u09zs8VAUnq+L2dmtmwspqegbA5g7kENGF7A8/YAGzoeXwQ8k33/Y8CuiPhiRPwt8G3gLYuo6YxUS2mzfViqmdmJFhMKHwXulvTzkn4euBv42AKetw24UVJF0grSSeVHsmUzwIs61n0BcGgRNZ2R2lxPwaFgZnaCxZzR/D8k7QDenD3vloh4fAHP2y3p48ADpCH0fuA6SUMRsVXSWyVNAFPAvRFx3xm1ZBE6h4/MzOy4xcwpEBHfAr4191jSZyLinQt43mZgc49l711MDWfDXCjUZ32pCzOzTs/3JjsXnJUq+qxaSieX3VMwMzvR8w2F8/KYzqrnFMzMujrt8JGkr9H9w1/A5We7oH7wRLOZWXenDYWIeGU/Cumn4Vo6fHSk3jjNmmZmxfJ8h4/OSysGqwAcPDa7xJWYmZ1bChoK6Tl4DgUzsxMVOhQOTDkUzMw6FTIUquWE4WrJPQUzs5MUMhQg7S24p2BmdqLihsJQlYPHTrlKt5lZoRU2FFYOVjx8ZGZ2ksKGgoePzMxOVdhQWDlU4YB7CmZmJyhsKKwYSoePIs7LyzeZmeWiuKEwWGGm0WJ61tc/MjOb05dQkHSTpB2SHpZ0w0nLBiV9QtKEpIckDfajppW+1IWZ2SkWdZOdMyFpDLgVuAaoAQ9KujMi6tkqvwNsj4ifzbuWTiuHsrOaj82wfsVAPzdtZnbO6kdP4XrgjoioR8QhYDtwNYCkKvAjEbGlD3WcwJe6MDM7VT9C4WLg6Y7Hu4D12feXAXuy4aP7JX2g2wtIujkbXpqYnJw8K0X5onhmZqfqRyhUgc6bIbeyL4C1wKuAfw9cC7xS0ltOfoGI2BIRmyJi0/j4+Fkpam746KB7CmZmbf0IhT3Aho7HFwHPZN9PAl+OiN0R0QTuAPpyU5/28JEvdWFm1taPUNgG3CipImkFcCXwSLbsSWCdpNXZ4zcAX+lDTYzUypQSefjIzKxD7kcfRcRuSR8HHiANofcD10kaioitkn4duENSC/g/EfG5vGsCkORLXZiZnST3UACIiM3A5h7LtgM/3I86TrZy0Je6MDPrVNgzmiG91MUhh4KZWVuxQ8HDR2ZmJyh0KKTDRz76yMxsTrFDYajq8xTMzDoUOhTGBiscmm7QbPny2WZmUPBQWJmdwHZ42r0FMzMoeigM+aJ4ZmadCh0Kxy914VAwM4OCh0L7ongOBTMzoOChsCK7+9qBKR+WamYGhQ8F9xTMzDo5FPA9FczM5hQ6FKrlhOFqyRPNZmaZQocC+PpHZmadHApDVc8pmJllCh8KKwcrHPRF8czMgD6FgqSbJO2Q9LCkG7osl6TPS/rjftTTycNHZmbH5X7nNUljwK3ANUANeFDSnRFR71jt3wDfzbuWblYOVTx8ZGaW6UdP4XrgjoioR8QhYDtw9dxCSRcCPw58og+1nGKFb8lpZtbWj1C4GHi64/EuYH3H498H3gf0vH61pJslTUiamJycPKvFrRiqMNNoMT3bPKuva2Z2PupHKFSBzk/cVvaFpLcDT0TEN+d7gYjYEhGbImLT+Pj4WS1uZftSF+4tmJnlPqcA7AE2dDy+CNiWff9TwEpJdwGrgXWSvhYRm/tQF9B5pdQZ1q8Y6NdmzczOSf0IhW3AVkl/CAwBVwK/BBARN86tJOla4MZ+BgJ0XCnVPQUzs/xDISJ2S/o48ADpcNX7geskDUXE1ry3fzpzobDvqM9VMDPrR0+BbO9/3h5ARNwL3NuPejpdtmYYgG/vO9rvTZuZnXMKf0bzSK3M+rEBntzrUDAzK3woAGy8YJgnJ48sdRlmZkvOoQBsHB/hyckjRPQ8VcLMrBAcCqShcHi6weTh+ulXNjNbxhwKpKEAsNNDSGZWcA4F0jkFgCcnPdlsZsXmUADWjw0wVC3x5F73FMys2BwKgKT2ZLOZWZE5FDIbx4d5ysNHZlZwDoXMxvERdh04xtRMY6lLMTNbMg6FzMYL0iOQ3FswsyJzKGTmDkv1vIKZFZlDIXPZmiES+bBUMys2h0JmoFLiktVD7imYWaE5FDpsHB/xuQpmVmh9CQVJN0naIelhSTectOw3Jd2XLfv9ftTTy8bxYf7x2aM0W74wnpkVU+6hIGkMuBW4BrgO+I+Sah2rfC0i3hARrwFeLOnqvGvqZeP4CPVGi90Hji1VCWZmS6ofPYXrgTsioh4Rh4DtQPuDPyL+tmPdJ4AVfaipq7nDUn1hPDMrqn6EwsXA0x2PdwHrT15J0hBpb+KBLstuljQhaWJycjK3Ql+8bpRyIh56al9u2zAzO5f1IxSqQLPjcSv7apNUAj4B/E5EnDJ2ExFbImJTRGwaHx/PrdAVgxXe8OJx/varu2l5XsHMCqgfobAH2NDx+CLgmbkHkgR8DPi7iLi7D/XM621XbGD3wWke+fZzS12KmVnf9SMUtgE3SqpIWgFcCTzSsfyPgIcj4s/7UMtpvfll6xislLj90d1LXYqZWd/lHgoRsRv4OOlcweeADwDXSbpB0vXAzwDvknRv9nVV3jXNZ7hW5sdesY47v/Y9Zhqt0z/BzGwZKfdjIxGxGdjcY/FYP2pYjLddsYHbv7qb+741yZtfvm6pyzEz6xuf0dzF6180zqqhioeQzKxwHApdVEoJP/6qC9n2jT0cqfv+CmZWHA6FHt5+xUVMz7b42H1PEeHDU82sGBwKPbz60lW85RXr+a+f/wdu/cuv+o5sZlYIDoUekkR85KZX82vXv4T//dhu3vbH231ZbTNb9hwK80gS8UtvfCF/8XOvYd/RGd72x9u5++t7lrosM7Pc6HwbL9+0aVNMTEz0fbu7DhzjFz61g8eeOcgtb3wh179iPQ//4z4e+fZzXL5mmFt+9IWMDlT6XpeZ2UJI2hERm067nkNh4aZnm3zg9sf5q4n2VTq4eNUguw4cY+1Ijd/68ZfxE/9kA+mVO8zMzh0OhZxEBF/45l6O1Bv80A+sYd3YAI9+9wC/ffvjPPbMQVYNVaiVS5QSMVQtsWqoyqrhCqMDFSqlhEpJrBmu8aaXXcArNox1DZB9R+p8ffchquWEkVqZSinh6eem2Ln3CN/dP8Wlq4e44pKVvPKiFQzX+nL+oZmd5xwKfdZsBX+94xm++swBms2g0QqmZhrsn5ph/9FZDk/PMtsKZpstDh2bpRVwyepBXv+icUZqZcqJmJpp8tBT+/jmnsM9t7NisMLBY7MAJII3vHicd266hDe9bB3VsqeIzKw7h8I57LmjM2z7xh7+/vE9fPk7+5ltBo1Wi1IiNl22mtduXMOrL11FRHCk3qDeaHHxqkE2XjDC2ECFfUfqPPbMQb707efY+uVd7Dk0zZrhKje95lLe/boXsHq4utRNNLNzjEOhIJqt4L5/mOTTDz3N5/7f9xmqlvjJqy/l2pdcwMqhCiuHKlwwOuBehFnBORQK6FvfP8xH732SOx7dTbPjJkGlRFyyapAXrB3mRetGefmFY7x8wxg/sHaYcslhYVYEDoUC+/6hab6zb4r9UzMcmJrhmf3HeOrZozw1eZQn9x5hppleErxWTnjZhWP84EVjrB6q8t39x/jOvqMcPDbLcK3McLXM6uEqL1k/yssuHOMl60ZZt6JGrVxa4haa2WItNBR86MoytG5sgHVjA12XzTZbPDV5lK/vPsg3dh/ia7sO8jdf2c3RmQYbVgxy6eohXrp+kKMzDY7WGzy++yB3Pv49OvcdVg9XWTtSpZwkJFlHoz7b4thsk9lmi0tWDfGidaO86IIRRgbSSfRS9pVkR1t97+A0O/ce4anJI1RKCRevGuSS1UOsGqpSLSdUywkliWYErVZQKyeMj9YYH60xNlChGUGzFcw0Wu1aZ5vB2pEq46MDjA2UmW0Gx2aaTDeaNFpBs5k2YuVwhdFa2YcOm3XhnoLRaqVHS/Wadzhab/DNPYd5cu8R9hya5vuHpnn2SJ1mKz1EtxXBQKXEYKVEkoin903xrb2HOTA1O+92Vw5V2Dg+QqMV7No/xbNHZs5amxLBfLfZrpUT1o7UGKyWqJUTKqWEYzNNDk/Pcni6QaWcMDZQZnSgQpKIRrNFIzsgoBXpXE4pEdVSGmADlYSBSomhavp7qJYTauUSlVJCKUnPjgeYabSoN1pEBKuHq6wZrrF6uEqSCAFS+tqtCBrNYKbZoj6bPgdIX0uinIhKOaGSJFTKopykhzvPNtOj3o7Wm9QbLWab6VejlYZrK4JyKWHlYIVVQ1WGa2VKCe2AbK/fDBKlQS5BoxntZXMHRswFbSN73QgI0l/6YKXESK3MyECFSknt1xqslhgbqLBisAIEh6YbHJ5uMNtxQ6skIWtPQikRzVYQEe0dgbltdYqAVqR/k9XDVS4YG2DNcBUJWq10WfqV/r/PNtPfab3R4vD0LAePzXJoukGi9EZbI7Uya0dqbFg50O4ZRwQHpmapN1rUyunfu1pOSMSidzAigtlmtH9fYm6nafGvtVDnVE9B0k3ArwIN4EMRsbVj2ZuA382W/UVEfKQfNdlxSSKqSe9/xOFamasuW8VVl61a8GtGBM8dneHYbJNmK3sDzL0pI7hgNP0w7HwDTM2kHxDpB2eTZuv4h+D0bIvJI3UmD9c5PD2b9T4SyiUxUiunH24S+46m6xyYmm1/UA9WS5Q7ein7p2aYPFxn35G0vplGi5lmi3VjNUYHKowOlLNDhxscmk4PH64kolxS1jsSJUEzYKaRPn96tsWh6QZ7D9Xbr1lvNJltph9kzexTrFZKqFUSQOyfmjlh7icvEu32lxIx00g/0M/2NpKOv2U/2tUvF4zWKCXi2SN1Zpvd2zXXE65kYZ1I7RBttTje+03E9EyTqex90c1cMMztJFRLCbVKuvPy06+9jF+89oU5trYPoSBpDLgVuAaoAQ9KujMi6pIS4EPA9cChbNnWiPhe3nVZviSxZqS2qOcMVcsMVYszotlqBQeOzbJ/aoZo72kf7wmUElHLehxzvbi5veVmtrc79wHfyPbgKyUxVCszVCkxUClRKc3t7R//wI4Ijs40OTA1w9F6k1b2mpB9eGV76K32nnn6wdTZIymXEsrJ8TpP3rutN5ocrTc5Mt1gtpX2jJotODrTSPfKj80iidGBMqO18gnzVM043p5mK0gSKEkkHcHWuQ8Tkf7OJGi0gn3ZzsO+o2nPM1G6/lydidJ7pqS9uYTRgTIrBtPeSyvgSD0djtx7qM4z+4+x68AUrYDx0RprR2oMVJL2jsBMo9Ue4pxttdo9qlZEuo1SgqRsx6NJoxkMVksMV8sMVJL2723u9zP3WsHx/4fZxlyvpsllq4dz+E88UT/egdcDd0REHahL2g5cDdwPXAU8GhH7ACR9Fngz8Mk+1GW2pJJsqKPf55VIae9qJMez4WvlErVyyefMnIf6cTzixcDTHY93AesXsKxN0s2SJiRNTE5O5laomVnR9SMUqkCz43Er+zrdsraI2BIRmyJi0/j4eG6FmpkVXT9CYQ+woePxRcAzC1hmZmZ91o9Q2AbcKKkiaQVwJfBItuwh4PWSxiRVgJ8A7upDTWZm1kXuE80RsVvSx4EHSEPo/cB1koYiYquk3yINjgT4bxFxMO+azMysu74c/xcRm4HNPZbdAdzRjzrMzGx+vhqamZm1ORTMzKztvLv2kaRJ4Dtn+PS1wLNnsZzzRRHbXcQ2QzHbXcQ2w+LbfVlEnPaY/vMuFJ4PSRMLuSDUclPEdhexzVDMdhexzZBfuz18ZGZmbQ4FMzNrK1oobFnqApZIEdtdxDZDMdtdxDZDTu0u1JyCmZnNr2g9BTMzm4dDwczsHCZpVNKl/dpeYUJB0k2Sdkh6WNINS11PXiSVJP2BpHuz9r43+/lt2T0pHpJ0zVLXmQdJA5K+Iem27PGHJX1J0v2SXrzU9eVB0lpJt2f/1/dkP1vW7Zb0q5K2S3oku9XvsmyzpFWStgI7gXd0/PyUtmYXHP3k3P+BpAvOdLuFuPfhfLcEXdrKclEG/j4i3iupBHxJ0g7gOuCfkt7YaCuwHI/r/m2yK/BKug4Yi4irJV0F/CHwz5eyuJx8BPhoRNyl1LJut6RLgLcDP0z6Xn5M0l6WZ5sbwAdJryy9Fub9v3438M2I+GlJ/xL4D8AvnMlGi9JTaN8SNCIOAXO3BF12sjbek33fBJ4CXgN8MlLfBfZlb65lQ9KrSO/a98XsR28HPgEQETuAS7N7gi8bki4ERiPiLoBIjxpZ7u2eIb05VwKMAM+xTNscEYcj4tGTftyrre2fA7cDrzvT7Z73v7gFWtBtP5cbSeuBcZZ5+7M3xYeA93X8+OQ27wXW9LOuPvhB4HuS/jobSriZZd7uiPg+6d7xvaRXV172bT5Jr7ZeSPq+JiIagM50A4UYPmKBt/1cTiQNAZ8kHTZ7D8u7/b8CfCYinpXa74Ui/M3XAq8E3ky6B70NmGUZt1vSKHAD6d/8SuAXKcbfek6vtpbjxPMLGme6gaKEQrfbfm5bolpyJ6kG/CXwexHxqKTlftvTdwIHJb2LtG0V0vHmDWR7T8Aq0qGG5WQSuH/uxlSS7gZ+juXd7p8CPh8RXwG+Iul6YIDl3eZOc+/lk9u6T9J4RExmc4lnHApFGT6a75agy4qkMvApYEtEzAXfXcDcURqXAJWsG74sRMRrI+ItEfEW4MPAnwK/QfoBQjYh98RJe1LLwUPA1dlRVwnwWuC/s7zbPQPMHXFTAi4h/f9ezm3u1Kut7Z+Tzi987kw3UIieQrdbgkbEcu1e/jzwI8D43KGZpIHwqKT/mz3+xSWprL/+F/BGSQ+SfpD87BLXc9ZFxBFJHwa+QDqE8GnSSx/8yTJu9yeBP8v+l5ukO0CbWYZtlrQa+Czp/F9F0ltJ39/d/q//CPhzSf8K2E+2E3hG212+gWpmZotVlOEjMzNbAIeCmZm1ORTMzKzNoWBmZm0OBTMza3MomJlZm0PBzMzaHApmCyTp1yV9QdKDkrZKunTuev5my0Uhzmg2e74kvR54aUT8aPZ4FLiK9NISn17K2szOJoeC2cKMAsMdj9eRXsJ5XNLGiPhn2bVo/gvpBfm+HhG3SLqW9NIEVdLLHu8BfiYijva1erMF8vCR2cLcDUxL2ibpiojYCfw7YGsWCBXgd4C3R8QbgXp2lyyANwK/HBGvA75Geilzs3OSewpmC5Ddxe5nJb2Z9IJsfwp8vWOVlwJXAHdm93QYAR4H/hG4JyL2Zuv9T+C3+la42SI5FMwWISI+J+l1wFeA2zoWlYD7IuJdnetnw0czHT8aAqbyrtPsTHn4yGwBJF0maTB7OAMcBQ6RzjUAPAFcJemibP2NkubmIN6UTUxDOr+wbG/wZOc/h4LZwmwEviTpAeAe4D8BDwMvlvR3EXEMuAW4Q9J9wB90PPcx4FOStpP2Ev6qv6WbLZzvp2CWo2z46MaIuGWpazFbCPcUzMyszaFgZmZtHj4yM7M29xTMzKzNoWBmZm0OBTMza3MomJlZm0PBzMzaHApmZtb2/wGRTMhNH580cQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_losses[:100])\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one input\n",
    "def easy_pad(easy_sent, easy_tar):\n",
    "    easy_sent += [PAD_TAG for i in range(MAX_LEN-len(easy_sent))]\n",
    "    easy_tar += [PAD_TAG for i in range(MAX_LEN-len(easy_tar))]\n",
    "    \n",
    "    return easy_sent, easy_tar\n",
    "\n",
    "def easy_test(_input):\n",
    "    _input = torch.unsqueeze(_input, 0).expand(128,100)\n",
    "    return _input\n",
    "\n",
    "def easy_output(output):\n",
    "    output = output.view(128,100,5)[0].argmax(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = readfile(test_data)\n",
    "word_list_test, tag_list_test = split_to_list(test_content)\n",
    "\n",
    "#===================================\n",
    "easy_sent, easy_tar = easy_pad(word_list_test[3],tag_list_test[3])\n",
    "input_test = prepare_sequence(easy_sent, word_to_ix)\n",
    "# input_test = prepare_sequence(t_sentence, word_to_ix)\n",
    "\n",
    "target_test = prepare_sequence(easy_tar, tag_to_ix)\n",
    "\n",
    "_input = easy_test(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = model(_input.cuda() if USE_CUDA else _input)\n",
    "    output = easy_output(output)\n",
    "    \n",
    "    print('predict :', output)\n",
    "    print('true :', target_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence__(seq, to_ix):\n",
    "    gg = []\n",
    "    \n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            return seq\n",
    "\n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "#     return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all__(seqs, to_ix):\n",
    "    get_index = []\n",
    "    notinseq = []\n",
    "    for i in range(len(seqs)):\n",
    "        a = prepare_sequence__(seqs[i], to_ix)\n",
    "        if a != None:\n",
    "            notinseq.append( a)\n",
    "            get_index.append(i)\n",
    "#         seq_list.append(prepare_sequence__(seqs[i], to_ix))\n",
    "        \n",
    "#     notinseq = torch.stack(notinseq)\n",
    "        \n",
    "    return notinseq, get_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch input\n",
    "reserved_index_test = filter_len(word_list_test[:143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reserved_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word, filter_tag = filter_sentence(reserved_index_test, word_list_test, tag_list_test)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_output(output):\n",
    "    output = output.view(128,100,5).argmax(2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  2,  3,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n",
      "\n",
      "predict : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Func', 'I-Func', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "true : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Loss : 0.0163\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = model(input_var.cuda() if USE_CUDA else _input)\n",
    "    \n",
    "    loss = criterion(output.cpu(), target_var.view(128*100))\n",
    "    output = total_output(output)\n",
    "    \n",
    "    print('predict :', output[37])\n",
    "    print('true :', target_var[37])\n",
    "    print()\n",
    "    print('predict :', index2tag(output[37], ix_to_tag))\n",
    "    print('true :', index2tag(target_var[37], ix_to_tag))\n",
    "    print()\n",
    "    \n",
    "    print(\"Loss : %.4f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
