{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "tag_to_ix = {UNKOWN_TAG: 0, PAD_TAG:1, \"B-Func\": 2, \"I-Func\": 3, \"O\": 4}\n",
    "\n",
    "tagset_size = len(tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM1 = 10\n",
    "HIDDEN_DIM2 = 8\n",
    "LABEL_EMBED_DIM = 3\n",
    "DENSE_OUT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_list.append(word_set[0])\n",
    "        tag_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, tag_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "\n",
    "    for i, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, tags = get_word_and_label(content, init, i)\n",
    "            init = i+1\n",
    "            word_list.append(words)\n",
    "            tag_list.append(tags)\n",
    "            \n",
    "    return word_list, tag_list\n",
    "    \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, tag_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_tag = list(tag_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_tag\n",
    "\n",
    "def pad_seq(seq):\n",
    "    seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_tag):\n",
    "    input_padded = [pad_seq(s) for s in filter_word]\n",
    "    target_padded = [pad_seq(s) for s in filter_tag]\n",
    "    \n",
    "    return input_padded, target_padded\n",
    "\n",
    "#======================================\n",
    "def dataload(input_var, target_var):\n",
    "    torch_dataset = Data.TensorDataset(input_var, target_var)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=2,       \n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim):\n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.label_embed_dim = label_embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(DENSE_OUT+label_embed_dim, hidden_dim2, batch_first=True)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.tagset_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.tagset_size, self.label_embed_dim)\n",
    "        \n",
    "#         self.hidden1 = self.init_hidden1()\n",
    "#         self.hidden2 = self.init_hidden2()\n",
    "#         self.to_label_embed = self.init_label_embed()\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, BATCH_SIZE, self.hidden_dim1 // 2)   \n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(BATCH_SIZE, self.hidden_dim2)        \n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(BATCH_SIZE, self.label_embed_dim)\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_output(self):\n",
    "        output_tensor = torch.zeros(BATCH_SIZE, MAX_LEN, self.tagset_size)\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        self.hidden1 = self.init_hidden1()\n",
    "        output_tensor = self.create_output()\n",
    "        \n",
    "        embeds = self.word_embeds(sentence)\n",
    "        bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        dense_out = self.dense(bilstm_out)\n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            if length==0:\n",
    "                \n",
    "#                 fake_hidden=(100)\n",
    "#                 noise_x = random(100)\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)\n",
    "            else:\n",
    "#                 fake_hidden=h\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)\n",
    "            to_tags = self.hidden2tag(h_next)\n",
    "            output = self.softmax(to_tags)\n",
    "            label = self.label_embed(output)\n",
    "            \n",
    "            output_tensor[:,length,:] = output\n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return output_tensor.view(BATCH_SIZE*MAX_LEN, self.tagset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_tag = dict_inverse(tag_to_ix)\n",
    "#===============================================\n",
    "content = readfile(train_data)\n",
    "word_list, tag_list = split_to_list(content)\n",
    "word_to_ix = word2index(word_list)\n",
    "reserved_index = filter_len(word_list)\n",
    "filter_word, filter_tag = filter_sentence(reserved_index, word_list, tag_list)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "#================================================\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)\n",
    "#================================================\n",
    "vocab_size = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataload(input_var, target_var)\n",
    "model = Entity_Typing(vocab_size, tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:12<03:54, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:24<03:44, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:37<03:32, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss 0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:51<03:25, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss 0.0690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [01:04<03:12, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss 0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [01:16<02:58, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss 0.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [01:29<02:45, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [01:41<02:32, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [01:54<02:19, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [02:06<02:06, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [02:18<01:53, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [02:31<01:40, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [02:43<01:28, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [02:56<01:15, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [03:08<01:02, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [03:21<00:50, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [03:33<00:37, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [03:46<00:25, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [03:58<00:12, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [04:10<00:00, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 10\n",
    "print_every = 12\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(20)):  \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x.cuda() if USE_CUDA else batch_x)\n",
    "        batch_y = batch_y.view(BATCH_SIZE*MAX_LEN)\n",
    "        loss = criterion(output, batch_y.cuda() if USE_CUDA else batch_y)\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % print_every == 1:\n",
    "            all_losses.append(loss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "    print(\"epoch: %d | loss %.4f\" % (epoch,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_losses[:100])\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one input\n",
    "def easy_pad(easy_sent, easy_tar):\n",
    "    easy_sent += [PAD_TAG for i in range(MAX_LEN-len(easy_sent))]\n",
    "    easy_tar += [PAD_TAG for i in range(MAX_LEN-len(easy_tar))]\n",
    "    \n",
    "    return easy_sent, easy_tar\n",
    "\n",
    "def easy_test(_input):\n",
    "    _input = torch.unsqueeze(_input, 0).expand(128,100)\n",
    "    return _input\n",
    "\n",
    "def easy_output(output):\n",
    "    output = output.view(128,100,5)[0].argmax(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = readfile(test_data)\n",
    "word_list_test, tag_list_test = split_to_list(test_content)\n",
    "\n",
    "#===================================\n",
    "easy_sent, easy_tar = easy_pad(word_list_test[3],tag_list_test[3])\n",
    "input_test = prepare_sequence(easy_sent, word_to_ix)\n",
    "# input_test = prepare_sequence(t_sentence, word_to_ix)\n",
    "\n",
    "target_test = prepare_sequence(easy_tar, tag_to_ix)\n",
    "\n",
    "_input = easy_test(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = model(_input.cuda() if USE_CUDA else _input)\n",
    "    output = easy_output(output)\n",
    "    \n",
    "    print('predict :', output)\n",
    "    print('true :', target_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence__(seq, to_ix):\n",
    "    gg = []\n",
    "    \n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            return seq\n",
    "\n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "#     return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all__(seqs, to_ix):\n",
    "    get_index = []\n",
    "    notinseq = []\n",
    "    for i in range(len(seqs)):\n",
    "        a = prepare_sequence__(seqs[i], to_ix)\n",
    "        if a != None:\n",
    "            notinseq.append( a)\n",
    "            get_index.append(i)\n",
    "#         seq_list.append(prepare_sequence__(seqs[i], to_ix))\n",
    "        \n",
    "#     notinseq = torch.stack(notinseq)\n",
    "        \n",
    "    return notinseq, get_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch input\n",
    "reserved_index_test = filter_len(word_list_test[:143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reserved_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word, filter_tag = filter_sentence(reserved_index_test, word_list_test, tag_list_test)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_output(output):\n",
    "    output = output.view(128,100,5).argmax(2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  2,  3,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n",
      "\n",
      "predict : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Func', 'I-Func', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "true : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Loss : 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = model(input_var.cuda() if USE_CUDA else _input)\n",
    "    \n",
    "    loss = criterion(output.cpu(), target_var.view(128*100))\n",
    "    output = total_output(output)\n",
    "    \n",
    "    print('predict :', output[37])\n",
    "    print('true :', target_var[37])\n",
    "    print()\n",
    "    print('predict :', index2tag(output[37], ix_to_tag))\n",
    "    print('true :', index2tag(target_var[37], ix_to_tag))\n",
    "    print()\n",
    "    \n",
    "    print(\"Loss : %.4f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
