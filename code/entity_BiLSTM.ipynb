{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def schema_load(schema_root):\n",
    "    raw_dict = \"\".join(readfile(schema_root))\n",
    "    dict2json = \"\".join(raw_dict.split()[2:])\n",
    "\n",
    "    json_acceptable_string = dict2json.replace(\"'\", \"\\\"\")\n",
    "    schema = json.loads(json_acceptable_string)\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def define_entity(schema):\n",
    "    tag_type = list(schema['tagging'])\n",
    "    \n",
    "    entity_tag = []\n",
    "    for k in list(schema['entity'].keys()):\n",
    "        entity_tag.append(schema['entity'][k]['tag'])\n",
    "        \n",
    "    TAG = []\n",
    "    for t in tag_type:\n",
    "        for e in entity_tag:\n",
    "            if t!='O':\n",
    "                TAG.append(t+'-'+e)  \n",
    "                \n",
    "    TAG = [UNKOWN_TAG, PAD_TAG] + TAG + ['O']   \n",
    "\n",
    "    return TAG\n",
    "\n",
    "def tag2ix(TAG):\n",
    "    tag_to_ix={t:i for i,t in enumerate(TAG)}\n",
    "    return tag_to_ix\n",
    "\n",
    "def define_relation(schema):\n",
    "    relation_type = list(schema['relation'])\n",
    "    \n",
    "    relation_tag = []\n",
    "    for k in list(schema['relation'].keys()):\n",
    "        relation_tag.append(schema['relation'][k]['tag'])\n",
    "    \n",
    "    relation_tag = [REL_PAD] + [REL_NONE] + relation_tag\n",
    "        \n",
    "    return relation_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_set = word_set.split()\n",
    "        if len(word_set)==1:\n",
    "            word_list.append(' ')\n",
    "            ent_list.append('O')\n",
    "            rel_list.append(REL_NONE)\n",
    "        \n",
    "        else:\n",
    "            word_list.append(word_set[0])\n",
    "            ent_list.append(word_set[1])\n",
    "\n",
    "            try:\n",
    "                testerror = word_set[2]\n",
    "            except IndexError:\n",
    "                rel_list.append(REL_NONE)\n",
    "            else:\n",
    "                rel_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "\n",
    "    for now_token, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, ents, rels = get_word_and_label(content, init, now_token)\n",
    "            init = now_token+1\n",
    "            word_list.append(words)\n",
    "            ent_list.append(ents)\n",
    "            rel_list.append(rels)\n",
    "            \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, ent_list, rel_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_ent = list(ent_list[i] for i in reserved_index)\n",
    "    filter_rel = list(rel_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_ent, filter_rel\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq, isrel):\n",
    "    if isrel:\n",
    "        seq += [REL_NONE for i in range(MAX_LEN-len(seq))]\n",
    "    else:\n",
    "        seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_ent, filter_rel):\n",
    "    input_padded = [pad_seq(s, False) for s in filter_word]\n",
    "    ent_padded = [pad_seq(s, False) for s in filter_ent]\n",
    "    rel_padded = [pad_seq(s, True) for s in filter_rel]\n",
    "    \n",
    "    return input_padded, ent_padded, rel_padded\n",
    "\n",
    "def deep_copy_lists(filter_word, filter_ent, filter_rel):\n",
    "    f_w = copy.deepcopy(filter_word)\n",
    "    f_e = copy.deepcopy(filter_ent)\n",
    "    f_r = copy.deepcopy(filter_rel)\n",
    "    \n",
    "    return f_w, f_e, f_r\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "\n",
    "\n",
    "def prepare_rel(rel_padded, to_ix):\n",
    "    \n",
    "    rel_ptr = torch.zeros(len(rel_padded), MAX_LEN, MAX_LEN, dtype=torch.long) \n",
    "    \n",
    "    # 對當前的token，去比較之前所有出現過的entity，是否有關係，建成矩陣\n",
    "    # [B*ML*ML]，第二維ML是當前token，第三維ML是根據當前token對之前出現過的entity紀錄關係，以index紀錄\n",
    "    for i, rel_seq in enumerate(rel_padded):\n",
    "        rel_dict = {}\n",
    "        for j, token_seq in enumerate(rel_seq):\n",
    "            rel_ptr[i][j][:j+1] = 1\n",
    "            if token_seq != REL_NONE:\n",
    "                for k, rel in enumerate(token_seq):\n",
    "\n",
    "                    # if 是第一次出現，紀錄後面數字(標第幾對)和關係位置(A OR B)\n",
    "                    # 假如下次出現又是同個關係位置(A)，依然紀錄\n",
    "                    # 直到下次出現關係位置B，依照之前紀錄的A位置的字，然後在第三維去標關係\n",
    "\n",
    "                    rel_token = rel.split('-')\n",
    "                    if rel_token[1] not in rel_dict:\n",
    "                        rel_dict[rel_token[1]] = {'rel':rel_token[0], 'loc':rel_token[2], 'idx':[j]}\n",
    "\n",
    "                    elif rel_token[1] in rel_dict and rel_dict[rel_token[1]]['loc']==rel_token[2]:\n",
    "                        rel_dict[rel_token[1]]['idx'].append(j)\n",
    "\n",
    "                    else:\n",
    "                        record_loc = rel_dict[rel_token[1]]['idx']\n",
    "                        for idxx in record_loc:\n",
    "                            rel_ptr[i][j][idxx] = to_ix[rel_token[0]]\n",
    "                            \n",
    "    return rel_ptr\n",
    "                \n",
    "\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def dataload(input_var, ent_var, rel_var, raw_input):\n",
    "    torch_dataset = Data.TensorDataset(input_var, ent_var, rel_var, raw_input)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=0,       \n",
    "#         drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_entity(entity):\n",
    "    entity = entity.view(BATCH_SIZE,ent_size).argmax(1)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output, rel_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        self.rel_size = rel_size\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.w2 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(self.attn_output, self.rel_size, bias=False)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        \n",
    "        decoder = encoder_outputs[:,-1,:].unsqueeze(1)                       #B*1*(ts+LE) [128,1,8]\n",
    "        encoder_score = self.w1(encoder_outputs)                             #B*now len*ATTN_OUT\n",
    "        decoder_score = self.w2(decoder)                                     #B*1*ATTN_OUT\n",
    "        energy = self.tanh(encoder_score+decoder_score)                      #B*now len*ATTN_OUT            \n",
    "        \n",
    "        energy = self.v(energy)                                              #B*now len*rel_size\n",
    "        \n",
    "        \n",
    "        # 針對每個entity做softmax，去顯示他們的關係權重\n",
    "        # 主要都會是rel_none\n",
    "        # 對第二維(rel)做softmax\n",
    "        p = self.softmax(energy)                                         #B*now len*rel_size\n",
    "        \n",
    "        return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, ent_tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim, rel_tag_to_ix):\n",
    "        \n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.ent_to_ix = ent_tag_to_ix\n",
    "        self.ent_size = len(ent_tag_to_ix)                   #es\n",
    "        self.rel_to_ix = rel_tag_to_ix\n",
    "        self.rel_size = len(rel_tag_to_ix)                   #rs           \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim1, momentum=0.5, affine=False)\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "#                             num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)        \n",
    "        self.bilstm = nn.GRU(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.ent_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.ent_size, self.label_embed_dim)\n",
    "        \n",
    "        self.attn = Attn(ATTN_IN, ATTN_OUT, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, self.batch, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(self.batch, self.hidden_dim2)              #B*h2\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(self.batch, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_entity(self):\n",
    "        output_tensor = torch.zeros(self.batch, MAX_LEN, self.ent_size)  #B*ML*es\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "    \n",
    "    def create_rel_matrix(self):\n",
    "        rel_tensor = torch.zeros(self.batch, MAX_LEN, MAX_LEN, self.rel_size)  #B*ML*ML*rs\n",
    "        return rel_tensor.cuda()if USE_CUDA else rel_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, batch_ent, isTrain=True):\n",
    "        \n",
    "        self.batch = sentence.size(0)\n",
    "#         self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        entity_tensor = self.create_entity()                    #B*ML*es\n",
    "        rel_tensor = self.create_rel_matrix()                   #B*ML*ML*rs\n",
    "        \n",
    "        \n",
    "\n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "#         bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        bilstm_out, hidden1 = self.bilstm(embeds)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        # bn\n",
    "        bilstm_out = self.bn(bilstm_out)\n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence_l = [] \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            \n",
    "            if length==0:\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*es,[128, 5]            \n",
    "            ent_output = self.softmax(to_tags)                               #B*es,[128, 5]  \n",
    "            s_ent_output = self.softmax_entity(ent_output)\n",
    "            ent_onehot = self.one_hot(s_ent_output)\n",
    "            \n",
    "            \n",
    "            if isTrain:\n",
    "                label = self.label_embed(ent_onehot)                             #B*LE,[128, 3]\n",
    "#                 label = self.label_embed(ent_output) \n",
    "            else:\n",
    "                batch_ent_onehot = self.one_hot(batch_ent[:,length])\n",
    "                label = self.label_embed(batch_ent_onehot)\n",
    "            \n",
    "     \n",
    "            \n",
    "            # Assignments to Variables are in-place operations.\n",
    "            # Use that variable in lots of other contexts \n",
    "            # and some of the functions require it to not change. \n",
    "            to_tags_clone = to_tags.clone()\n",
    "            label_clone = label.clone()\n",
    "            \n",
    "            \n",
    "#             for i, tag in enumerate(s_ent_output):\n",
    "#                 if tag==ent_tag_to_ix['O']:\n",
    "#                     to_tags_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "#                     label_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "                    \n",
    "            # relation layer\n",
    "#             encoder_sequence_l.append(torch.cat((to_tags,label),1)) \n",
    "            encoder_sequence_l.append(torch.cat((h_next,label),1))  \n",
    "            encoder_sequence = torch.stack(encoder_sequence_l).t()     #B*len*(es+LE), [128,1,8]          \n",
    "\n",
    "            # Calculate attention weights \n",
    "            attn_weights = self.attn(encoder_sequence)\n",
    "\n",
    "        \n",
    "            entity_tensor[:,length,:] = ent_output\n",
    "            \n",
    "            # rel_tensor[:,length, 頭~當前 ,:]\n",
    "            rel_tensor[:,length,:length+1,:] = attn_weights\n",
    "\n",
    "        \n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return entity_tensor.view(self.batch*MAX_LEN, self.ent_size), \\\n",
    "               rel_tensor.view(self.batch*MAX_LEN*MAX_LEN, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def softmax_entity(self, entity):\n",
    "        entity = entity.view(self.batch,ent_size).argmax(1)\n",
    "        return entity\n",
    "    \n",
    "    \n",
    "    def one_hot(self, batch_ent):   \n",
    "        batchsize = batch_ent.size(0)\n",
    "        nb_digits = len(ent_tag_to_ix)\n",
    "        batch_ent = torch.unsqueeze(batch_ent, 1)\n",
    "        y_onehot = torch.cuda.FloatTensor(batchsize, nb_digits)        \n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, batch_ent, 1)    \n",
    "\n",
    "        return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "relation_data_old = root+'facial_r.old.train'\n",
    "# relation_data = root+'facial_r.train'\n",
    "relation_data = root+'facial_r2.train'\n",
    "schema_root = root+'schema_2.txt'\n",
    "dev_data = root+'facial_r2.dev'\n",
    "test_data = root+'facial_r2.test'\n",
    "\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "REL_NONE = 'Rel-None'\n",
    "REL_PAD = 'Rel-Pad'\n",
    "rule = ('FUNC', 'ApplyTo', 'STAT')\n",
    "\n",
    "schema = schema_load(schema_root)\n",
    "ENT_TAG = define_entity(schema)\n",
    "REL_TAG = define_relation(schema)\n",
    "ent_tag_to_ix = tag2ix(ENT_TAG)\n",
    "'''{'<PAD>': 1,\n",
    " '<UNKNOWN>': 0,\n",
    " 'B-FUNC': 2,\n",
    " 'B-STAT': 3,\n",
    " 'I-FUNC': 4,\n",
    " 'I-STAT': 5,\n",
    " 'O': 6}'''\n",
    "rel_tag_to_ix = tag2ix(REL_TAG)\n",
    "'''{'ApplyTo': 2, 'Rel-None': 1, 'Rel-Pad': 0}'''\n",
    "\n",
    "# ========hyper-parameter-set==========\n",
    "\n",
    "ent_size = len(ent_tag_to_ix)\n",
    "rel_size = len(rel_tag_to_ix)\n",
    "MAX_LEN = 70     # original 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "EMBEDDING_DIM = 40\n",
    "HIDDEN_DIM1 = 20\n",
    "HIDDEN_DIM2 = 16\n",
    "LABEL_EMBED_DIM = ent_size\n",
    "DENSE_OUT = 100\n",
    "\n",
    "# ATTN_IN = ent_size+LABEL_EMBED_DIM\n",
    "ATTN_IN = HIDDEN_DIM2+LABEL_EMBED_DIM\n",
    "ATTN_OUT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    content = readfile(data)\n",
    "    word_list, ent_list, rel_list = split_to_list(content)\n",
    "    word_to_ix = word2index(word_list)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    #================================================\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, vocab_size, word_to_ix, reserved_index, word_list\n",
    "\n",
    "def dev_preprocess(dev_data):\n",
    "    dev_content = readfile(dev_data)\n",
    "    word_list, ent_list, rel_list = split_to_list(dev_content)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, reserved_index, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_ent_tag = dict_inverse(ent_tag_to_ix)\n",
    "ix_to_rel_tag = dict_inverse(rel_tag_to_ix)\n",
    "#===============================================\n",
    "input_var, ent_var, rel_var, vocab_size, word_to_ix, raw_index, raw_input = preprocess(relation_data)\n",
    "loader = dataload(input_var, ent_var, rel_var, raw_index)\n",
    "\n",
    "input_dev, ent_dev, rel_dev, raw_index_dev, raw_input_dev = dev_preprocess(dev_data)\n",
    "dev_loader = dataload(input_dev, ent_dev, rel_dev, raw_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "# criterion_rel = nn.NLLLoss(ignore_index=rel_tag_to_ix[REL_PAD])\n",
    "criterion_rel = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<05:57,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | ent loss 0.6312 | rel loss 0.0579 | total loss 0.6891\n",
      "         | val ent loss 0.4642 | val rel loss 0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:07<05:50,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | ent loss 0.3630 | rel loss 0.0204 | total loss 0.3834\n",
      "         | val ent loss 0.3365 | val rel loss 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:10<05:51,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | ent loss 0.3380 | rel loss 0.0140 | total loss 0.3520\n",
      "         | val ent loss 0.3602 | val rel loss 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:14<05:49,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | ent loss 0.2704 | rel loss 0.0145 | total loss 0.2850\n",
      "         | val ent loss 0.3574 | val rel loss 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:18<05:46,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | ent loss 0.1705 | rel loss 0.0146 | total loss 0.1851\n",
      "         | val ent loss 0.2224 | val rel loss 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:22<05:44,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | ent loss 0.1606 | rel loss 0.0102 | total loss 0.1708\n",
      "         | val ent loss 0.1368 | val rel loss 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:25<05:38,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | ent loss 0.1007 | rel loss 0.0103 | total loss 0.1109\n",
      "         | val ent loss 0.2133 | val rel loss 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:29<05:34,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | ent loss 0.0714 | rel loss 0.0088 | total loss 0.0802\n",
      "         | val ent loss 0.2221 | val rel loss 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:32<05:31,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | ent loss 0.0509 | rel loss 0.0092 | total loss 0.0601\n",
      "         | val ent loss 0.1246 | val rel loss 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:36<05:25,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | ent loss 0.0346 | rel loss 0.0096 | total loss 0.0442\n",
      "          | val ent loss 0.1245 | val rel loss 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [00:39<05:21,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | ent loss 0.0566 | rel loss 0.0090 | total loss 0.0657\n",
      "          | val ent loss 0.2009 | val rel loss 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [00:43<05:18,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | ent loss 0.0764 | rel loss 0.0063 | total loss 0.0827\n",
      "          | val ent loss 0.1622 | val rel loss 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [00:46<05:13,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | ent loss 0.0253 | rel loss 0.0090 | total loss 0.0343\n",
      "          | val ent loss 0.1383 | val rel loss 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [00:50<05:08,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | ent loss 0.0226 | rel loss 0.0073 | total loss 0.0299\n",
      "          | val ent loss 0.1249 | val rel loss 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [00:54<05:06,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | ent loss 0.0359 | rel loss 0.0084 | total loss 0.0443\n",
      "          | val ent loss 0.1822 | val rel loss 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [00:57<05:03,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | ent loss 0.0261 | rel loss 0.0075 | total loss 0.0336\n",
      "          | val ent loss 0.1682 | val rel loss 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [01:01<05:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | ent loss 0.0379 | rel loss 0.0051 | total loss 0.0430\n",
      "          | val ent loss 0.1555 | val rel loss 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [01:05<04:56,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | ent loss 0.0091 | rel loss 0.0064 | total loss 0.0155\n",
      "          | val ent loss 0.1717 | val rel loss 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [01:08<04:53,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | ent loss 0.0067 | rel loss 0.0074 | total loss 0.0141\n",
      "          | val ent loss 0.1348 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [01:12<04:51,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | ent loss 0.0065 | rel loss 0.0074 | total loss 0.0139\n",
      "          | val ent loss 0.1192 | val rel loss 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [01:16<04:47,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | ent loss 0.0068 | rel loss 0.0062 | total loss 0.0130\n",
      "          | val ent loss 0.1862 | val rel loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [01:20<04:44,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | ent loss 0.0080 | rel loss 0.0067 | total loss 0.0146\n",
      "          | val ent loss 0.1231 | val rel loss 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [01:23<04:40,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | ent loss 0.0202 | rel loss 0.0042 | total loss 0.0244\n",
      "          | val ent loss 0.1653 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [01:27<04:36,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | ent loss 0.0170 | rel loss 0.0058 | total loss 0.0228\n",
      "          | val ent loss 0.1851 | val rel loss 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [01:30<04:32,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | ent loss 0.0389 | rel loss 0.0049 | total loss 0.0438\n",
      "          | val ent loss 0.2099 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [01:34<04:28,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | ent loss 0.0279 | rel loss 0.0051 | total loss 0.0330\n",
      "          | val ent loss 0.2933 | val rel loss 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [01:37<04:23,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | ent loss 0.0151 | rel loss 0.0052 | total loss 0.0203\n",
      "          | val ent loss 0.2011 | val rel loss 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [01:41<04:20,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | ent loss 0.0369 | rel loss 0.0050 | total loss 0.0420\n",
      "          | val ent loss 0.1944 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [01:44<04:15,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | ent loss 0.0057 | rel loss 0.0039 | total loss 0.0096\n",
      "          | val ent loss 0.1172 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [01:47<04:11,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | ent loss 0.0064 | rel loss 0.0042 | total loss 0.0106\n",
      "          | val ent loss 0.2399 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [01:51<04:08,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | ent loss 0.0060 | rel loss 0.0041 | total loss 0.0102\n",
      "          | val ent loss 0.1906 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [01:54<04:03,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | ent loss 0.0050 | rel loss 0.0053 | total loss 0.0103\n",
      "          | val ent loss 0.1530 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [01:58<04:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | ent loss 0.0037 | rel loss 0.0037 | total loss 0.0075\n",
      "          | val ent loss 0.1771 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [02:02<03:56,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | ent loss 0.0064 | rel loss 0.0036 | total loss 0.0100\n",
      "          | val ent loss 0.1223 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [02:05<03:53,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | ent loss 0.0025 | rel loss 0.0035 | total loss 0.0060\n",
      "          | val ent loss 0.1631 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [02:08<03:49,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | ent loss 0.0036 | rel loss 0.0028 | total loss 0.0064\n",
      "          | val ent loss 0.1388 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [02:12<03:45,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | ent loss 0.0040 | rel loss 0.0036 | total loss 0.0076\n",
      "          | val ent loss 0.2504 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [02:15<03:41,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | ent loss 0.0025 | rel loss 0.0022 | total loss 0.0047\n",
      "          | val ent loss 0.1141 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [02:19<03:38,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | ent loss 0.0018 | rel loss 0.0027 | total loss 0.0046\n",
      "          | val ent loss 0.1290 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [02:23<03:35,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | ent loss 0.0041 | rel loss 0.0020 | total loss 0.0061\n",
      "          | val ent loss 0.1321 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [02:27<03:32,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | ent loss 0.0039 | rel loss 0.0023 | total loss 0.0063\n",
      "          | val ent loss 0.2607 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [02:30<03:28,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | ent loss 0.0054 | rel loss 0.0016 | total loss 0.0070\n",
      "          | val ent loss 0.1409 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [02:33<03:24,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | ent loss 0.0036 | rel loss 0.0021 | total loss 0.0057\n",
      "          | val ent loss 0.0799 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [02:37<03:20,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | ent loss 0.0042 | rel loss 0.0023 | total loss 0.0065\n",
      "          | val ent loss 0.1286 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [02:40<03:16,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | ent loss 0.0089 | rel loss 0.0026 | total loss 0.0116\n",
      "          | val ent loss 0.2000 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [02:44<03:12,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | ent loss 0.0014 | rel loss 0.0022 | total loss 0.0036\n",
      "          | val ent loss 0.1895 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [02:48<03:09,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | ent loss 0.0042 | rel loss 0.0016 | total loss 0.0058\n",
      "          | val ent loss 0.0671 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [02:51<03:05,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | ent loss 0.0049 | rel loss 0.0021 | total loss 0.0070\n",
      "          | val ent loss 0.0095 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [02:55<03:02,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | ent loss 0.0128 | rel loss 0.0030 | total loss 0.0157\n",
      "          | val ent loss 0.2719 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [02:58<02:58,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 | ent loss 0.0016 | rel loss 0.0021 | total loss 0.0037\n",
      "          | val ent loss 0.1705 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [03:02<02:55,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 | ent loss 0.0136 | rel loss 0.0020 | total loss 0.0155\n",
      "          | val ent loss 0.2930 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [03:06<02:52,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 | ent loss 0.0065 | rel loss 0.0024 | total loss 0.0089\n",
      "          | val ent loss 0.3684 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [03:10<02:48,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 | ent loss 0.0132 | rel loss 0.0019 | total loss 0.0151\n",
      "          | val ent loss 0.1987 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [03:13<02:45,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 | ent loss 0.0145 | rel loss 0.0022 | total loss 0.0167\n",
      "          | val ent loss 0.2551 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [03:17<02:41,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 | ent loss 0.0071 | rel loss 0.0023 | total loss 0.0094\n",
      "          | val ent loss 0.1316 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [03:21<02:38,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 | ent loss 0.0084 | rel loss 0.0035 | total loss 0.0119\n",
      "          | val ent loss 0.2124 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [03:24<02:34,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 | ent loss 0.0081 | rel loss 0.0031 | total loss 0.0113\n",
      "          | val ent loss 0.1824 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [03:28<02:30,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 | ent loss 0.0017 | rel loss 0.0017 | total loss 0.0034\n",
      "          | val ent loss 0.1434 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [03:31<02:26,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 | ent loss 0.0017 | rel loss 0.0019 | total loss 0.0035\n",
      "          | val ent loss 0.1457 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [03:34<02:23,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 | ent loss 0.0018 | rel loss 0.0017 | total loss 0.0034\n",
      "          | val ent loss 0.1101 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [03:38<02:19,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 | ent loss 0.0063 | rel loss 0.0020 | total loss 0.0084\n",
      "          | val ent loss 0.1662 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [03:41<02:15,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 | ent loss 0.0011 | rel loss 0.0016 | total loss 0.0027\n",
      "          | val ent loss 0.3032 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [03:45<02:12,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 | ent loss 0.0022 | rel loss 0.0021 | total loss 0.0043\n",
      "          | val ent loss 0.2640 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [03:48<02:08,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 | ent loss 0.0163 | rel loss 0.0018 | total loss 0.0181\n",
      "          | val ent loss 0.1345 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [03:52<02:05,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 | ent loss 0.0044 | rel loss 0.0016 | total loss 0.0060\n",
      "          | val ent loss 0.1537 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [03:55<02:01,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 | ent loss 0.0021 | rel loss 0.0019 | total loss 0.0040\n",
      "          | val ent loss 0.1684 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [03:59<01:57,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 | ent loss 0.0036 | rel loss 0.0014 | total loss 0.0050\n",
      "          | val ent loss 0.1295 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [04:03<01:54,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 | ent loss 0.0014 | rel loss 0.0016 | total loss 0.0031\n",
      "          | val ent loss 0.1347 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [04:06<01:50,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 | ent loss 0.0022 | rel loss 0.0018 | total loss 0.0040\n",
      "          | val ent loss 0.1393 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [04:09<01:46,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 | ent loss 0.0020 | rel loss 0.0017 | total loss 0.0036\n",
      "          | val ent loss 0.0827 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [04:13<01:43,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71 | ent loss 0.0082 | rel loss 0.0016 | total loss 0.0099\n",
      "          | val ent loss 0.2437 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [04:17<01:39,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 | ent loss 0.0019 | rel loss 0.0016 | total loss 0.0036\n",
      "          | val ent loss 0.2055 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [04:20<01:36,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 | ent loss 0.0013 | rel loss 0.0017 | total loss 0.0031\n",
      "          | val ent loss 0.1306 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [04:23<01:32,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 | ent loss 0.0008 | rel loss 0.0016 | total loss 0.0024\n",
      "          | val ent loss 0.1614 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [04:26<01:28,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 | ent loss 0.0033 | rel loss 0.0014 | total loss 0.0047\n",
      "          | val ent loss 0.2587 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [04:30<01:25,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76 | ent loss 0.0015 | rel loss 0.0016 | total loss 0.0031\n",
      "          | val ent loss 0.1259 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [04:33<01:21,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 | ent loss 0.0018 | rel loss 0.0014 | total loss 0.0031\n",
      "          | val ent loss 0.1464 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [04:37<01:18,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78 | ent loss 0.0300 | rel loss 0.0025 | total loss 0.0325\n",
      "          | val ent loss 0.1421 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [04:41<01:14,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 | ent loss 0.0164 | rel loss 0.0024 | total loss 0.0188\n",
      "          | val ent loss 0.1166 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [04:44<01:11,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80 | ent loss 0.0024 | rel loss 0.0024 | total loss 0.0048\n",
      "          | val ent loss 0.1259 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [04:48<01:07,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81 | ent loss 0.0027 | rel loss 0.0017 | total loss 0.0044\n",
      "          | val ent loss 0.3417 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [04:51<01:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82 | ent loss 0.0020 | rel loss 0.0019 | total loss 0.0039\n",
      "          | val ent loss 0.1969 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [04:55<01:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83 | ent loss 0.0020 | rel loss 0.0015 | total loss 0.0035\n",
      "          | val ent loss 0.1339 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [04:59<00:57,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 | ent loss 0.0276 | rel loss 0.0021 | total loss 0.0297\n",
      "          | val ent loss 0.3380 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [05:02<00:53,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85 | ent loss 0.0035 | rel loss 0.0021 | total loss 0.0056\n",
      "          | val ent loss 0.1294 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [05:06<00:49,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86 | ent loss 0.0126 | rel loss 0.0019 | total loss 0.0146\n",
      "          | val ent loss 0.1306 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [05:10<00:46,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 | ent loss 0.0007 | rel loss 0.0014 | total loss 0.0021\n",
      "          | val ent loss 0.1937 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [05:13<00:42,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88 | ent loss 0.0011 | rel loss 0.0015 | total loss 0.0025\n",
      "          | val ent loss 0.0292 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [05:17<00:39,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89 | ent loss 0.0007 | rel loss 0.0015 | total loss 0.0022\n",
      "          | val ent loss 0.1984 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [05:20<00:35,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90 | ent loss 0.0009 | rel loss 0.0018 | total loss 0.0026\n",
      "          | val ent loss 0.1613 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [05:24<00:32,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 | ent loss 0.0009 | rel loss 0.0019 | total loss 0.0028\n",
      "          | val ent loss 0.1946 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [05:27<00:28,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 | ent loss 0.0009 | rel loss 0.0017 | total loss 0.0026\n",
      "          | val ent loss 0.1068 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [05:30<00:24,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93 | ent loss 0.0018 | rel loss 0.0016 | total loss 0.0034\n",
      "          | val ent loss 0.1763 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [05:34<00:21,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 | ent loss 0.0041 | rel loss 0.0018 | total loss 0.0059\n",
      "          | val ent loss 0.4384 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [05:37<00:17,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 | ent loss 0.0009 | rel loss 0.0016 | total loss 0.0025\n",
      "          | val ent loss 0.2428 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [05:41<00:14,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96 | ent loss 0.0010 | rel loss 0.0015 | total loss 0.0025\n",
      "          | val ent loss 0.1960 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [05:44<00:10,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 | ent loss 0.0201 | rel loss 0.0017 | total loss 0.0217\n",
      "          | val ent loss 0.1135 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [05:48<00:07,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98 | ent loss 0.0031 | rel loss 0.0018 | total loss 0.0049\n",
      "          | val ent loss 0.2558 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [05:51<00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 | ent loss 0.0057 | rel loss 0.0019 | total loss 0.0077\n",
      "          | val ent loss 0.6018 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [05:54<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 | ent loss 0.0016 | rel loss 0.0017 | total loss 0.0033\n",
      "           | val ent loss 0.1413 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 100\n",
    "print_every = 12\n",
    "\n",
    "train_entloss_l = []\n",
    "val_entloss_l = []\n",
    "train_relloss_l = []\n",
    "val_relloss_l = []\n",
    "\n",
    "loss = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(n_iters)):  \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "        batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "        \n",
    "        entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "        relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "        loss = entloss+relloss\n",
    "        \n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    train_entloss_l.append(entloss.cpu())\n",
    "    train_relloss_l.append(relloss.cpu())\n",
    "    #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "        \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "        model.eval()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "        val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "        \n",
    "    val_entloss_l.append(val_entloss.cpu())\n",
    "    val_relloss_l.append(val_relloss.cpu())\n",
    "    \n",
    "    \n",
    "    print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "          % (epoch+1, entloss, relloss, loss))\n",
    "    print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "          % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "torch.save(model.state_dict(), 'relation_extraction_1_new.pkl')\n",
    "\n",
    "# model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "#               LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "# model.load_state_dict(torch.load('relation_extraction.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_entloss_l, label='train_ent_loss')\n",
    "plt.plot(val_entloss_l, label='val_ent_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entity Loss\") \n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_relloss_l, label='train_rel_loss')\n",
    "plt.plot(val_relloss_l, label='val_rel_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relation Loss\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_choose(input_var):\n",
    "    r_choose = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        r_choose.append(random.randint(0,len(input_var)))\n",
    "    return r_choose\n",
    "        \n",
    "def ent_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,ent_size).argmax(2)\n",
    "    return output\n",
    "\n",
    "def rel_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,MAX_LEN,rel_size).argmax(3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict : ['O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "true : ['O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Entity loss : 0.0021\n",
      "Relation loss : 0.0015\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    r_choose = random_choose(input_var)\n",
    "    model.eval()\n",
    "    ent_output, rel_output = model(input_var[r_choose].cuda() if USE_CUDA else input_var, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "    \n",
    "    batchsize = input_var[r_choose].size(0)\n",
    "    \n",
    "    ent_loss = criterion_tag(ent_output.cpu(), ent_var[r_choose].view(BATCH_SIZE*MAX_LEN))\n",
    "    ent_output = ent_argmax(ent_output, batchsize)\n",
    "    \n",
    "    rel_loss = criterion_rel(rel_output.cpu(), rel_var[r_choose].view(BATCH_SIZE*MAX_LEN*MAX_LEN))\n",
    "    \n",
    "    print()\n",
    "    print('predict :', index2tag(ent_output[0], ix_to_ent_tag))\n",
    "    print('true :', index2tag(ent_var[r_choose[0]], ix_to_ent_tag))\n",
    "    \n",
    "    print()\n",
    "    print(\"Entity loss : %.4f\" % ent_loss)\n",
    "    print(\"Relation loss : %.4f\" % rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "def evaluate_data(data_loader, raw_input, isTrain=False, silent=False):\n",
    "    tps, fps, tns, fns = 0, 0, 0, 0\n",
    "    y_ent_true_all, y_ent_pred_all = [], []\n",
    "    y_rel_true_all, y_rel_pred_all = [], []\n",
    "    print_every_batch = 5\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(data_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            ent_loss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN))\n",
    "            ent_output = ent_argmax(ent_output, batchsize)\n",
    "\n",
    "            rel_loss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "            rel_output = rel_argmax(rel_output, batchsize)\n",
    "\n",
    "            \n",
    "            if not silent:\n",
    "                print()    \n",
    "                print(\"Entity loss : %.4f\" % ent_loss)\n",
    "                print(\"Relation loss : %.4f\" % rel_loss)\n",
    "                print()\n",
    "                print('===========================================')\n",
    "                \n",
    "#             elif step%print_every_batch==0:\n",
    "#                 print()    \n",
    "#                 print(\"Entity loss : %.4f\" % ent_loss)\n",
    "#                 print(\"Relation loss : %.4f\" % rel_loss)\n",
    "#                 print()\n",
    "#                 print('===========================================')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel = \\\n",
    "            batch_decode(ent_output, rel_output, batch_index, raw_input, batch_ent, batch_rel, silent)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            y_ent_true_all.extend(y_true_ent)\n",
    "            y_ent_pred_all.extend(y_pred_ent)\n",
    "\n",
    "            y_rel_true_all.extend(y_true_rel)\n",
    "            y_rel_pred_all.extend(y_pred_rel)\n",
    "            \n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            tns += tn\n",
    "            fns += fn\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"Entity detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_ent_true_all, y_ent_pred_all, average='micro', \n",
    "                                                  labels=range(len(schema['entity'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"Relation detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_rel_true_all, y_rel_pred_all, average='micro', \n",
    "                                              labels=range(len(schema['relation'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"ReferenceEntity+Relation score\")\n",
    "        print(\"%s \\t %s \\t %s \\t    %s %s %s %s\" % ('precision ', 'recall ', 'fbeta_score ', 'tp', 'fp', 'tn', 'fn'))\n",
    "        p_r_f1 = p_r_fscore(tps, fps, tns, fns)\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t\\t    %d %d %d %d' % (p_r_f1[0], p_r_f1[1], p_r_f1[2], tps, fps, tns, fns))\n",
    "\n",
    "            \n",
    "            \n",
    "def batch_decode(ent_output, rel_output, batch_index, word_lists, true_ent, true_rel, silent):\n",
    "    \n",
    "    eval_ent_list_true_l, eval_rel_list_true_l = [], []\n",
    "    eval_ent_list_pred_l, eval_rel_list_pred_l = [], []\n",
    "    \n",
    "    for e,r,i,te,tr in zip(ent_output, rel_output, batch_index, true_ent, true_rel):\n",
    "        \n",
    "        # 算句子長度\n",
    "        len_of_list = len(word_lists[i])\n",
    "        word_list = word_lists[i]\n",
    "        true_ent = index2tag(te, ix_to_ent_tag)[:len_of_list]\n",
    "        pridict_ent = index2tag(e, ix_to_ent_tag)[:len_of_list]     \n",
    "        \n",
    "        # 單句decode關係\n",
    "        true_r_list, appear_error = decode_rel(te, tr)   # true\n",
    "        pre_r_list, appear_error = decode_rel(e, r)      # predict\n",
    "        \n",
    "        true_r_list = [list(set(i)) if type(i) is list else i for i in true_r_list]\n",
    "        pre_r_list = [list(set(i)) if type(i) is list else i for i in pre_r_list]\n",
    "        \n",
    "        # 出現error，跳過這句\n",
    "        if appear_error:\n",
    "            continue\n",
    "        \n",
    "        true_r_list = true_r_list[:len_of_list]\n",
    "        pre_r_list = pre_r_list[:len_of_list]\n",
    "        \n",
    "        \n",
    "        # 評分用\n",
    "        eval_ent_list_true, err_count = decode_ent(true_ent, schema)\n",
    "        eval_rel_list_true = decode_rel_to_eval(true_r_list, schema, eval_ent_list_true)\n",
    "        \n",
    "        eval_ent_list_pred, err_count = decode_ent(pridict_ent, schema)\n",
    "        eval_rel_list_pred = decode_rel_to_eval(pre_r_list, schema, eval_ent_list_pred)\n",
    "        \n",
    "        if not silent:\n",
    "            print(word_list)\n",
    "            print(true_ent)\n",
    "            print(true_r_list)\n",
    "            print()\n",
    "            print('Predict output')\n",
    "            print(pridict_ent)\n",
    "            print(pre_r_list)\n",
    "            print()\n",
    "            print('True')\n",
    "            print(eval_ent_list_true)\n",
    "            print(eval_rel_list_true)\n",
    "            print('predict')\n",
    "            print(eval_ent_list_pred)\n",
    "            print(eval_rel_list_pred)\n",
    "            print(\"=====================================\")\n",
    "        \n",
    "        eval_ent_list_true_l.append(eval_ent_list_true)\n",
    "        eval_rel_list_true_l.append(eval_rel_list_true)\n",
    "        eval_ent_list_pred_l.append(eval_ent_list_pred)\n",
    "        eval_rel_list_pred_l.append(eval_rel_list_pred)\n",
    "    \n",
    "    \n",
    "    e_score, y_true_ent, y_pred_ent = get_scores(eval_ent_list_true_l, eval_ent_list_pred_l, \\\n",
    "                                                 range(len(schema['entity'])),output_y=True)\n",
    "    r_score, y_true_rel, y_pred_rel = get_scores(eval_rel_list_true_l, eval_rel_list_pred_l, \\\n",
    "                                                 range(len(schema['relation'])),output_y=True)\n",
    "    \n",
    "    tp, fp, tn, fn = relation_error_analysis(eval_rel_list_true_l, eval_rel_list_pred_l)\n",
    "    \n",
    "    if not silent:\n",
    "        print('Batch entity score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(e_score)\n",
    "        print()\n",
    "        print('Batch relation score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(r_score)\n",
    "        print()\n",
    "        print('p_r_fscore')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tp, fp, tn, fn), tp, fp, tn, fn)\n",
    "        print('===========================================')\n",
    "    \n",
    "    return tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def decode_ent(pred_ent, schema):\n",
    "    '''\n",
    "    Aggregate entities from predicted tags\n",
    "    Input:\n",
    "    pred_ent=a list of entity tags in a sentence\n",
    "    schema=the dictionary defining entities and relations\n",
    "    Output: \n",
    "    ent_list=[(ent_start, ent_end, ent_type=eid_in_schema)]\n",
    "    err_count=the number of bad tags\n",
    "    '''\n",
    "    ent_list = []\n",
    "    ent_start = 0\n",
    "    ent_end = 0\n",
    "    state = {\n",
    "        'ENT_SPAN': 0,\n",
    "        'NO_ENT': 1\n",
    "    }\n",
    "    err_count = 0\n",
    "    ent_type = ''\n",
    "    sid = state['NO_ENT']\n",
    "    for idx, e_tag in enumerate(pred_ent):\n",
    "        bio = e_tag[0]\n",
    "        type_tag = e_tag.split('-')[-1]\n",
    "        if sid == state['NO_ENT']:\n",
    "            if bio == 'B':\n",
    "                ent_start = idx\n",
    "                ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                sid = state['ENT_SPAN']\n",
    "            elif bio == 'I':\n",
    "                err_count += 1\n",
    "        elif sid == state['ENT_SPAN']:\n",
    "            if bio != 'I':\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                if bio == 'B':\n",
    "                    ent_start = idx\n",
    "                    ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                else:\n",
    "                    sid = state['NO_ENT']\n",
    "            elif ent_type != get_eid_from_tag(type_tag, schema):\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                err_count += 1\n",
    "                sid = state['NO_ENT']\n",
    "    if sid == state['ENT_SPAN']:\n",
    "        ent_end = len(pred_ent) - 1\n",
    "        ent_list.append((ent_start, ent_end, ent_type))\n",
    "    return ent_list, err_count\n",
    "\n",
    "def get_eid_from_tag(tag, schema):\n",
    "    '''\n",
    "    Assume schema is a dictionary in schema.txt\n",
    "    return eid or -1 if no match is found\n",
    "    '''\n",
    "    for content in schema['entity'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['eid']\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def decode_rel_to_eval(r_list, schema, ent_list):\n",
    "    \n",
    "    max_pair = 0\n",
    "    for r in r_list:\n",
    "        if type(r) is list:\n",
    "            for single_r in r:\n",
    "                if int(single_r[-3])>max_pair:\n",
    "                    max_pair = int(single_r[-3])\n",
    "    \n",
    "\n",
    "    pair_idx = {}\n",
    "    for pair in range(max_pair+1):\n",
    "        for i, r in enumerate(r_list):\n",
    "            if type(r) is list:\n",
    "                for single_r in r:\n",
    "                    if int(single_r[-3])==pair:\n",
    "                        if pair not in pair_idx:\n",
    "                            pair_idx[pair] = [i]\n",
    "                        else:\n",
    "                            pair_idx[pair].append(i)\n",
    "    \n",
    "    \n",
    "#     # 算兩兩不同tag的數目\n",
    "#     e_type_dict = {}\n",
    "#     for e_pair in ent_list:\n",
    "#         if e_pair[-1] not in e_type_dict:\n",
    "#             e_type_dict[e_pair[-1]] = 1\n",
    "#         else:\n",
    "#             e_type_dict[e_pair[-1]] += 1\n",
    "    \n",
    "#     total_pair = 0\n",
    "#     e_type_l = list(e_type_dict.values())\n",
    "#     for i, ent_type_num_1 in enumerate(e_type_l):\n",
    "#         for j, ent_type_num_2 in enumerate(e_type_l[i+1:]):\n",
    "#             pair_num = ent_type_num_1*ent_type_num_2\n",
    "#             total_pair += pair_num\n",
    "\n",
    "    pair_list = []\n",
    "    for i, e_pair_1 in enumerate(ent_list):\n",
    "        for j, e_pair_2 in enumerate(ent_list[i+1:]):\n",
    "            if e_pair_1[-1]!=e_pair_2[-1]:\n",
    "                pair_list.append([e_pair_1, e_pair_2])\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    eval_rel_list = []\n",
    "    for pair in pair_idx:\n",
    "        rel_loc = pair_idx[pair]\n",
    "        for e_pairs in pair_list:\n",
    "            check_pair = True\n",
    "            first_start = e_pairs[0][0]\n",
    "            first_end = e_pairs[0][1]\n",
    "            sec_start = e_pairs[1][0]\n",
    "            sec_end = e_pairs[1][1]\n",
    "            \n",
    "            first_l = list(range(first_start, first_end+1))\n",
    "            sec_l = list(range(sec_start, sec_end+1))\n",
    "            combine_l = first_l+sec_l\n",
    "\n",
    "            \n",
    "            check_in_entity = []\n",
    "            for x in combine_l:\n",
    "                if x in rel_loc:\n",
    "                    check_in_entity.append(True)\n",
    "                else:\n",
    "                    check_in_entity.append(False)\n",
    "                    check_pair = False\n",
    "                    break             \n",
    "\n",
    "            if all(check_in_entity)==True:\n",
    "                for r in r_list[first_start]:\n",
    "                    r_info = r.split('-')\n",
    "                    \n",
    "                    if int(r_info[1])==pair:\n",
    "                        r_tag = get_rid_from_tag(r_info[0], schema)\n",
    "                        e_pairs_copy = e_pairs\n",
    "                        e_pairs_copy.append(r_tag)\n",
    "                        eval_rel_list.append(tuple(e_pairs_copy))\n",
    "    \n",
    "    return eval_rel_list\n",
    "    \n",
    "        \n",
    "def get_rid_from_tag(tag, schema):   \n",
    "    for content in schema['relation'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['rid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rel_info(ent_output):\n",
    "    r_list = []     # 存放完整關係\n",
    "    r_dict = {}     # 記錄關係資訊\n",
    "    appear_error = False\n",
    "\n",
    "    pred_ent = index2tag(ent_output, ix_to_ent_tag)\n",
    "    \n",
    "\n",
    "    e_loc = 0       # 當前遇到的entity的位置\n",
    "    for loc, e in enumerate(pred_ent):\n",
    "        if e[0]=='B':\n",
    "            e_loc = loc\n",
    "            r_dict[loc] = {\n",
    "                '_2ndtag':e[2:],\n",
    "                'end':loc,\n",
    "            }\n",
    "            r_list.append([])\n",
    "                   \n",
    "        elif e[0]=='I':\n",
    "            # 錯誤來自於，entity預測錯誤，沒有預測到B tag，直接跳到I tag\n",
    "            # 所以沒有紀錄e_loc\n",
    "            try: \n",
    "                r_dict[e_loc]['end'] = loc\n",
    "            except KeyError:\n",
    "                appear_error = True\n",
    "                break\n",
    "            \n",
    "            r_list.append([])\n",
    "            \n",
    "        else:\n",
    "            r_list.append(\"\")\n",
    "              \n",
    "    return r_list, r_dict, appear_error\n",
    "        \n",
    "        \n",
    "def decode_rel(ent_output, rel_output):\n",
    "\n",
    "    r_list, r_dict, appear_error = create_rel_info(ent_output) \n",
    "    \n",
    "    IsB = False           # 是否遇到B tag的lock\n",
    "    IsNext = False        # 是否為B tag後面的tag 的lock\n",
    "    num_reocrd = -1       # 紀錄pair數\n",
    "    now_loc = 0\n",
    "    pre_rel_end_loc = 0\n",
    "    now_rel_end_loc = 0\n",
    "    \n",
    "    rel_keyerror = False\n",
    "    \n",
    "    for now in range(len(rel_output)):\n",
    "        for loc, rel in enumerate(rel_output[now][:now+1]):\n",
    "            rel = rel.cpu().numpy()\n",
    "            \n",
    "#             print(rel, IsB, IsNext)\n",
    "            \n",
    "            # 有關係存在，且為B tag \n",
    "            if rel!=rel_tag_to_ix[REL_NONE] and IsB==False and IsNext==False:\n",
    "\n",
    "                IsB = True\n",
    "                IsNext = True\n",
    "                tag = ix_to_rel_tag[int(rel)]\n",
    "                num_reocrd+=1\n",
    "                now_loc = loc\n",
    "                \n",
    "                # 錯誤來自於，now_loc找不到，也就是說，rel預測出來是有關係存在\n",
    "                # 但預測是'O'\n",
    "                # 而在entity中卻沒有預測出來，所以r_dict中沒有紀錄\n",
    "                try:\n",
    "                    pre_rel_end_loc = r_dict[now_loc]['end']\n",
    "\n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    now_rel_end_loc = r_dict[now]['end']\n",
    "                    \n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                second_tag = r_dict[now_loc]['_2ndtag']\n",
    "                preAorB = check_rel_loc(second_tag, schema)\n",
    "                nowAorB = 'B' if preAorB=='A' else 'A'\n",
    "                \n",
    "                pre_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+preAorB\n",
    "                now_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+nowAorB\n",
    "                \n",
    "                # 將以前的token填上關係\n",
    "                for token in range(now_loc, pre_rel_end_loc+1):\n",
    "                    \n",
    "                    # 出現以下error\n",
    "                    '''AttributeError: 'str' object has no attribute 'append'''\n",
    "                    # 為 r_list 前處理中沒有給予可能有關係的位置空的list\n",
    "                    try:\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "                    except AttributeError:\n",
    "                        r_list[token] = []\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "\n",
    "             \n",
    "                # 當前token填上關係\n",
    "                r_list[now].append(now_complete_rel)\n",
    "                \n",
    "\n",
    "            \n",
    "            # 關係前位中B tag後面的tag\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsB:\n",
    "                # 如果還在這個entity的範圍內\n",
    "                if loc<=pre_rel_end_loc:\n",
    "                    pass\n",
    "                \n",
    "                # 超出現在這個entity的範圍，改lock\n",
    "                else:\n",
    "                    IsB = False\n",
    "\n",
    "            \n",
    "            # B tag後面的tag的關係，依照前面的關係複製\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsNext:\n",
    "                r_list[now] = r_list[now-1]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if now<=now_rel_end_loc:\n",
    "                    IsB = False\n",
    "                else:\n",
    "                    IsB = False\n",
    "                    IsNext = False\n",
    "\n",
    "        \n",
    "        if rel_keyerror:\n",
    "            rel_keyerror = False\n",
    "            break\n",
    "                \n",
    "                \n",
    "    return r_list, appear_error\n",
    "                \n",
    "\n",
    "# 是三元關係中的前者還是後者                  \n",
    "def check_rel_loc(second_tag, schema):\n",
    "    convert_tag = ''\n",
    "\n",
    "    for ent_content in schema['entity']:\n",
    "        if schema['entity'][ent_content]['tag']==second_tag:\n",
    "            convert_tag = ent_content\n",
    "    \n",
    "    rel_types = schema['relation'].values()\n",
    "\n",
    "    for rel_content in schema['relation'].values():\n",
    "        for AorB in rel_content['arguments']:\n",
    "            if rel_content['arguments'][AorB]==convert_tag:\n",
    "                return AorB\n",
    "            \n",
    "\n",
    "            \n",
    "def get_scores(true_lists, pred_lists, labels, output_y=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for t_list, p_list in zip(true_lists, pred_lists):\n",
    "        yt, yp = align_yt_yp(t_list, p_list, labels)\n",
    "        y_true.extend(yt)\n",
    "        y_pred.extend(yp)\n",
    "        \n",
    "    scores = precision_recall_fscore_support(y_true, y_pred, average='micro', labels=labels)\n",
    "    return scores, y_true, y_pred if output_y else scores\n",
    "\n",
    "def align_yt_yp(truths, predictions, labels):\n",
    "    '''\n",
    "    Input:\n",
    "        truths/predictions: list of true and predicted tuples, \n",
    "        with the leading entries as the structure and the last entry as the class,\n",
    "        e.g., [(e1, e2, rel), ...]\n",
    "        labels: sequence of valid class\n",
    "    Output:\n",
    "        yt: list of true class given a structure\n",
    "        yp: list of predicted class given a structure\n",
    "    '''\n",
    "    yt, yp = [], []\n",
    "    _ID_NONE = len(labels)\n",
    "    true_dict = { t[:-1]: t[-1] for t in truths }\n",
    "    for p in predictions:\n",
    "        yt.append(true_dict.pop(p[:-1], _ID_NONE))\n",
    "        yp.append(p[-1])\n",
    "    for target in true_dict.values():\n",
    "        yt.append(target)\n",
    "        yp.append(_ID_NONE)\n",
    "    return yt, yp\n",
    "\n",
    "\n",
    "\n",
    "def is_neg_triple(t):\n",
    "    return np.imag(t[-1]) > 0\n",
    "\n",
    "def negate_triple(t):\n",
    "    # Mark negative triples with imaginary relation id\n",
    "    return (t[0], t[1], np.real(t[-1]).item() + 1j)\n",
    "\n",
    "def posit_triple(t):\n",
    "    return (t[0], t[1], np.real(t[-1]).item())\n",
    "\n",
    "def has_edge(base_ptrs, rel, e):\n",
    "    '''\n",
    "    Assume a relation exist between an entity pair, \n",
    "    if all the tokens in the base entity point to those in entity e.\n",
    "    '''\n",
    "    tok_has_ptr_to_e = [tok_ptrs[rel].ge(e[0]).dot(tok_ptrs[rel].le(e[1])).item() > 0 \n",
    "                        for tok_ptrs in base_ptrs]\n",
    "    return len(tok_has_ptr_to_e) > 0 and all(tok_has_ptr_to_e)\n",
    "\n",
    "\n",
    "def relation_error_analysis(true_rel_lists, rel_lists):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, r_list in enumerate(rel_lists):\n",
    "        true_pos = len([t for t in r_list if t in true_rel_lists[i]])\n",
    "        all_true = len([t for t in true_rel_lists[i] if not is_neg_triple(t)])\n",
    "        all_pos = len(r_list)\n",
    "        tp += true_pos\n",
    "        fn += all_true - true_pos\n",
    "        fp += all_pos - true_pos\n",
    "        tn += len([t for t in true_rel_lists[i] if is_neg_triple(t) and posit_triple(t) not in r_list])\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def p_r_fscore(tp, fp, tn, fn, beta=1, eps=1e-8):\n",
    "    p = tp / (tp + fp + eps)\n",
    "    r = tp / (tp + fn + eps)\n",
    "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r + eps))\n",
    "    return p, r, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.2378\n",
      "Relation loss : 0.0023\n",
      "\n",
      "===========================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 11, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[((2, 3, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 27, 1)]\n",
      "[((9, 10, 0), (24, 27, 1), 0)]\n",
      "=====================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[((25, 27, 1), (48, 49, 0), 0)]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 0), (30, 33, 1)]\n",
      "[((25, 26, 0), (30, 33, 1), 0)]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[((15, 18, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'I-STAT']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', []]\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (23, 25, 1), (49, 50, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7096774193548387, 0.9166666666666666, 0.7999999999999999, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5, 0.5555555555555556, 0.5263157894736842, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.49999999949999996, 0.5555555549382716, 0.5263157839335181) 5 5 0 4\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.2181\n",
      "Relation loss : 0.0022\n",
      "\n",
      "===========================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (9, 13, 1)]\n",
      "[((2, 3, 0), (9, 13, 1), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[((17, 18, 0), (29, 32, 1), 0)]\n",
      "=====================================\n",
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(6, 7, 0), (43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(2, 5, 1), (16, 17, 0), (19, 20, 0)]\n",
      "[((2, 5, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], '', [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[((5, 7, 1), (29, 30, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O']\n",
      "['', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1), (22, 23, 0)]\n",
      "[((4, 6, 1), (22, 23, 0), 0)]\n",
      "=====================================\n",
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1), (14, 15, 0)]\n",
      "[((4, 7, 1), (14, 15, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7575757575757576, 0.9615384615384616, 0.8474576271186441, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3333333333333333, 0.6666666666666666, 0.4444444444444444, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3333333330555555, 0.6666666655555555, 0.4444444395061729) 4 8 0 2\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0840\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[((29, 30, 0), (37, 38, 1), 0)]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(16, 17, 0), (24, 25, 1)]\n",
      "[((16, 17, 0), (24, 25, 1), 0)]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[((8, 12, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8, 0.8888888888888888, 0.8421052631578948, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.4, 0.6666666666666666, 0.5, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3999999992, 0.6666666644444444, 0.49999999406250006) 2 3 0 1\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.743 \t\t 0.932 \t\t 0.827 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.407 \t\t 0.611 \t\t 0.489 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.407 \t\t 0.611 \t\t 0.489 \t\t    11 16 0 7\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = root+'facial_r2.test'\n",
    "input_test, ent_test, rel_test, raw_index_test, raw_input_test = dev_preprocess(test_data)\n",
    "test_loader = dataload(input_test, ent_test, rel_test, raw_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.758 \t\t 0.946 \t\t 0.842 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.431 \t\t 0.727 \t\t 0.541 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.431 \t\t 0.727 \t\t 0.541 \t\t    93 123 0 35\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_train():\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "    criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "    criterion_rel = nn.NLLLoss()\n",
    "    \n",
    "    n_iters = 1\n",
    "    print_every = 12\n",
    "\n",
    "    train_entloss_l = []\n",
    "    val_entloss_l = []\n",
    "    train_relloss_l = []\n",
    "    val_relloss_l = []\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for epoch in tqdm(range(n_iters)):  \n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "            batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "\n",
    "            entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "            relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "            loss = entloss+relloss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        train_entloss_l.append(entloss.cpu())\n",
    "        train_relloss_l.append(relloss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "            val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "\n",
    "        val_entloss_l.append(val_entloss.cpu())\n",
    "        val_relloss_l.append(val_relloss.cpu())\n",
    "\n",
    "        \n",
    "        \n",
    "        evaluate_data(loader, raw_input, isTrain=True, silent=True)\n",
    "        \n",
    "        print()\n",
    "        print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "              % (epoch+1, entloss, relloss, loss))\n",
    "        print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "              % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.1460\n",
      "Relation loss : 0.0018\n",
      "\n",
      "===========================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[((29, 30, 0), (37, 38, 1), 0)]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[((8, 12, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 0), (30, 33, 1)]\n",
      "[((25, 26, 0), (30, 33, 1), 0)]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[((5, 7, 1), (29, 30, 0), 0)]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], '', [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8125, 0.9629629629629629, 0.8813559322033898, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5555555555555556, 0.625, 0.5882352941176471, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5555555549382716, 0.6249999992187499, 0.5882352884429066) 5 4 0 3\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.2410\n",
      "Relation loss : 0.0015\n",
      "\n",
      "===========================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(2, 5, 1), (16, 17, 0), (19, 20, 0)]\n",
      "[((2, 5, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(16, 17, 0), (24, 25, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1), (14, 15, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1), (22, 23, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (49, 52, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'O', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'I-STAT']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', [], '', [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', []]\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (23, 23, 1), (49, 50, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 11, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6944444444444444, 0.9259259259259259, 0.7936507936507936, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8333333333333334, 0.625, 0.7142857142857143, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8333333319444445, 0.6249999992187499, 0.7142857083673471) 5 1 0 3\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.2533\n",
      "Relation loss : 0.0023\n",
      "\n",
      "===========================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (9, 13, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(6, 7, 0), (43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.625, 0.8333333333333334, 0.7142857142857143, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(1.0, 0.5, 0.6666666666666666, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.9999999900000002, 0.4999999975, 0.6666666577777778) 1 0 0 1\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.737 \t\t 0.933 \t\t 0.824 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.688 \t\t 0.611 \t\t 0.647 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.687 \t\t 0.611 \t\t 0.647 \t\t    11 5 0 7\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.762 \t\t 0.950 \t\t 0.846 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.623 \t\t 0.734 \t\t 0.674 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.623 \t\t 0.734 \t\t 0.674 \t\t    94 57 0 34\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=False, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_var, ent_var, rel_var, raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
