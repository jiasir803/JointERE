{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def schema_load(schema_root):\n",
    "    raw_dict = \"\".join(readfile(schema_root))\n",
    "    dict2json = \"\".join(raw_dict.split()[2:])\n",
    "\n",
    "    json_acceptable_string = dict2json.replace(\"'\", \"\\\"\")\n",
    "    schema = json.loads(json_acceptable_string)\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def define_entity(schema):\n",
    "    tag_type = list(schema['tagging'])\n",
    "    \n",
    "    entity_tag = []\n",
    "    for k in list(schema['entity'].keys()):\n",
    "        entity_tag.append(schema['entity'][k]['tag'])\n",
    "        \n",
    "    TAG = []\n",
    "    for t in tag_type:\n",
    "        for e in entity_tag:\n",
    "            if t!='O':\n",
    "                TAG.append(t+'-'+e)  \n",
    "                \n",
    "    TAG = [UNKOWN_TAG, PAD_TAG] + TAG + ['O']   \n",
    "\n",
    "    return TAG\n",
    "\n",
    "def tag2ix(TAG):\n",
    "    tag_to_ix={t:i for i,t in enumerate(TAG)}\n",
    "    return tag_to_ix\n",
    "\n",
    "def define_relation(schema):\n",
    "    relation_type = list(schema['relation'])\n",
    "    \n",
    "    relation_tag = []\n",
    "    for k in list(schema['relation'].keys()):\n",
    "        relation_tag.append(schema['relation'][k]['tag'])\n",
    "    \n",
    "    relation_tag = [REL_PAD] + [REL_NONE] + relation_tag\n",
    "        \n",
    "    return relation_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_set = word_set.split()\n",
    "        if len(word_set)==1:\n",
    "            word_list.append(' ')\n",
    "            ent_list.append('O')\n",
    "            rel_list.append(REL_NONE)\n",
    "        \n",
    "        else:\n",
    "            word_list.append(word_set[0])\n",
    "            ent_list.append(word_set[1])\n",
    "\n",
    "            try:\n",
    "                testerror = word_set[2]\n",
    "            except IndexError:\n",
    "                rel_list.append(REL_NONE)\n",
    "            else:\n",
    "                rel_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "\n",
    "    for now_token, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, ents, rels = get_word_and_label(content, init, now_token)\n",
    "            init = now_token+1\n",
    "            word_list.append(words)\n",
    "            ent_list.append(ents)\n",
    "            rel_list.append(rels)\n",
    "            \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, ent_list, rel_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_ent = list(ent_list[i] for i in reserved_index)\n",
    "    filter_rel = list(rel_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_ent, filter_rel\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq, isrel):\n",
    "    if isrel:\n",
    "        seq += [REL_NONE for i in range(MAX_LEN-len(seq))]\n",
    "    else:\n",
    "        seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_ent, filter_rel):\n",
    "    input_padded = [pad_seq(s, False) for s in filter_word]\n",
    "    ent_padded = [pad_seq(s, False) for s in filter_ent]\n",
    "    rel_padded = [pad_seq(s, True) for s in filter_rel]\n",
    "    \n",
    "    return input_padded, ent_padded, rel_padded\n",
    "\n",
    "def deep_copy_lists(filter_word, filter_ent, filter_rel):\n",
    "    f_w = copy.deepcopy(filter_word)\n",
    "    f_e = copy.deepcopy(filter_ent)\n",
    "    f_r = copy.deepcopy(filter_rel)\n",
    "    \n",
    "    return f_w, f_e, f_r\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "\n",
    "\n",
    "def prepare_rel(rel_padded, to_ix):\n",
    "    \n",
    "    rel_ptr = torch.zeros(len(rel_padded), MAX_LEN, MAX_LEN, dtype=torch.long) \n",
    "    \n",
    "    # 對當前的token，去比較之前所有出現過的entity，是否有關係，建成矩陣\n",
    "    # [B*ML*ML]，第二維ML是當前token，第三維ML是根據當前token對之前出現過的entity紀錄關係，以index紀錄\n",
    "    for i, rel_seq in enumerate(rel_padded):\n",
    "        rel_dict = {}\n",
    "        for j, token_seq in enumerate(rel_seq):\n",
    "            rel_ptr[i][j][:j+1] = 1\n",
    "            if token_seq != REL_NONE:\n",
    "                for k, rel in enumerate(token_seq):\n",
    "\n",
    "                    # if 是第一次出現，紀錄後面數字(標第幾對)和關係位置(A OR B)\n",
    "                    # 假如下次出現又是同個關係位置(A)，依然紀錄\n",
    "                    # 直到下次出現關係位置B，依照之前紀錄的A位置的字，然後在第三維去標關係\n",
    "\n",
    "                    rel_token = rel.split('-')\n",
    "                    if rel_token[1] not in rel_dict:\n",
    "                        rel_dict[rel_token[1]] = {'rel':rel_token[0], 'loc':rel_token[2], 'idx':[j]}\n",
    "\n",
    "                    elif rel_token[1] in rel_dict and rel_dict[rel_token[1]]['loc']==rel_token[2]:\n",
    "                        rel_dict[rel_token[1]]['idx'].append(j)\n",
    "\n",
    "                    else:\n",
    "                        record_loc = rel_dict[rel_token[1]]['idx']\n",
    "                        for idxx in record_loc:\n",
    "                            rel_ptr[i][j][idxx] = to_ix[rel_token[0]]\n",
    "                            \n",
    "    return rel_ptr\n",
    "                \n",
    "\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def dataload(input_var, ent_var, rel_var, raw_input):\n",
    "    torch_dataset = Data.TensorDataset(input_var, ent_var, rel_var, raw_input)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=2,       \n",
    "#         drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_entity(entity):\n",
    "    entity = entity.view(BATCH_SIZE,ent_size).argmax(1)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output, rel_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        self.rel_size = rel_size\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.w2 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(self.attn_output, self.rel_size, bias=False)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        \n",
    "        decoder = encoder_outputs[:,-1,:].unsqueeze(1)                       #B*1*(ts+LE) [128,1,8]\n",
    "        encoder_score = self.w1(encoder_outputs)                             #B*now len*ATTN_OUT\n",
    "        decoder_score = self.w2(decoder)                                     #B*1*ATTN_OUT\n",
    "        energy = self.tanh(encoder_score+decoder_score)                      #B*now len*ATTN_OUT            \n",
    "        \n",
    "        energy = self.v(energy)                                              #B*now len*rel_size\n",
    "        \n",
    "        \n",
    "        # 針對每個entity做softmax，去顯示他們的關係權重\n",
    "        # 主要都會是rel_none\n",
    "        # 對第二維(rel)做softmax\n",
    "        p = self.softmax(energy)                                         #B*now len*rel_size\n",
    "        \n",
    "        return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, ent_tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim, rel_tag_to_ix):\n",
    "        \n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.ent_to_ix = ent_tag_to_ix\n",
    "        self.ent_size = len(ent_tag_to_ix)                   #es\n",
    "        self.rel_to_ix = rel_tag_to_ix\n",
    "        self.rel_size = len(rel_tag_to_ix)                   #rs           \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim1, momentum=0.5, affine=False)\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "#                             num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)        \n",
    "        self.bilstm = nn.GRU(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.ent_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.ent_size, self.label_embed_dim)\n",
    "        \n",
    "        self.attn = Attn(ATTN_IN, ATTN_OUT, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, self.batch, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(self.batch, self.hidden_dim2)              #B*h2\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(self.batch, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_entity(self):\n",
    "        output_tensor = torch.zeros(self.batch, MAX_LEN, self.ent_size)  #B*ML*es\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "    \n",
    "    def create_rel_matrix(self):\n",
    "        rel_tensor = torch.zeros(self.batch, MAX_LEN, MAX_LEN, self.rel_size)  #B*ML*ML*rs\n",
    "        return rel_tensor.cuda()if USE_CUDA else rel_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, batch_ent, isTrain=True):\n",
    "        \n",
    "        self.batch = sentence.size(0)\n",
    "#         self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        entity_tensor = self.create_entity()                    #B*ML*es\n",
    "        rel_tensor = self.create_rel_matrix()                   #B*ML*ML*rs\n",
    "        \n",
    "        \n",
    "\n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "#         bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        bilstm_out, hidden1 = self.bilstm(embeds)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        # bn\n",
    "        bilstm_out = self.bn(bilstm_out)\n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence_l = [] \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            \n",
    "            if length==0:\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*es,[128, 5]            \n",
    "            ent_output = self.softmax(to_tags)                               #B*es,[128, 5]  \n",
    "            s_ent_output = self.softmax_entity(ent_output)\n",
    "            ent_onehot = self.one_hot(s_ent_output)\n",
    "            \n",
    "            \n",
    "            if isTrain:\n",
    "                label = self.label_embed(ent_onehot)                             #B*LE,[128, 3]\n",
    "#                 label = self.label_embed(ent_output) \n",
    "            else:\n",
    "                batch_ent_onehot = self.one_hot(batch_ent[:,length])\n",
    "                label = self.label_embed(batch_ent_onehot)\n",
    "            \n",
    "     \n",
    "            \n",
    "            # Assignments to Variables are in-place operations.\n",
    "            # Use that variable in lots of other contexts \n",
    "            # and some of the functions require it to not change. \n",
    "            to_tags_clone = to_tags.clone()\n",
    "            label_clone = label.clone()\n",
    "            \n",
    "            \n",
    "#             for i, tag in enumerate(s_ent_output):\n",
    "#                 if tag==ent_tag_to_ix['O']:\n",
    "#                     to_tags_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "#                     label_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "                    \n",
    "            # relation layer\n",
    "#             encoder_sequence_l.append(torch.cat((to_tags,label),1)) \n",
    "            encoder_sequence_l.append(torch.cat((h_next,label),1))  \n",
    "            encoder_sequence = torch.stack(encoder_sequence_l).t()     #B*len*(es+LE), [128,1,8]          \n",
    "\n",
    "            # Calculate attention weights \n",
    "            attn_weights = self.attn(encoder_sequence)\n",
    "\n",
    "        \n",
    "            entity_tensor[:,length,:] = ent_output\n",
    "            \n",
    "            # rel_tensor[:,length, 頭~當前 ,:]\n",
    "            rel_tensor[:,length,:length+1,:] = attn_weights\n",
    "\n",
    "        \n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return entity_tensor.view(self.batch*MAX_LEN, self.ent_size), \\\n",
    "               rel_tensor.view(self.batch*MAX_LEN*MAX_LEN, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def softmax_entity(self, entity):\n",
    "        entity = entity.view(self.batch,ent_size).argmax(1)\n",
    "        return entity\n",
    "    \n",
    "    \n",
    "    def one_hot(self, batch_ent):   \n",
    "        batchsize = batch_ent.size(0)\n",
    "        nb_digits = len(ent_tag_to_ix)\n",
    "        batch_ent = torch.unsqueeze(batch_ent, 1)\n",
    "        y_onehot = torch.cuda.FloatTensor(batchsize, nb_digits)        \n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, batch_ent, 1)    \n",
    "\n",
    "        return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "relation_data_old = root+'facial_r.old.train'\n",
    "# relation_data = root+'facial_r.train'\n",
    "relation_data = root+'facial_r2.train'\n",
    "schema_root = root+'schema_2.txt'\n",
    "dev_data = root+'facial_r2.dev'\n",
    "test_data = root+'facial_r2.test'\n",
    "\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "REL_NONE = 'Rel-None'\n",
    "REL_PAD = 'Rel-Pad'\n",
    "rule = ('FUNC', 'ApplyTo', 'STAT')\n",
    "\n",
    "schema = schema_load(schema_root)\n",
    "ENT_TAG = define_entity(schema)\n",
    "REL_TAG = define_relation(schema)\n",
    "ent_tag_to_ix = tag2ix(ENT_TAG)\n",
    "'''{'<PAD>': 1,\n",
    " '<UNKNOWN>': 0,\n",
    " 'B-FUNC': 2,\n",
    " 'B-STAT': 3,\n",
    " 'I-FUNC': 4,\n",
    " 'I-STAT': 5,\n",
    " 'O': 6}'''\n",
    "rel_tag_to_ix = tag2ix(REL_TAG)\n",
    "'''{'ApplyTo': 2, 'Rel-None': 1, 'Rel-Pad': 0}'''\n",
    "\n",
    "# ========hyper-parameter-set==========\n",
    "\n",
    "ent_size = len(ent_tag_to_ix)\n",
    "rel_size = len(rel_tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 18\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM1 = 10\n",
    "HIDDEN_DIM2 = 8\n",
    "LABEL_EMBED_DIM = ent_size\n",
    "DENSE_OUT = 100\n",
    "\n",
    "# ATTN_IN = ent_size+LABEL_EMBED_DIM\n",
    "ATTN_IN = HIDDEN_DIM2+LABEL_EMBED_DIM\n",
    "ATTN_OUT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    content = readfile(data)\n",
    "    word_list, ent_list, rel_list = split_to_list(content)\n",
    "    word_to_ix = word2index(word_list)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    #================================================\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, vocab_size, word_to_ix, reserved_index, word_list\n",
    "\n",
    "def dev_preprocess(dev_data):\n",
    "    dev_content = readfile(dev_data)\n",
    "    word_list, ent_list, rel_list = split_to_list(dev_content)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, reserved_index, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_ent_tag = dict_inverse(ent_tag_to_ix)\n",
    "ix_to_rel_tag = dict_inverse(rel_tag_to_ix)\n",
    "#===============================================\n",
    "input_var, ent_var, rel_var, vocab_size, word_to_ix, raw_index, raw_input = preprocess(relation_data)\n",
    "loader = dataload(input_var, ent_var, rel_var, raw_index)\n",
    "\n",
    "input_dev, ent_dev, rel_dev, raw_index_dev, raw_input_dev = dev_preprocess(dev_data)\n",
    "dev_loader = dataload(input_dev, ent_dev, rel_dev, raw_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "# criterion_rel = nn.NLLLoss(ignore_index=rel_tag_to_ix[REL_PAD])\n",
    "criterion_rel = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/70 [00:07<09:08,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | ent loss 0.6958 | rel loss 0.0710 | total loss 0.7668\n",
      "         | val ent loss 0.6545 | val rel loss 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/70 [00:15<09:02,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | ent loss 0.6938 | rel loss 0.0239 | total loss 0.7177\n",
      "         | val ent loss 0.5074 | val rel loss 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 3/70 [00:23<08:35,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | ent loss 0.6541 | rel loss 0.0133 | total loss 0.6675\n",
      "         | val ent loss 0.5591 | val rel loss 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 4/70 [00:30<08:25,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | ent loss 0.5256 | rel loss 0.0106 | total loss 0.5362\n",
      "         | val ent loss 0.5116 | val rel loss 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 5/70 [00:37<08:13,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | ent loss 0.3456 | rel loss 0.0090 | total loss 0.3546\n",
      "         | val ent loss 0.3095 | val rel loss 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 6/70 [00:44<07:50,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | ent loss 0.3143 | rel loss 0.0069 | total loss 0.3212\n",
      "         | val ent loss 0.3270 | val rel loss 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 7/70 [00:50<07:30,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | ent loss 0.2629 | rel loss 0.0066 | total loss 0.2695\n",
      "         | val ent loss 0.2159 | val rel loss 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 8/70 [00:56<07:15,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | ent loss 0.2479 | rel loss 0.0056 | total loss 0.2535\n",
      "         | val ent loss 0.2518 | val rel loss 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 9/70 [01:01<06:57,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | ent loss 0.2165 | rel loss 0.0046 | total loss 0.2211\n",
      "         | val ent loss 0.1750 | val rel loss 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 10/70 [01:07<06:47,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | ent loss 0.1831 | rel loss 0.0046 | total loss 0.1878\n",
      "          | val ent loss 0.2179 | val rel loss 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 11/70 [01:13<06:35,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | ent loss 0.1723 | rel loss 0.0046 | total loss 0.1769\n",
      "          | val ent loss 0.2208 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 12/70 [01:19<06:25,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | ent loss 0.2081 | rel loss 0.0040 | total loss 0.2121\n",
      "          | val ent loss 0.2091 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 13/70 [01:25<06:16,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | ent loss 0.1582 | rel loss 0.0050 | total loss 0.1632\n",
      "          | val ent loss 0.1830 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 14/70 [01:31<06:07,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | ent loss 0.1295 | rel loss 0.0038 | total loss 0.1334\n",
      "          | val ent loss 0.2307 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 15/70 [01:38<06:00,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | ent loss 0.1178 | rel loss 0.0043 | total loss 0.1221\n",
      "          | val ent loss 0.1228 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 16/70 [01:44<05:53,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | ent loss 0.0999 | rel loss 0.0042 | total loss 0.1041\n",
      "          | val ent loss 0.1045 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 17/70 [01:51<05:46,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | ent loss 0.1085 | rel loss 0.0033 | total loss 0.1117\n",
      "          | val ent loss 0.2575 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 18/70 [01:57<05:38,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | ent loss 0.0949 | rel loss 0.0041 | total loss 0.0990\n",
      "          | val ent loss 0.1056 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 19/70 [02:02<05:29,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | ent loss 0.0982 | rel loss 0.0030 | total loss 0.1011\n",
      "          | val ent loss 0.1905 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 20/70 [02:09<05:22,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | ent loss 0.0493 | rel loss 0.0030 | total loss 0.0523\n",
      "          | val ent loss 0.1863 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 21/70 [02:16<05:17,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | ent loss 0.0401 | rel loss 0.0037 | total loss 0.0438\n",
      "          | val ent loss 0.1251 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 22/70 [02:22<05:10,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | ent loss 0.0343 | rel loss 0.0044 | total loss 0.0388\n",
      "          | val ent loss 0.0886 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 23/70 [02:28<05:04,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | ent loss 0.0405 | rel loss 0.0028 | total loss 0.0433\n",
      "          | val ent loss 0.1330 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 24/70 [02:35<04:57,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | ent loss 0.0555 | rel loss 0.0039 | total loss 0.0594\n",
      "          | val ent loss 0.0937 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 25/70 [02:41<04:51,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | ent loss 0.0319 | rel loss 0.0036 | total loss 0.0356\n",
      "          | val ent loss 0.1393 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 26/70 [02:48<04:45,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | ent loss 0.0295 | rel loss 0.0041 | total loss 0.0336\n",
      "          | val ent loss 0.1573 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 27/70 [02:55<04:38,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | ent loss 0.0246 | rel loss 0.0029 | total loss 0.0275\n",
      "          | val ent loss 0.1550 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 28/70 [03:01<04:32,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | ent loss 0.0261 | rel loss 0.0034 | total loss 0.0295\n",
      "          | val ent loss 0.1279 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 29/70 [03:07<04:25,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | ent loss 0.0524 | rel loss 0.0024 | total loss 0.0548\n",
      "          | val ent loss 0.2037 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 30/70 [03:14<04:19,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | ent loss 0.0358 | rel loss 0.0029 | total loss 0.0387\n",
      "          | val ent loss 0.1150 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 31/70 [03:21<04:13,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | ent loss 0.0322 | rel loss 0.0031 | total loss 0.0353\n",
      "          | val ent loss 0.0980 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 32/70 [03:27<04:06,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | ent loss 0.0274 | rel loss 0.0027 | total loss 0.0301\n",
      "          | val ent loss 0.1022 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 33/70 [03:34<04:00,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | ent loss 0.0110 | rel loss 0.0021 | total loss 0.0132\n",
      "          | val ent loss 0.0994 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 34/70 [03:41<03:54,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | ent loss 0.0240 | rel loss 0.0027 | total loss 0.0268\n",
      "          | val ent loss 0.1306 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 35/70 [03:49<03:49,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | ent loss 0.0312 | rel loss 0.0021 | total loss 0.0333\n",
      "          | val ent loss 0.1325 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 36/70 [03:55<03:42,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | ent loss 0.0128 | rel loss 0.0021 | total loss 0.0149\n",
      "          | val ent loss 0.0844 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 37/70 [04:01<03:35,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | ent loss 0.0206 | rel loss 0.0023 | total loss 0.0229\n",
      "          | val ent loss 0.0279 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 38/70 [04:08<03:29,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | ent loss 0.0183 | rel loss 0.0022 | total loss 0.0205\n",
      "          | val ent loss 0.1710 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 39/70 [04:15<03:23,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | ent loss 0.0185 | rel loss 0.0026 | total loss 0.0211\n",
      "          | val ent loss 0.0424 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 40/70 [04:22<03:16,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | ent loss 0.0154 | rel loss 0.0023 | total loss 0.0178\n",
      "          | val ent loss 0.0753 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 41/70 [04:30<03:11,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | ent loss 0.0182 | rel loss 0.0022 | total loss 0.0204\n",
      "          | val ent loss 0.0990 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 42/70 [04:36<03:04,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | ent loss 0.0115 | rel loss 0.0021 | total loss 0.0135\n",
      "          | val ent loss 0.1372 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 43/70 [04:42<02:57,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | ent loss 0.0179 | rel loss 0.0025 | total loss 0.0205\n",
      "          | val ent loss 0.0603 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 44/70 [04:48<02:50,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | ent loss 0.0099 | rel loss 0.0018 | total loss 0.0117\n",
      "          | val ent loss 0.0987 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 45/70 [04:56<02:44,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | ent loss 0.0169 | rel loss 0.0021 | total loss 0.0190\n",
      "          | val ent loss 0.1429 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 46/70 [05:03<02:38,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | ent loss 0.0225 | rel loss 0.0020 | total loss 0.0245\n",
      "          | val ent loss 0.1225 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 47/70 [05:10<02:31,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | ent loss 0.0199 | rel loss 0.0018 | total loss 0.0216\n",
      "          | val ent loss 0.0875 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 48/70 [05:16<02:25,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | ent loss 0.0248 | rel loss 0.0018 | total loss 0.0265\n",
      "          | val ent loss 0.0326 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 49/70 [05:23<02:18,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | ent loss 0.0166 | rel loss 0.0019 | total loss 0.0184\n",
      "          | val ent loss 0.0724 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 50/70 [05:30<02:12,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 | ent loss 0.0186 | rel loss 0.0015 | total loss 0.0200\n",
      "          | val ent loss 0.1326 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 51/70 [05:36<02:05,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 | ent loss 0.0191 | rel loss 0.0019 | total loss 0.0210\n",
      "          | val ent loss 0.1022 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 52/70 [05:42<01:58,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 | ent loss 0.0140 | rel loss 0.0022 | total loss 0.0163\n",
      "          | val ent loss 0.1377 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 53/70 [05:49<01:52,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 | ent loss 0.0249 | rel loss 0.0018 | total loss 0.0267\n",
      "          | val ent loss 0.0751 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 54/70 [05:56<01:45,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 | ent loss 0.0055 | rel loss 0.0015 | total loss 0.0070\n",
      "          | val ent loss 0.1040 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 55/70 [06:03<01:39,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 | ent loss 0.0157 | rel loss 0.0019 | total loss 0.0176\n",
      "          | val ent loss 0.0631 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 56/70 [06:09<01:32,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 | ent loss 0.0225 | rel loss 0.0019 | total loss 0.0244\n",
      "          | val ent loss 0.1542 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 57/70 [06:16<01:25,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 | ent loss 0.0104 | rel loss 0.0017 | total loss 0.0120\n",
      "          | val ent loss 0.1289 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 58/70 [06:23<01:19,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 | ent loss 0.0069 | rel loss 0.0012 | total loss 0.0081\n",
      "          | val ent loss 0.0649 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 59/70 [06:30<01:12,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 | ent loss 0.0127 | rel loss 0.0017 | total loss 0.0144\n",
      "          | val ent loss 0.0855 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 60/70 [06:36<01:06,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 | ent loss 0.0060 | rel loss 0.0014 | total loss 0.0074\n",
      "          | val ent loss 0.0586 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 61/70 [06:42<00:59,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 | ent loss 0.0074 | rel loss 0.0015 | total loss 0.0090\n",
      "          | val ent loss 0.0769 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 62/70 [06:48<00:52,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 | ent loss 0.0093 | rel loss 0.0014 | total loss 0.0107\n",
      "          | val ent loss 0.1335 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 63/70 [06:55<00:46,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 | ent loss 0.0156 | rel loss 0.0015 | total loss 0.0171\n",
      "          | val ent loss 0.0325 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 64/70 [07:01<00:39,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 | ent loss 0.0057 | rel loss 0.0015 | total loss 0.0072\n",
      "          | val ent loss 0.0540 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 65/70 [07:08<00:32,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 | ent loss 0.0039 | rel loss 0.0013 | total loss 0.0051\n",
      "          | val ent loss 0.2180 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 66/70 [07:14<00:26,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 | ent loss 0.0060 | rel loss 0.0014 | total loss 0.0074\n",
      "          | val ent loss 0.0779 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 67/70 [07:21<00:19,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 | ent loss 0.0035 | rel loss 0.0013 | total loss 0.0048\n",
      "          | val ent loss 0.0904 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 68/70 [07:28<00:13,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 | ent loss 0.0108 | rel loss 0.0012 | total loss 0.0120\n",
      "          | val ent loss 0.0607 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 69/70 [07:35<00:06,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 | ent loss 0.0064 | rel loss 0.0015 | total loss 0.0079\n",
      "          | val ent loss 0.1078 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 70/70 [07:41<00:00,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 | ent loss 0.0047 | rel loss 0.0012 | total loss 0.0059\n",
      "          | val ent loss 0.1508 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 70\n",
    "print_every = 12\n",
    "\n",
    "train_entloss_l = []\n",
    "val_entloss_l = []\n",
    "train_relloss_l = []\n",
    "val_relloss_l = []\n",
    "\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "loss = 0\n",
    "ent_loss = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(n_iters)):  \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "        batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "        \n",
    "        entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "        relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "        loss = entloss+relloss\n",
    "        \n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    train_entloss_l.append(entloss.cpu())\n",
    "    train_relloss_l.append(relloss.cpu())\n",
    "    #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "        \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "        model.eval()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "        val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "        \n",
    "    val_entloss_l.append(val_entloss.cpu())\n",
    "    val_relloss_l.append(val_relloss.cpu())\n",
    "    \n",
    "    \n",
    "    print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "          % (epoch+1, entloss, relloss, loss))\n",
    "    print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "          % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "torch.save(model.state_dict(), 'relation_extraction_1_new.pkl')\n",
    "\n",
    "# model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "#               LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "# model.load_state_dict(torch.load('relation_extraction.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_entloss_l, label='train_ent_loss')\n",
    "plt.plot(val_entloss_l, label='val_ent_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entity Loss\") \n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_relloss_l, label='train_rel_loss')\n",
    "plt.plot(val_relloss_l, label='val_rel_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relation Loss\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_choose(input_var):\n",
    "    r_choose = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        r_choose.append(random.randint(0,len(input_var)))\n",
    "    return r_choose\n",
    "        \n",
    "def ent_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,ent_size).argmax(2)\n",
    "    return output\n",
    "\n",
    "def rel_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,MAX_LEN,rel_size).argmax(3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "true : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', '<PAD>']\n",
      "\n",
      "Entity loss : 0.0055\n",
      "Relation loss : 0.0013\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    r_choose = random_choose(input_var)\n",
    "    model.eval()\n",
    "    ent_output, rel_output = model(input_var[r_choose].cuda() if USE_CUDA else input_var, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "    \n",
    "    batchsize = input_var[r_choose].size(0)\n",
    "    \n",
    "    ent_loss = criterion_tag(ent_output.cpu(), ent_var[r_choose].view(BATCH_SIZE*MAX_LEN))\n",
    "    ent_output = ent_argmax(ent_output, batchsize)\n",
    "    \n",
    "    rel_loss = criterion_rel(rel_output.cpu(), rel_var[r_choose].view(BATCH_SIZE*MAX_LEN*MAX_LEN))\n",
    "    \n",
    "    print()\n",
    "    print('predict :', index2tag(ent_output[0], ix_to_ent_tag))\n",
    "    print('true :', index2tag(ent_var[r_choose[0]], ix_to_ent_tag))\n",
    "    \n",
    "    print()\n",
    "    print(\"Entity loss : %.4f\" % ent_loss)\n",
    "    print(\"Relation loss : %.4f\" % rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "def evaluate_data(data_loader, raw_input, isTrain=False, silent=False):\n",
    "    tps, fps, tns, fns = 0, 0, 0, 0\n",
    "    y_ent_true_all, y_ent_pred_all = [], []\n",
    "    y_rel_true_all, y_rel_pred_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(data_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            ent_loss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN))\n",
    "            ent_output = ent_argmax(ent_output, batchsize)\n",
    "\n",
    "            rel_loss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "            rel_output = rel_argmax(rel_output, batchsize)\n",
    "\n",
    "\n",
    "            print()    \n",
    "            print(\"Entity loss : %.4f\" % ent_loss)\n",
    "            print(\"Relation loss : %.4f\" % rel_loss)\n",
    "            print()\n",
    "\n",
    "            tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel = \\\n",
    "            batch_decode(ent_output, rel_output, batch_index, raw_input, batch_ent, batch_rel, silent)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('===========================================')\n",
    "\n",
    "            y_ent_true_all.extend(y_true_ent)\n",
    "            y_ent_pred_all.extend(y_pred_ent)\n",
    "\n",
    "            y_rel_true_all.extend(y_true_rel)\n",
    "            y_rel_pred_all.extend(y_pred_rel)\n",
    "            \n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            tns += tn\n",
    "            fns += fn\n",
    "            \n",
    "    \n",
    "        print()\n",
    "        print(\"Entity detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(precision_recall_fscore_support(y_ent_true_all, y_ent_pred_all, average='micro', \n",
    "                                                  labels=range(len(schema['entity']))))\n",
    "        print()\n",
    "        print(\"Relation detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(precision_recall_fscore_support(y_rel_true_all, y_rel_pred_all, average='micro', \n",
    "                                              labels=range(len(schema['relation']))))\n",
    "        print()\n",
    "        print(\"ReferenceEntity+Relation score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tps, fps, tns, fns), tps, fps, tns, fns)\n",
    "            \n",
    "            \n",
    "def batch_decode(ent_output, rel_output, batch_index, word_lists, true_ent, true_rel, silent):\n",
    "    \n",
    "    eval_ent_list_true_l, eval_rel_list_true_l = [], []\n",
    "    eval_ent_list_pred_l, eval_rel_list_pred_l = [], []\n",
    "    \n",
    "    for e,r,i,te,tr in zip(ent_output, rel_output, batch_index, true_ent, true_rel):\n",
    "        \n",
    "        # 算句子長度\n",
    "        len_of_list = len(word_lists[i])\n",
    "        word_list = word_lists[i]\n",
    "        true_ent = index2tag(te, ix_to_ent_tag)[:len_of_list]\n",
    "        pridict_ent = index2tag(e, ix_to_ent_tag)[:len_of_list]     \n",
    "        \n",
    "        # 單句decode關係\n",
    "        true_r_list, appear_error = decode_rel(te, tr)   # true\n",
    "        pre_r_list, appear_error = decode_rel(e, r)      # predict\n",
    "        \n",
    "        true_r_list = [list(set(i)) if type(i) is list else i for i in true_r_list]\n",
    "        pre_r_list = [list(set(i)) if type(i) is list else i for i in pre_r_list]\n",
    "        \n",
    "        # 出現error，跳過這句\n",
    "        if appear_error:\n",
    "            continue\n",
    "        \n",
    "        true_r_list = true_r_list[:len_of_list]\n",
    "        pre_r_list = pre_r_list[:len_of_list]\n",
    "        \n",
    "        \n",
    "        # 評分用\n",
    "        eval_ent_list_true, err_count = decode_ent(true_ent, schema)\n",
    "        eval_rel_list_true = decode_rel_to_eval(true_r_list, schema, eval_ent_list_true)\n",
    "        \n",
    "        eval_ent_list_pred, err_count = decode_ent(pridict_ent, schema)\n",
    "        eval_rel_list_pred = decode_rel_to_eval(pre_r_list, schema, eval_ent_list_pred)\n",
    "        \n",
    "        if not silent:\n",
    "            print(word_list)\n",
    "            print(true_ent)\n",
    "            print(true_r_list)\n",
    "            print()\n",
    "            print('Predict output')\n",
    "            print(pridict_ent)\n",
    "            print(pre_r_list)\n",
    "            print()\n",
    "            print('True')\n",
    "            print(eval_ent_list_true)\n",
    "            print(eval_rel_list_true)\n",
    "            print('predict')\n",
    "            print(eval_ent_list_pred)\n",
    "            print(eval_rel_list_pred)\n",
    "            print(\"=====================================\")\n",
    "        \n",
    "        eval_ent_list_true_l.append(eval_ent_list_true)\n",
    "        eval_rel_list_true_l.append(eval_rel_list_true)\n",
    "        eval_ent_list_pred_l.append(eval_ent_list_pred)\n",
    "        eval_rel_list_pred_l.append(eval_rel_list_pred)\n",
    "    \n",
    "    \n",
    "    e_score, y_true_ent, y_pred_ent = get_scores(eval_ent_list_true_l, eval_ent_list_pred_l, \\\n",
    "                                                 range(len(schema['entity'])),output_y=True)\n",
    "    r_score, y_true_rel, y_pred_rel = get_scores(eval_rel_list_true_l, eval_rel_list_pred_l, \\\n",
    "                                                 range(len(schema['relation'])),output_y=True)\n",
    "    \n",
    "    tp, fp, tn, fn = relation_error_analysis(eval_rel_list_true_l, eval_rel_list_pred_l)\n",
    "    \n",
    "    if not silent:\n",
    "        print('Batch entity score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(e_score)\n",
    "        print()\n",
    "        print('Batch relation score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(r_score)\n",
    "        print()\n",
    "        print('p_r_fscore')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tp, fp, tn, fn), tp, fp, tn, fn)\n",
    "    \n",
    "    return tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def decode_ent(pred_ent, schema):\n",
    "    '''\n",
    "    Aggregate entities from predicted tags\n",
    "    Input:\n",
    "    pred_ent=a list of entity tags in a sentence\n",
    "    schema=the dictionary defining entities and relations\n",
    "    Output: \n",
    "    ent_list=[(ent_start, ent_end, ent_type=eid_in_schema)]\n",
    "    err_count=the number of bad tags\n",
    "    '''\n",
    "    ent_list = []\n",
    "    ent_start = 0\n",
    "    ent_end = 0\n",
    "    state = {\n",
    "        'ENT_SPAN': 0,\n",
    "        'NO_ENT': 1\n",
    "    }\n",
    "    err_count = 0\n",
    "    ent_type = ''\n",
    "    sid = state['NO_ENT']\n",
    "    for idx, e_tag in enumerate(pred_ent):\n",
    "        bio = e_tag[0]\n",
    "        type_tag = e_tag.split('-')[-1]\n",
    "        if sid == state['NO_ENT']:\n",
    "            if bio == 'B':\n",
    "                ent_start = idx\n",
    "                ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                sid = state['ENT_SPAN']\n",
    "            elif bio == 'I':\n",
    "                err_count += 1\n",
    "        elif sid == state['ENT_SPAN']:\n",
    "            if bio != 'I':\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                if bio == 'B':\n",
    "                    ent_start = idx\n",
    "                    ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                else:\n",
    "                    sid = state['NO_ENT']\n",
    "            elif ent_type != get_eid_from_tag(type_tag, schema):\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                err_count += 1\n",
    "                sid = state['NO_ENT']\n",
    "    if sid == state['ENT_SPAN']:\n",
    "        ent_end = len(pred_ent) - 1\n",
    "        ent_list.append((ent_start, ent_end, ent_type))\n",
    "    return ent_list, err_count\n",
    "\n",
    "def get_eid_from_tag(tag, schema):\n",
    "    '''\n",
    "    Assume schema is a dictionary in schema.txt\n",
    "    return eid or -1 if no match is found\n",
    "    '''\n",
    "    for content in schema['entity'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['eid']\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def decode_rel_to_eval(r_list, schema, ent_list):\n",
    "    \n",
    "    max_pair = 0\n",
    "    for r in r_list:\n",
    "        if type(r) is list:\n",
    "            for single_r in r:\n",
    "                if int(single_r[-3])>max_pair:\n",
    "                    max_pair = int(single_r[-3])\n",
    "    \n",
    "\n",
    "    pair_idx = {}\n",
    "    for pair in range(max_pair+1):\n",
    "        for i, r in enumerate(r_list):\n",
    "            if type(r) is list:\n",
    "                for single_r in r:\n",
    "                    if int(single_r[-3])==pair:\n",
    "                        if pair not in pair_idx:\n",
    "                            pair_idx[pair] = [i]\n",
    "                        else:\n",
    "                            pair_idx[pair].append(i)\n",
    "    \n",
    "    \n",
    "#     # 算兩兩不同tag的數目\n",
    "#     e_type_dict = {}\n",
    "#     for e_pair in ent_list:\n",
    "#         if e_pair[-1] not in e_type_dict:\n",
    "#             e_type_dict[e_pair[-1]] = 1\n",
    "#         else:\n",
    "#             e_type_dict[e_pair[-1]] += 1\n",
    "    \n",
    "#     total_pair = 0\n",
    "#     e_type_l = list(e_type_dict.values())\n",
    "#     for i, ent_type_num_1 in enumerate(e_type_l):\n",
    "#         for j, ent_type_num_2 in enumerate(e_type_l[i+1:]):\n",
    "#             pair_num = ent_type_num_1*ent_type_num_2\n",
    "#             total_pair += pair_num\n",
    "\n",
    "    pair_list = []\n",
    "    for i, e_pair_1 in enumerate(ent_list):\n",
    "        for j, e_pair_2 in enumerate(ent_list[i+1:]):\n",
    "            if e_pair_1[-1]!=e_pair_2[-1]:\n",
    "                pair_list.append([e_pair_1, e_pair_2])\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    eval_rel_list = []\n",
    "    for pair in pair_idx:\n",
    "        rel_loc = pair_idx[pair]\n",
    "        for e_pairs in pair_list:\n",
    "            check_pair = True\n",
    "            first_start = e_pairs[0][0]\n",
    "            first_end = e_pairs[0][1]\n",
    "            sec_start = e_pairs[1][0]\n",
    "            sec_end = e_pairs[1][1]\n",
    "            \n",
    "            first_l = list(range(first_start, first_end+1))\n",
    "            sec_l = list(range(sec_start, sec_end+1))\n",
    "            combine_l = first_l+sec_l\n",
    "\n",
    "            \n",
    "            check_in_entity = []\n",
    "            for x in combine_l:\n",
    "                if x in rel_loc:\n",
    "                    check_in_entity.append(True)\n",
    "                else:\n",
    "                    check_in_entity.append(False)\n",
    "                    check_pair = False\n",
    "                    break             \n",
    "\n",
    "            if all(check_in_entity)==True:\n",
    "                for r in r_list[first_start]:\n",
    "                    r_info = r.split('-')\n",
    "                    \n",
    "                    if int(r_info[1])==pair:\n",
    "                        r_tag = get_rid_from_tag(r_info[0], schema)\n",
    "                        e_pairs_copy = copy.copy(e_pairs)\n",
    "                        e_pairs_copy.append(r_tag)\n",
    "                        eval_rel_list.append(tuple(e_pairs_copy))\n",
    "    \n",
    "    return eval_rel_list\n",
    "    \n",
    "        \n",
    "def get_rid_from_tag(tag, schema):   \n",
    "    for content in schema['relation'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['rid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rel_info(ent_output):\n",
    "    r_list = []     # 存放完整關係\n",
    "    r_dict = {}     # 記錄關係資訊\n",
    "    appear_error = False\n",
    "\n",
    "    pred_ent = index2tag(ent_output, ix_to_ent_tag)\n",
    "    \n",
    "\n",
    "    e_loc = 0       # 當前遇到的entity的位置\n",
    "    for loc, e in enumerate(pred_ent):\n",
    "        if e[0]=='B':\n",
    "            e_loc = loc\n",
    "            r_dict[loc] = {\n",
    "                '_2ndtag':e[2:],\n",
    "                'end':loc,\n",
    "            }\n",
    "            r_list.append([])\n",
    "                   \n",
    "        elif e[0]=='I':\n",
    "            # 錯誤來自於，entity預測錯誤，沒有預測到B tag，直接跳到I tag\n",
    "            # 所以沒有紀錄e_loc\n",
    "            try: \n",
    "                r_dict[e_loc]['end'] = loc\n",
    "            except KeyError:\n",
    "                appear_error = True\n",
    "                break\n",
    "            \n",
    "            r_list.append([])\n",
    "            \n",
    "        else:\n",
    "            r_list.append(\"\")\n",
    "              \n",
    "    return r_list, r_dict, appear_error\n",
    "        \n",
    "        \n",
    "def decode_rel(ent_output, rel_output):\n",
    "\n",
    "    r_list, r_dict, appear_error = create_rel_info(ent_output) \n",
    "    \n",
    "    IsB = False           # 是否遇到B tag的lock\n",
    "    IsNext = False        # 是否為B tag後面的tag 的lock\n",
    "    num_reocrd = -1       # 紀錄pair數\n",
    "    now_loc = 0\n",
    "    pre_rel_end_loc = 0\n",
    "    now_rel_end_loc = 0\n",
    "    \n",
    "    rel_keyerror = False\n",
    "    \n",
    "    for now in range(len(rel_output)):\n",
    "        for loc, rel in enumerate(rel_output[now][:now+1]):\n",
    "            rel = rel.cpu().numpy()\n",
    "            \n",
    "#             print(rel, IsB, IsNext)\n",
    "            \n",
    "            # 有關係存在，且為B tag \n",
    "            if rel!=rel_tag_to_ix[REL_NONE] and IsB==False and IsNext==False:\n",
    "\n",
    "                IsB = True\n",
    "                IsNext = True\n",
    "                tag = ix_to_rel_tag[int(rel)]\n",
    "                num_reocrd+=1\n",
    "                now_loc = loc\n",
    "                \n",
    "                # 錯誤來自於，now_loc找不到，也就是說，rel預測出來是有關係存在\n",
    "                # 但預測是'O'\n",
    "                # 而在entity中卻沒有預測出來，所以r_dict中沒有紀錄\n",
    "                try:\n",
    "                    pre_rel_end_loc = r_dict[now_loc]['end']\n",
    "\n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    now_rel_end_loc = r_dict[now]['end']\n",
    "                    \n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                second_tag = r_dict[now_loc]['_2ndtag']\n",
    "                preAorB = check_rel_loc(second_tag, schema)\n",
    "                nowAorB = 'B' if preAorB=='A' else 'A'\n",
    "                \n",
    "                pre_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+preAorB\n",
    "                now_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+nowAorB\n",
    "                \n",
    "                # 將以前的token填上關係\n",
    "                for token in range(now_loc, pre_rel_end_loc+1):\n",
    "                    \n",
    "                    # 出現以下error\n",
    "                    '''AttributeError: 'str' object has no attribute 'append'''\n",
    "                    # 為 r_list 前處理中沒有給予可能有關係的位置空的list\n",
    "                    try:\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "                    except AttributeError:\n",
    "                        r_list[token] = []\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "\n",
    "             \n",
    "                # 當前token填上關係\n",
    "                r_list[now].append(now_complete_rel)\n",
    "                \n",
    "\n",
    "            \n",
    "            # 關係前位中B tag後面的tag\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsB:\n",
    "                # 如果還在這個entity的範圍內\n",
    "                if loc<=pre_rel_end_loc:\n",
    "                    pass\n",
    "                \n",
    "                # 超出現在這個entity的範圍，改lock\n",
    "                else:\n",
    "                    IsB = False\n",
    "\n",
    "            \n",
    "            # B tag後面的tag的關係，依照前面的關係複製\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsNext:\n",
    "                r_list[now] = r_list[now-1]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if now<=now_rel_end_loc:\n",
    "                    IsB = False\n",
    "                else:\n",
    "                    IsB = False\n",
    "                    IsNext = False\n",
    "\n",
    "        \n",
    "        if rel_keyerror:\n",
    "            rel_keyerror = False\n",
    "            break\n",
    "                \n",
    "                \n",
    "    return r_list, appear_error\n",
    "                \n",
    "\n",
    "# 是三元關係中的前者還是後者                  \n",
    "def check_rel_loc(second_tag, schema):\n",
    "    convert_tag = ''\n",
    "\n",
    "    for ent_content in schema['entity']:\n",
    "        if schema['entity'][ent_content]['tag']==second_tag:\n",
    "            convert_tag = ent_content\n",
    "    \n",
    "    rel_types = schema['relation'].values()\n",
    "\n",
    "    for rel_content in schema['relation'].values():\n",
    "        for AorB in rel_content['arguments']:\n",
    "            if rel_content['arguments'][AorB]==convert_tag:\n",
    "                return AorB\n",
    "            \n",
    "\n",
    "            \n",
    "def get_scores(true_lists, pred_lists, labels, output_y=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for t_list, p_list in zip(true_lists, pred_lists):\n",
    "        yt, yp = align_yt_yp(t_list, p_list, labels)\n",
    "        y_true.extend(yt)\n",
    "        y_pred.extend(yp)\n",
    "        \n",
    "    scores = precision_recall_fscore_support(y_true, y_pred, average='micro', labels=labels)\n",
    "    return scores, y_true, y_pred if output_y else scores\n",
    "\n",
    "def align_yt_yp(truths, predictions, labels):\n",
    "    '''\n",
    "    Input:\n",
    "        truths/predictions: list of true and predicted tuples, \n",
    "        with the leading entries as the structure and the last entry as the class,\n",
    "        e.g., [(e1, e2, rel), ...]\n",
    "        labels: sequence of valid class\n",
    "    Output:\n",
    "        yt: list of true class given a structure\n",
    "        yp: list of predicted class given a structure\n",
    "    '''\n",
    "    yt, yp = [], []\n",
    "    _ID_NONE = len(labels)\n",
    "    true_dict = { t[:-1]: t[-1] for t in truths }\n",
    "    for p in predictions:\n",
    "        yt.append(true_dict.pop(p[:-1], _ID_NONE))\n",
    "        yp.append(p[-1])\n",
    "    for target in true_dict.values():\n",
    "        yt.append(target)\n",
    "        yp.append(_ID_NONE)\n",
    "    return yt, yp\n",
    "\n",
    "\n",
    "\n",
    "def is_neg_triple(t):\n",
    "    return np.imag(t[-1]) > 0\n",
    "\n",
    "def negate_triple(t):\n",
    "    # Mark negative triples with imaginary relation id\n",
    "    return (t[0], t[1], np.real(t[-1]).item() + 1j)\n",
    "\n",
    "def posit_triple(t):\n",
    "    return (t[0], t[1], np.real(t[-1]).item())\n",
    "\n",
    "def has_edge(base_ptrs, rel, e):\n",
    "    '''\n",
    "    Assume a relation exist between an entity pair, \n",
    "    if all the tokens in the base entity point to those in entity e.\n",
    "    '''\n",
    "    tok_has_ptr_to_e = [tok_ptrs[rel].ge(e[0]).dot(tok_ptrs[rel].le(e[1])).item() > 0 \n",
    "                        for tok_ptrs in base_ptrs]\n",
    "    return len(tok_has_ptr_to_e) > 0 and all(tok_has_ptr_to_e)\n",
    "\n",
    "\n",
    "def relation_error_analysis(true_rel_lists, rel_lists):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, r_list in enumerate(rel_lists):\n",
    "        true_pos = len([t for t in r_list if t in true_rel_lists[i]])\n",
    "        all_true = len([t for t in true_rel_lists[i] if not is_neg_triple(t)])\n",
    "        all_pos = len(r_list)\n",
    "        tp += true_pos\n",
    "        fn += all_true - true_pos\n",
    "        fp += all_pos - true_pos\n",
    "        tn += len([t for t in true_rel_lists[i] if is_neg_triple(t) and posit_triple(t) not in r_list])\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def p_r_fscore(tp, fp, tn, fn, beta=1, eps=1e-8):\n",
    "    p = tp / (tp + fp + eps)\n",
    "    r = tp / (tp + fn + eps)\n",
    "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r + eps))\n",
    "    return p, r, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.1512\n",
      "Relation loss : 0.0012\n",
      "\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(16, 17, 0), (24, 25, 1)]\n",
      "[((16, 17, 0), (24, 25, 1), 0)]\n",
      "=====================================\n",
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (9, 13, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (23, 25, 1), (49, 50, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', [], [], [], [], [], '', '', [], []]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['而', '面', '膜', '的', '精', '華', '液', '不', '算', '多', '，', '但', '也', '很', '夠', '用', '了', '，', '是', '敷', '上', '之', '後', '不', '會', '滴', '下', '的', '量', '，', '剛', '剛', '好', '，', '精', '華', '液', '本', '身', '沒', '什', '麼', '香', '味', '，', '我', '這', '個', '小', '敏', '感', '的', '油', '性', '肌', '老', '實', '說', '敷', '完', '之', '後', '卻', '什', '麼', '感', '覺', '都', '沒', '有', '，', '沒', '有', '過', '敏', '、', '沒', '有', '感', '覺', '特', '別', '保', '水', '、', '緊', '緻', '.', '.', '.', '等']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '']\n",
      "\n",
      "True\n",
      "[(52, 54, 1), (85, 86, 0)]\n",
      "[]\n",
      "predict\n",
      "[(52, 54, 1), (85, 86, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 0), (30, 33, 1)]\n",
      "[((25, 26, 0), (30, 33, 1), 0)]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['效', '果', '方', '面', '我', '覺', '得', '還', '不', '錯', ',', '因', '為', '我', '是', '混', '合', '性', '肌', '膚', ',', '敷', '完', '了', '之', '後', '有', '覺', '得', '還', '滿', '保', '濕', '的', ',', '隔', '天', '早', '上', '起', '來', '比', '較', '會', '出', '油', '的', '地', '方', ',', '出', '油', '狀', '況', '就', '比', '較', '沒', '有', '那', '麼', '嚴', '重', '了', ',', '整', '題', '來', '說', '還', '滿', '推', '薦', '的', '喔']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(15, 19, 1), (31, 32, 0)]\n",
      "[((15, 19, 1), (31, 32, 0), 0)]\n",
      "predict\n",
      "[(15, 19, 1), (31, 32, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O']\n",
      "['', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', [], [], '', '', '', '', '', '', [], [], '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1), (16, 17, 0), (19, 20, 0), (27, 28, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['極', '效', '肌', '因', '修', '護', '巨', '藻', '、', '齒', '缘', '墨', '角', '藻', '複', '合', '水', '解', '酵', '母', '提', '取', '物', '，', '浸', '透', '濕', '潤', '乾', '燥', '肌', '膚', '，', '增', '強', '防', '護', '屏', '障', '，', '協', '同', '蘆', '薈', '、', '山', '金', '車', '及', '光', '果', '甘', '草', '植', '萃', '精', '華', '，', '深', '度', '安', '撫', '同', '時', '舒', '緩', '肌', '膚', '的', '不', '適', '，', '拋', '開', '惱', '人', '的', '乾', '燥', '缺', '水', '不', '安', '讓', '肌', '膚', '穩', '定']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(28, 31, 1)]\n",
      "[]\n",
      "predict\n",
      "[(28, 31, 1), (64, 65, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1), (18, 19, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1), (14, 15, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], '', [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6590909090909091, 0.9666666666666667, 0.7837837837837838, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5, 0.125, 0.2, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.4999999975, 0.12499999984374999, 0.19999999640000002) 1 1 0 7\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0859\n",
      "Relation loss : 0.0010\n",
      "\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['精', '華', '液', '內', '含', '酵', '母', '萃', '取', '，', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '，', '可', '以', '達', '到', '保', '濕', '效', '用', '，', '質', '地', '清', '爽', '滑', '順', '，', '敷', '用', '時', '保', '濕', '滋', '潤', '度', '相', '當', '不', '錯', '，', '可', '以', '修', '護', '肌', '膚', '乾', '燥', '缺', '水', '部', '位', '，', '取', '下', '面', '膜', '後', '的', '肌', '膚', '立', '即', '透', '亮', '飽', '滿', '，', '連', '毛', '孔', '都', '明', '顯', '縮', '小']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(32, 33, 0), (47, 48, 0), (61, 64, 1)]\n",
      "[((47, 48, 0), (61, 64, 1), 0)]\n",
      "predict\n",
      "[(32, 33, 0), (47, 48, 0), (61, 64, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 9, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', ['ApplyTo-0-B'], [], '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(6, 7, 0), (29, 30, 0), (43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['S', 't', 'e', 'p', '2', '.', '強', '化', '補', '水', '-', '嫩', '白', '蠶', '絲', '面', '膜', '-', '面', '膜', '非', '常', '薄', '貼', '，', '記', '得', '要', '把', '蠶', '絲', '面', '膜', '朝', '臉', '敷', '上', '後', '再', '把', '珍', '珠', '膜', '撕', '下', '布', '料', '採', '用', '凝', '水', '蠶', '絲', '，', '清', '透', '，', '用', '天', '然', '草', '本', '植', '物', '萃', '取', '的', '精', '華', '，', '幫', '助', '保', '濕', '，', '也', '可', '以', '舒', '緩', '一', '些', '夏', '季', '保', '養', '時', '乾', '燥', '肌', '的', '狀', '況']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', [], [], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', [], [], '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(72, 73, 0), (78, 79, 0), (84, 85, 0), (87, 89, 1)]\n",
      "[((78, 79, 0), (87, 89, 1), 0)]\n",
      "predict\n",
      "[(72, 73, 0), (78, 79, 0), (84, 85, 0), (87, 89, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['以', '上', '是', '我', '不', '會', '再', '使', '用', '此', '產', '品', '，', '也', '不', '會', '推', '薦', '親', '友', '使', '用', '的', '原', '因', '，', '最', '大', '原', '因', '是', '因', '為', '；', '居', '然', '在', '使', '用', '後', '，', '肌', '膚', '反', '而', '變', '得', '乾', '到', '發', '癢', '，', '可', '見', '產', '品', '若', '無', '法', '真', '正', '提', '供', '乾', '性', '肌', '膚', '滋', '潤', '和', '保', '濕', '的', '話', '，', '添', '加', '再', '多', '吸', '引', '消', '費', '者', '的', '成', '分', '也', '不', '見', '得', '能', '得', '到', '消', '費', '者', '的', '心']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(63, 66, 1), (70, 71, 0)]\n",
      "[]\n",
      "predict\n",
      "[(63, 66, 1), (70, 71, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1), (22, 23, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8095238095238095, 0.9714285714285714, 0.8831168831168832, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(1.0, 0.2, 0.33333333333333337, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.999999995, 0.1999999998, 0.33333333000000004) 2 0 0 8\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1016\n",
      "Relation loss : 0.0013\n",
      "\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], [], [], [], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['洗', '完', '臉', '後', '，', '我', '將', '「', '我', '的', '美', '麗', '日', '記', '」', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '敷', '在', '臉', '上', '，', '經', '過', '2', '0', '分', '鐘', '後', '，', '將', '面', '膜', '從', '臉', '部', '由', '下', '往', '上', '撕', '下', '，', '再', '用', '清', '水', '將', '面', '膜', '清', '洗', '乾', '淨', '後', '，', '從', '鏡', '子', '中', '我', '看', '到', '臉', '部', '肌', '膚', '乾', '燥', '缺', '水', '的', '現', '象', '消', '失', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(76, 79, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 0), (76, 79, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8235294117647058, 1.0, 0.9032258064516129, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.0, 0.0, 0.0, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.0, 0.0, 0.0) 0 0 0 5\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7475728155339806, 0.9746835443037974, 0.8461538461538461, None)\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.75, 0.13043478260869565, 0.22222222222222218, None)\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7499999981250001, 0.13043478255198487, 0.22222221953360766) 3 1 0 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = root+'facial_r2.test'\n",
    "input_test, ent_test, rel_test, raw_index_test, raw_input_test = dev_preprocess(test_data)\n",
    "test_loader = dataload(input_test, ent_test, rel_test, raw_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.2018\n",
      "Relation loss : 0.0012\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0922\n",
      "Relation loss : 0.0013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "\n",
      "Entity loss : 0.1890\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.2322\n",
      "Relation loss : 0.0010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "\n",
      "Entity loss : 0.1503\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1431\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1908\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1002\n",
      "Relation loss : 0.0013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "\n",
      "Entity loss : 0.1458\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1257\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0984\n",
      "Relation loss : 0.0009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "\n",
      "Entity loss : 0.1178\n",
      "Relation loss : 0.0017\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0982\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0831\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0850\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1317\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0956\n",
      "Relation loss : 0.0012\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0763\n",
      "Relation loss : 0.0015\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0715\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0756\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1292\n",
      "Relation loss : 0.0009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "\n",
      "Entity loss : 0.0030\n",
      "Relation loss : 0.0008\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7463687150837989, 0.9794721407624634, 0.8471781864299303, None)\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5757575757575758, 0.1111111111111111, 0.18627450980392157, None)\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5757575755831037, 0.11111111110461339, 0.18627450707372167) 19 14 0 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
