{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def schema_load(schema_root):\n",
    "    raw_dict = \"\".join(readfile(schema_root))\n",
    "    dict2json = \"\".join(raw_dict.split()[2:])\n",
    "\n",
    "    json_acceptable_string = dict2json.replace(\"'\", \"\\\"\")\n",
    "    schema = json.loads(json_acceptable_string)\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def define_entity(schema):\n",
    "    tag_type = list(schema['tagging'])\n",
    "    \n",
    "    entity_tag = []\n",
    "    for k in list(schema['entity'].keys()):\n",
    "        entity_tag.append(schema['entity'][k]['tag'])\n",
    "        \n",
    "    TAG = []\n",
    "    for t in tag_type:\n",
    "        for e in entity_tag:\n",
    "            if t!='O':\n",
    "                TAG.append(t+'-'+e)  \n",
    "                \n",
    "    TAG = [UNKOWN_TAG, PAD_TAG] + TAG + ['O']   \n",
    "\n",
    "    return TAG\n",
    "\n",
    "def tag2ix(TAG):\n",
    "    tag_to_ix={t:i for i,t in enumerate(TAG)}\n",
    "    return tag_to_ix\n",
    "\n",
    "def define_relation(schema):\n",
    "    relation_type = list(schema['relation'])\n",
    "    \n",
    "    relation_tag = []\n",
    "    for k in list(schema['relation'].keys()):\n",
    "        relation_tag.append(schema['relation'][k]['tag'])\n",
    "    \n",
    "    relation_tag = [REL_PAD] + [REL_NONE] + relation_tag\n",
    "        \n",
    "    return relation_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_set = word_set.split()\n",
    "        if len(word_set)==1:\n",
    "            word_list.append(' ')\n",
    "            ent_list.append('O')\n",
    "            rel_list.append(REL_NONE)\n",
    "        \n",
    "        else:\n",
    "            word_list.append(word_set[0])\n",
    "            ent_list.append(word_set[1])\n",
    "\n",
    "            try:\n",
    "                testerror = word_set[2]\n",
    "            except IndexError:\n",
    "                rel_list.append(REL_NONE)\n",
    "            else:\n",
    "                rel_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "\n",
    "    for now_token, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, ents, rels = get_word_and_label(content, init, now_token)\n",
    "            init = now_token+1\n",
    "            word_list.append(words)\n",
    "            ent_list.append(ents)\n",
    "            rel_list.append(rels)\n",
    "            \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, ent_list, rel_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_ent = list(ent_list[i] for i in reserved_index)\n",
    "    filter_rel = list(rel_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_ent, filter_rel\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq, isrel):\n",
    "    if isrel:\n",
    "        seq += [REL_NONE for i in range(MAX_LEN-len(seq))]\n",
    "    else:\n",
    "        seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_ent, filter_rel):\n",
    "    input_padded = [pad_seq(s, False) for s in filter_word]\n",
    "    ent_padded = [pad_seq(s, False) for s in filter_ent]\n",
    "    rel_padded = [pad_seq(s, True) for s in filter_rel]\n",
    "    \n",
    "    return input_padded, ent_padded, rel_padded\n",
    "\n",
    "def deep_copy_lists(filter_word, filter_ent, filter_rel):\n",
    "    f_w = copy.deepcopy(filter_word)\n",
    "    f_e = copy.deepcopy(filter_ent)\n",
    "    f_r = copy.deepcopy(filter_rel)\n",
    "    \n",
    "    return f_w, f_e, f_r\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "\n",
    "\n",
    "def prepare_rel(rel_padded, to_ix):\n",
    "    \n",
    "    rel_ptr = torch.zeros(len(rel_padded), MAX_LEN, MAX_LEN, dtype=torch.long) \n",
    "    \n",
    "    # 對當前的token，去比較之前所有出現過的entity，是否有關係，建成矩陣\n",
    "    # [B*ML*ML]，第二維ML是當前token，第三維ML是根據當前token對之前出現過的entity紀錄關係，以index紀錄\n",
    "    for i, rel_seq in enumerate(rel_padded):\n",
    "        rel_dict = {}\n",
    "        for j, token_seq in enumerate(rel_seq):\n",
    "            rel_ptr[i][j][:j+1] = 1\n",
    "            if token_seq != REL_NONE:\n",
    "                for k, rel in enumerate(token_seq):\n",
    "\n",
    "                    # if 是第一次出現，紀錄後面數字(標第幾對)和關係位置(A OR B)\n",
    "                    # 假如下次出現又是同個關係位置(A)，依然紀錄\n",
    "                    # 直到下次出現關係位置B，依照之前紀錄的A位置的字，然後在第三維去標關係\n",
    "\n",
    "                    rel_token = rel.split('-')\n",
    "                    if rel_token[1] not in rel_dict:\n",
    "                        rel_dict[rel_token[1]] = {'rel':rel_token[0], 'loc':rel_token[2], 'idx':[j]}\n",
    "\n",
    "                    elif rel_token[1] in rel_dict and rel_dict[rel_token[1]]['loc']==rel_token[2]:\n",
    "                        rel_dict[rel_token[1]]['idx'].append(j)\n",
    "\n",
    "                    else:\n",
    "                        record_loc = rel_dict[rel_token[1]]['idx']\n",
    "                        for idxx in record_loc:\n",
    "                            rel_ptr[i][j][idxx] = to_ix[rel_token[0]]\n",
    "                            \n",
    "    return rel_ptr\n",
    "                \n",
    "\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def dataload(input_var, ent_var, rel_var, raw_input):\n",
    "    torch_dataset = Data.TensorDataset(input_var, ent_var, rel_var, raw_input)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=0,       \n",
    "#         drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_entity(entity):\n",
    "    entity = entity.view(BATCH_SIZE,ent_size).argmax(1)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output, rel_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        self.rel_size = rel_size\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.w2 = nn.Linear(self.attn_input, self.attn_output)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(self.attn_output, self.rel_size, bias=False)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        \n",
    "        decoder = encoder_outputs[:,-1,:].unsqueeze(1)                       #B*1*(ts+LE) [128,1,8]\n",
    "        encoder_score = self.w1(encoder_outputs)                             #B*now len*ATTN_OUT\n",
    "        decoder_score = self.w2(decoder)                                     #B*1*ATTN_OUT\n",
    "        energy = self.tanh(encoder_score+decoder_score)                      #B*now len*ATTN_OUT            \n",
    "        \n",
    "        energy = self.v(energy)                                              #B*now len*rel_size\n",
    "        \n",
    "        \n",
    "        # 針對每個entity做softmax，去顯示他們的關係權重\n",
    "        # 主要都會是rel_none\n",
    "        # 對第二維(rel)做softmax\n",
    "        p = self.softmax(energy)                                         #B*now len*rel_size\n",
    "        \n",
    "        return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, ent_tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim, rel_tag_to_ix):\n",
    "        \n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.ent_to_ix = ent_tag_to_ix\n",
    "        self.ent_size = len(ent_tag_to_ix)                   #es\n",
    "        self.rel_to_ix = rel_tag_to_ix\n",
    "        self.rel_size = len(rel_tag_to_ix)                   #rs           \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim1, momentum=0.5, affine=False)\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "#                             num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)        \n",
    "        self.bilstm = nn.GRU(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.ent_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.ent_size, self.label_embed_dim)\n",
    "        \n",
    "        self.attn = Attn(ATTN_IN, ATTN_OUT, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, self.batch, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(self.batch, self.hidden_dim2)              #B*h2\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(self.batch, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_entity(self):\n",
    "        output_tensor = torch.zeros(self.batch, MAX_LEN, self.ent_size)  #B*ML*es\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "    \n",
    "    def create_rel_matrix(self):\n",
    "        rel_tensor = torch.zeros(self.batch, MAX_LEN, MAX_LEN, self.rel_size)  #B*ML*ML*rs\n",
    "        return rel_tensor.cuda()if USE_CUDA else rel_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, batch_ent, isTrain=True):\n",
    "        \n",
    "        self.batch = sentence.size(0)\n",
    "#         self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        entity_tensor = self.create_entity()                    #B*ML*es\n",
    "        rel_tensor = self.create_rel_matrix()                   #B*ML*ML*rs\n",
    "        \n",
    "        \n",
    "\n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "#         bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        bilstm_out, hidden1 = self.bilstm(embeds)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        # bn\n",
    "        bilstm_out = self.bn(bilstm_out)\n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence_l = [] \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            \n",
    "            if length==0:\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*es,[128, 5]            \n",
    "            ent_output = self.softmax(to_tags)                               #B*es,[128, 5]  \n",
    "            s_ent_output = self.softmax_entity(ent_output)\n",
    "            ent_onehot = self.one_hot(s_ent_output)\n",
    "            \n",
    "            \n",
    "            if isTrain:\n",
    "                label = self.label_embed(ent_onehot)                             #B*LE,[128, 3]\n",
    "#                 label = self.label_embed(ent_output) \n",
    "            else:\n",
    "                batch_ent_onehot = self.one_hot(batch_ent[:,length])\n",
    "                label = self.label_embed(batch_ent_onehot)\n",
    "            \n",
    "     \n",
    "            \n",
    "            # Assignments to Variables are in-place operations.\n",
    "            # Use that variable in lots of other contexts \n",
    "            # and some of the functions require it to not change. \n",
    "            to_tags_clone = to_tags.clone()\n",
    "            label_clone = label.clone()\n",
    "            \n",
    "            \n",
    "#             for i, tag in enumerate(s_ent_output):\n",
    "#                 if tag==ent_tag_to_ix['O']:\n",
    "#                     to_tags_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "#                     label_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "                    \n",
    "            # relation layer\n",
    "#             encoder_sequence_l.append(torch.cat((to_tags,label),1)) \n",
    "            encoder_sequence_l.append(torch.cat((h_next,label),1))  \n",
    "            encoder_sequence = torch.stack(encoder_sequence_l).t()     #B*len*(es+LE), [128,1,8]          \n",
    "\n",
    "            # Calculate attention weights \n",
    "            attn_weights = self.attn(encoder_sequence)\n",
    "\n",
    "        \n",
    "            entity_tensor[:,length,:] = ent_output\n",
    "            \n",
    "            # rel_tensor[:,length, 頭~當前 ,:]\n",
    "            rel_tensor[:,length,:length+1,:] = attn_weights\n",
    "\n",
    "        \n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return entity_tensor.view(self.batch*MAX_LEN, self.ent_size), \\\n",
    "               rel_tensor.view(self.batch*MAX_LEN*MAX_LEN, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def softmax_entity(self, entity):\n",
    "        entity = entity.view(self.batch,ent_size).argmax(1)\n",
    "        return entity\n",
    "    \n",
    "    \n",
    "    def one_hot(self, batch_ent):   \n",
    "        batchsize = batch_ent.size(0)\n",
    "        nb_digits = len(ent_tag_to_ix)\n",
    "        batch_ent = torch.unsqueeze(batch_ent, 1)\n",
    "        y_onehot = torch.cuda.FloatTensor(batchsize, nb_digits)        \n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, batch_ent, 1)    \n",
    "\n",
    "        return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "relation_data_old = root+'facial_r.old.train'\n",
    "# relation_data = root+'facial_r.train'\n",
    "relation_data = root+'facial_r2.train'\n",
    "schema_root = root+'schema_2.txt'\n",
    "dev_data = root+'facial_r2.dev'\n",
    "test_data = root+'facial_r2.test'\n",
    "\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "REL_NONE = 'Rel-None'\n",
    "REL_PAD = 'Rel-Pad'\n",
    "rule = ('FUNC', 'ApplyTo', 'STAT')\n",
    "\n",
    "schema = schema_load(schema_root)\n",
    "ENT_TAG = define_entity(schema)\n",
    "REL_TAG = define_relation(schema)\n",
    "ent_tag_to_ix = tag2ix(ENT_TAG)\n",
    "'''{'<PAD>': 1,\n",
    " '<UNKNOWN>': 0,\n",
    " 'B-FUNC': 2,\n",
    " 'B-STAT': 3,\n",
    " 'I-FUNC': 4,\n",
    " 'I-STAT': 5,\n",
    " 'O': 6}'''\n",
    "rel_tag_to_ix = tag2ix(REL_TAG)\n",
    "'''{'ApplyTo': 2, 'Rel-None': 1, 'Rel-Pad': 0}'''\n",
    "\n",
    "# ========hyper-parameter-set==========\n",
    "\n",
    "ent_size = len(ent_tag_to_ix)\n",
    "rel_size = len(rel_tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 18\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM1 = 10\n",
    "HIDDEN_DIM2 = 8\n",
    "LABEL_EMBED_DIM = ent_size\n",
    "DENSE_OUT = 100\n",
    "\n",
    "# ATTN_IN = ent_size+LABEL_EMBED_DIM\n",
    "ATTN_IN = HIDDEN_DIM2+LABEL_EMBED_DIM\n",
    "ATTN_OUT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    content = readfile(data)\n",
    "    word_list, ent_list, rel_list = split_to_list(content)\n",
    "    word_to_ix = word2index(word_list)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    #================================================\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, vocab_size, word_to_ix, reserved_index, word_list\n",
    "\n",
    "def dev_preprocess(dev_data):\n",
    "    dev_content = readfile(dev_data)\n",
    "    word_list, ent_list, rel_list = split_to_list(dev_content)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, reserved_index, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_ent_tag = dict_inverse(ent_tag_to_ix)\n",
    "ix_to_rel_tag = dict_inverse(rel_tag_to_ix)\n",
    "#===============================================\n",
    "input_var, ent_var, rel_var, vocab_size, word_to_ix, raw_index, raw_input = preprocess(relation_data)\n",
    "loader = dataload(input_var, ent_var, rel_var, raw_index)\n",
    "\n",
    "input_dev, ent_dev, rel_dev, raw_index_dev, raw_input_dev = dev_preprocess(dev_data)\n",
    "dev_loader = dataload(input_dev, ent_dev, rel_dev, raw_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "# criterion_rel = nn.NLLLoss(ignore_index=rel_tag_to_ix[REL_PAD])\n",
    "criterion_rel = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:06<10:39,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | ent loss 0.6094 | rel loss 0.0737 | total loss 0.6831\n",
      "         | val ent loss 0.5175 | val rel loss 0.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:11<09:41,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | ent loss 0.5687 | rel loss 0.0199 | total loss 0.5886\n",
      "         | val ent loss 0.6670 | val rel loss 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:17<09:20,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | ent loss 0.6340 | rel loss 0.0125 | total loss 0.6465\n",
      "         | val ent loss 0.6137 | val rel loss 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:23<09:24,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | ent loss 0.6027 | rel loss 0.0094 | total loss 0.6121\n",
      "         | val ent loss 0.5392 | val rel loss 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:29<09:23,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | ent loss 0.4184 | rel loss 0.0092 | total loss 0.4276\n",
      "         | val ent loss 0.2769 | val rel loss 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:35<09:11,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | ent loss 0.3681 | rel loss 0.0073 | total loss 0.3755\n",
      "         | val ent loss 0.2482 | val rel loss 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:40<08:59,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | ent loss 0.2801 | rel loss 0.0086 | total loss 0.2887\n",
      "         | val ent loss 0.2269 | val rel loss 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:46<08:58,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | ent loss 0.2449 | rel loss 0.0059 | total loss 0.2509\n",
      "         | val ent loss 0.2567 | val rel loss 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:51<08:42,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | ent loss 0.2445 | rel loss 0.0047 | total loss 0.2491\n",
      "         | val ent loss 0.2451 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:56<08:32,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | ent loss 0.2778 | rel loss 0.0043 | total loss 0.2821\n",
      "          | val ent loss 0.2948 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [01:02<08:25,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | ent loss 0.2413 | rel loss 0.0041 | total loss 0.2454\n",
      "          | val ent loss 0.2365 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [01:08<08:18,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | ent loss 0.1889 | rel loss 0.0053 | total loss 0.1941\n",
      "          | val ent loss 0.2669 | val rel loss 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [01:14<08:17,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | ent loss 0.1672 | rel loss 0.0042 | total loss 0.1713\n",
      "          | val ent loss 0.2402 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [01:19<08:09,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | ent loss 0.1591 | rel loss 0.0038 | total loss 0.1629\n",
      "          | val ent loss 0.2939 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [01:25<08:05,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | ent loss 0.1423 | rel loss 0.0033 | total loss 0.1457\n",
      "          | val ent loss 0.2999 | val rel loss 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [01:31<08:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | ent loss 0.1870 | rel loss 0.0030 | total loss 0.1899\n",
      "          | val ent loss 0.2320 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [01:36<07:51,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | ent loss 0.1304 | rel loss 0.0040 | total loss 0.1343\n",
      "          | val ent loss 0.2570 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [01:41<07:44,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | ent loss 0.0949 | rel loss 0.0032 | total loss 0.0982\n",
      "          | val ent loss 0.1124 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [01:47<07:37,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | ent loss 0.0945 | rel loss 0.0034 | total loss 0.0979\n",
      "          | val ent loss 0.2138 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [01:52<07:29,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | ent loss 0.0708 | rel loss 0.0031 | total loss 0.0739\n",
      "          | val ent loss 0.1429 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [01:57<07:23,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | ent loss 0.0871 | rel loss 0.0028 | total loss 0.0900\n",
      "          | val ent loss 0.2749 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [02:03<07:17,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | ent loss 0.0760 | rel loss 0.0033 | total loss 0.0793\n",
      "          | val ent loss 0.1806 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [02:08<07:10,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | ent loss 0.0588 | rel loss 0.0024 | total loss 0.0612\n",
      "          | val ent loss 0.2497 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [02:14<07:05,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | ent loss 0.0374 | rel loss 0.0024 | total loss 0.0398\n",
      "          | val ent loss 0.1553 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [02:20<07:02,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | ent loss 0.0206 | rel loss 0.0021 | total loss 0.0227\n",
      "          | val ent loss 0.1260 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [02:27<06:59,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | ent loss 0.0435 | rel loss 0.0024 | total loss 0.0458\n",
      "          | val ent loss 0.1425 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [02:34<06:56,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | ent loss 0.0269 | rel loss 0.0022 | total loss 0.0291\n",
      "          | val ent loss 0.0646 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [02:39<06:49,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | ent loss 0.0207 | rel loss 0.0024 | total loss 0.0232\n",
      "          | val ent loss 0.1722 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [02:45<06:44,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | ent loss 0.0473 | rel loss 0.0017 | total loss 0.0490\n",
      "          | val ent loss 0.1250 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [02:50<06:38,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | ent loss 0.0165 | rel loss 0.0022 | total loss 0.0187\n",
      "          | val ent loss 0.1371 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [02:56<06:33,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | ent loss 0.0154 | rel loss 0.0017 | total loss 0.0171\n",
      "          | val ent loss 0.1151 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [03:03<06:29,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | ent loss 0.0331 | rel loss 0.0022 | total loss 0.0353\n",
      "          | val ent loss 0.0619 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [03:09<06:25,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | ent loss 0.0214 | rel loss 0.0019 | total loss 0.0233\n",
      "          | val ent loss 0.1501 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [03:16<06:20,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | ent loss 0.0286 | rel loss 0.0023 | total loss 0.0309\n",
      "          | val ent loss 0.1142 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [03:22<06:15,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | ent loss 0.0146 | rel loss 0.0018 | total loss 0.0164\n",
      "          | val ent loss 0.1343 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [03:28<06:10,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | ent loss 0.0212 | rel loss 0.0017 | total loss 0.0229\n",
      "          | val ent loss 0.0817 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [03:34<06:04,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | ent loss 0.0232 | rel loss 0.0023 | total loss 0.0255\n",
      "          | val ent loss 0.1963 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [03:41<06:00,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | ent loss 0.0068 | rel loss 0.0018 | total loss 0.0086\n",
      "          | val ent loss 0.1084 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [03:47<05:55,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | ent loss 0.0180 | rel loss 0.0020 | total loss 0.0199\n",
      "          | val ent loss 0.0946 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [03:53<05:49,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | ent loss 0.0193 | rel loss 0.0017 | total loss 0.0211\n",
      "          | val ent loss 0.1013 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [03:59<05:44,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | ent loss 0.0145 | rel loss 0.0017 | total loss 0.0162\n",
      "          | val ent loss 0.1101 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [04:04<05:38,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | ent loss 0.0161 | rel loss 0.0019 | total loss 0.0180\n",
      "          | val ent loss 0.1220 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [04:11<05:33,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | ent loss 0.0182 | rel loss 0.0018 | total loss 0.0200\n",
      "          | val ent loss 0.0406 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [04:18<05:28,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | ent loss 0.0201 | rel loss 0.0022 | total loss 0.0223\n",
      "          | val ent loss 0.0683 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [04:24<05:23,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | ent loss 0.0061 | rel loss 0.0020 | total loss 0.0081\n",
      "          | val ent loss 0.0901 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [04:30<05:17,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | ent loss 0.0179 | rel loss 0.0021 | total loss 0.0201\n",
      "          | val ent loss 0.1154 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [04:36<05:11,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | ent loss 0.0054 | rel loss 0.0015 | total loss 0.0069\n",
      "          | val ent loss 0.1088 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [04:42<05:05,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | ent loss 0.0060 | rel loss 0.0015 | total loss 0.0074\n",
      "          | val ent loss 0.0874 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [04:47<04:59,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | ent loss 0.0063 | rel loss 0.0016 | total loss 0.0079\n",
      "          | val ent loss 0.0277 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [04:53<04:53,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 | ent loss 0.0218 | rel loss 0.0015 | total loss 0.0233\n",
      "          | val ent loss 0.0638 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [04:59<04:47,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 | ent loss 0.0040 | rel loss 0.0017 | total loss 0.0058\n",
      "          | val ent loss 0.1976 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [05:04<04:40,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 | ent loss 0.0088 | rel loss 0.0017 | total loss 0.0105\n",
      "          | val ent loss 0.1257 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [05:10<04:35,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 | ent loss 0.0192 | rel loss 0.0019 | total loss 0.0211\n",
      "          | val ent loss 0.1554 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [05:15<04:29,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 | ent loss 0.0103 | rel loss 0.0018 | total loss 0.0121\n",
      "          | val ent loss 0.1710 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [05:21<04:23,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 | ent loss 0.0284 | rel loss 0.0018 | total loss 0.0302\n",
      "          | val ent loss 0.0462 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [05:28<04:17,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 | ent loss 0.0121 | rel loss 0.0019 | total loss 0.0140\n",
      "          | val ent loss 0.0881 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [05:34<04:12,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 | ent loss 0.0266 | rel loss 0.0015 | total loss 0.0281\n",
      "          | val ent loss 0.0695 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [05:40<04:06,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 | ent loss 0.0081 | rel loss 0.0018 | total loss 0.0100\n",
      "          | val ent loss 0.0325 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [05:46<04:00,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 | ent loss 0.0057 | rel loss 0.0016 | total loss 0.0073\n",
      "          | val ent loss 0.1197 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [05:52<03:54,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 | ent loss 0.0156 | rel loss 0.0019 | total loss 0.0174\n",
      "          | val ent loss 0.1115 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [05:57<03:48,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 | ent loss 0.0161 | rel loss 0.0015 | total loss 0.0176\n",
      "          | val ent loss 0.1000 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [06:03<03:42,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 | ent loss 0.0133 | rel loss 0.0012 | total loss 0.0146\n",
      "          | val ent loss 0.1735 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [06:08<03:36,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 | ent loss 0.0201 | rel loss 0.0017 | total loss 0.0218\n",
      "          | val ent loss 0.1135 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [06:14<03:30,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 | ent loss 0.0224 | rel loss 0.0014 | total loss 0.0239\n",
      "          | val ent loss 0.1449 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [06:20<03:24,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 | ent loss 0.0575 | rel loss 0.0013 | total loss 0.0588\n",
      "          | val ent loss 0.1411 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [06:25<03:18,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 | ent loss 0.0319 | rel loss 0.0011 | total loss 0.0330\n",
      "          | val ent loss 0.0726 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [06:30<03:12,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 | ent loss 0.0187 | rel loss 0.0011 | total loss 0.0199\n",
      "          | val ent loss 0.1585 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [06:36<03:06,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 | ent loss 0.0307 | rel loss 0.0011 | total loss 0.0318\n",
      "          | val ent loss 0.1234 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [06:42<03:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 | ent loss 0.0139 | rel loss 0.0012 | total loss 0.0151\n",
      "          | val ent loss 0.1306 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [06:48<02:54,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 | ent loss 0.0086 | rel loss 0.0012 | total loss 0.0098\n",
      "          | val ent loss 0.0639 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [06:53<02:48,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71 | ent loss 0.0040 | rel loss 0.0010 | total loss 0.0051\n",
      "          | val ent loss 0.1663 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [07:00<02:43,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 | ent loss 0.0141 | rel loss 0.0014 | total loss 0.0154\n",
      "          | val ent loss 0.1121 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [07:06<02:37,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 | ent loss 0.0165 | rel loss 0.0010 | total loss 0.0175\n",
      "          | val ent loss 0.1100 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [07:11<02:31,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 | ent loss 0.0077 | rel loss 0.0011 | total loss 0.0088\n",
      "          | val ent loss 0.1411 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [07:16<02:25,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 | ent loss 0.0102 | rel loss 0.0011 | total loss 0.0113\n",
      "          | val ent loss 0.1445 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [07:22<02:19,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76 | ent loss 0.0043 | rel loss 0.0010 | total loss 0.0053\n",
      "          | val ent loss 0.0782 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [07:27<02:13,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 | ent loss 0.0017 | rel loss 0.0010 | total loss 0.0028\n",
      "          | val ent loss 0.1985 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [07:33<02:07,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78 | ent loss 0.0017 | rel loss 0.0008 | total loss 0.0025\n",
      "          | val ent loss 0.0612 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [07:39<02:02,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 | ent loss 0.0079 | rel loss 0.0011 | total loss 0.0090\n",
      "          | val ent loss 0.0473 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [07:45<01:56,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80 | ent loss 0.0018 | rel loss 0.0012 | total loss 0.0030\n",
      "          | val ent loss 0.1281 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [07:51<01:50,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81 | ent loss 0.0035 | rel loss 0.0010 | total loss 0.0045\n",
      "          | val ent loss 0.2183 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [07:56<01:44,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82 | ent loss 0.0160 | rel loss 0.0014 | total loss 0.0174\n",
      "          | val ent loss 0.0649 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [08:02<01:38,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83 | ent loss 0.0072 | rel loss 0.0013 | total loss 0.0085\n",
      "          | val ent loss 0.1958 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [08:08<01:33,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 | ent loss 0.0023 | rel loss 0.0011 | total loss 0.0034\n",
      "          | val ent loss 0.1475 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [08:14<01:27,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85 | ent loss 0.0144 | rel loss 0.0013 | total loss 0.0157\n",
      "          | val ent loss 0.1065 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [08:19<01:21,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86 | ent loss 0.0025 | rel loss 0.0011 | total loss 0.0036\n",
      "          | val ent loss 0.0632 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [08:25<01:15,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 | ent loss 0.0051 | rel loss 0.0014 | total loss 0.0064\n",
      "          | val ent loss 0.1773 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [08:31<01:09,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88 | ent loss 0.0016 | rel loss 0.0009 | total loss 0.0026\n",
      "          | val ent loss 0.1231 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [08:38<01:04,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89 | ent loss 0.0118 | rel loss 0.0012 | total loss 0.0130\n",
      "          | val ent loss 0.1170 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [08:45<00:58,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90 | ent loss 0.0019 | rel loss 0.0010 | total loss 0.0029\n",
      "          | val ent loss 0.1159 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [08:50<00:52,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 | ent loss 0.0091 | rel loss 0.0010 | total loss 0.0101\n",
      "          | val ent loss 0.1577 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [08:56<00:46,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 | ent loss 0.0091 | rel loss 0.0010 | total loss 0.0100\n",
      "          | val ent loss 0.1657 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [09:02<00:40,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93 | ent loss 0.0045 | rel loss 0.0010 | total loss 0.0055\n",
      "          | val ent loss 0.1103 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [09:08<00:35,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 | ent loss 0.0079 | rel loss 0.0010 | total loss 0.0089\n",
      "          | val ent loss 0.2588 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [09:14<00:29,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 | ent loss 0.0050 | rel loss 0.0008 | total loss 0.0059\n",
      "          | val ent loss 0.1806 | val rel loss 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [09:19<00:23,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96 | ent loss 0.0035 | rel loss 0.0011 | total loss 0.0046\n",
      "          | val ent loss 0.2230 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [09:25<00:17,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 | ent loss 0.0110 | rel loss 0.0012 | total loss 0.0122\n",
      "          | val ent loss 0.0958 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [09:31<00:11,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98 | ent loss 0.0099 | rel loss 0.0012 | total loss 0.0111\n",
      "          | val ent loss 0.0918 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [09:39<00:05,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 | ent loss 0.0028 | rel loss 0.0010 | total loss 0.0038\n",
      "          | val ent loss 0.0823 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [09:45<00:00,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 | ent loss 0.0041 | rel loss 0.0008 | total loss 0.0049\n",
      "           | val ent loss 0.1359 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 100\n",
    "print_every = 12\n",
    "\n",
    "train_entloss_l = []\n",
    "val_entloss_l = []\n",
    "train_relloss_l = []\n",
    "val_relloss_l = []\n",
    "\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "loss = 0\n",
    "ent_loss = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(n_iters)):  \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "        batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "        \n",
    "        entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "        relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "        loss = entloss+relloss\n",
    "        \n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    train_entloss_l.append(entloss.cpu())\n",
    "    train_relloss_l.append(relloss.cpu())\n",
    "    #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "        \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "        model.eval()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "        val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "        \n",
    "    val_entloss_l.append(val_entloss.cpu())\n",
    "    val_relloss_l.append(val_relloss.cpu())\n",
    "    \n",
    "    \n",
    "    print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "          % (epoch+1, entloss, relloss, loss))\n",
    "    print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "          % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "torch.save(model.state_dict(), 'relation_extraction_1_new.pkl')\n",
    "\n",
    "# model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "#               LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "# model.load_state_dict(torch.load('relation_extraction.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_entloss_l, label='train_ent_loss')\n",
    "plt.plot(val_entloss_l, label='val_ent_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entity Loss\") \n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_relloss_l, label='train_rel_loss')\n",
    "plt.plot(val_relloss_l, label='val_rel_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relation Loss\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_choose(input_var):\n",
    "    r_choose = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        r_choose.append(random.randint(0,len(input_var)))\n",
    "    return r_choose\n",
    "        \n",
    "def ent_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,ent_size).argmax(2)\n",
    "    return output\n",
    "\n",
    "def rel_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,MAX_LEN,rel_size).argmax(3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "true : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Entity loss : 0.0036\n",
      "Relation loss : 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    r_choose = random_choose(input_var)\n",
    "    model.eval()\n",
    "    ent_output, rel_output = model(input_var[r_choose].cuda() if USE_CUDA else input_var, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "    \n",
    "    batchsize = input_var[r_choose].size(0)\n",
    "    \n",
    "    ent_loss = criterion_tag(ent_output.cpu(), ent_var[r_choose].view(BATCH_SIZE*MAX_LEN))\n",
    "    ent_output = ent_argmax(ent_output, batchsize)\n",
    "    \n",
    "    rel_loss = criterion_rel(rel_output.cpu(), rel_var[r_choose].view(BATCH_SIZE*MAX_LEN*MAX_LEN))\n",
    "    \n",
    "    print()\n",
    "    print('predict :', index2tag(ent_output[0], ix_to_ent_tag))\n",
    "    print('true :', index2tag(ent_var[r_choose[0]], ix_to_ent_tag))\n",
    "    \n",
    "    print()\n",
    "    print(\"Entity loss : %.4f\" % ent_loss)\n",
    "    print(\"Relation loss : %.4f\" % rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "def evaluate_data(data_loader, raw_input, isTrain=False, silent=False):\n",
    "    tps, fps, tns, fns = 0, 0, 0, 0\n",
    "    y_ent_true_all, y_ent_pred_all = [], []\n",
    "    y_rel_true_all, y_rel_pred_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(data_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            ent_loss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN))\n",
    "            ent_output = ent_argmax(ent_output, batchsize)\n",
    "\n",
    "            rel_loss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "            rel_output = rel_argmax(rel_output, batchsize)\n",
    "\n",
    "\n",
    "            print()    \n",
    "            print(\"Entity loss : %.4f\" % ent_loss)\n",
    "            print(\"Relation loss : %.4f\" % rel_loss)\n",
    "            print()\n",
    "\n",
    "            tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel = \\\n",
    "            batch_decode(ent_output, rel_output, batch_index, raw_input, batch_ent, batch_rel, silent)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('===========================================')\n",
    "\n",
    "            y_ent_true_all.extend(y_true_ent)\n",
    "            y_ent_pred_all.extend(y_pred_ent)\n",
    "\n",
    "            y_rel_true_all.extend(y_true_rel)\n",
    "            y_rel_pred_all.extend(y_pred_rel)\n",
    "            \n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            tns += tn\n",
    "            fns += fn\n",
    "            \n",
    "    \n",
    "        print()\n",
    "        print(\"Entity detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(precision_recall_fscore_support(y_ent_true_all, y_ent_pred_all, average='micro', \n",
    "                                                  labels=range(len(schema['entity']))))\n",
    "        print()\n",
    "        print(\"Relation detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(precision_recall_fscore_support(y_rel_true_all, y_rel_pred_all, average='micro', \n",
    "                                              labels=range(len(schema['relation']))))\n",
    "        print()\n",
    "        print(\"ReferenceEntity+Relation score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tps, fps, tns, fns), tps, fps, tns, fns)\n",
    "            \n",
    "            \n",
    "def batch_decode(ent_output, rel_output, batch_index, word_lists, true_ent, true_rel, silent):\n",
    "    \n",
    "    eval_ent_list_true_l, eval_rel_list_true_l = [], []\n",
    "    eval_ent_list_pred_l, eval_rel_list_pred_l = [], []\n",
    "    \n",
    "    for e,r,i,te,tr in zip(ent_output, rel_output, batch_index, true_ent, true_rel):\n",
    "        \n",
    "        # 算句子長度\n",
    "        len_of_list = len(word_lists[i])\n",
    "        word_list = word_lists[i]\n",
    "        true_ent = index2tag(te, ix_to_ent_tag)[:len_of_list]\n",
    "        pridict_ent = index2tag(e, ix_to_ent_tag)[:len_of_list]     \n",
    "        \n",
    "        # 單句decode關係\n",
    "        true_r_list, appear_error = decode_rel(te, tr)   # true\n",
    "        pre_r_list, appear_error = decode_rel(e, r)      # predict\n",
    "        \n",
    "        true_r_list = [list(set(i)) if type(i) is list else i for i in true_r_list]\n",
    "        pre_r_list = [list(set(i)) if type(i) is list else i for i in pre_r_list]\n",
    "        \n",
    "        # 出現error，跳過這句\n",
    "        if appear_error:\n",
    "            continue\n",
    "        \n",
    "        true_r_list = true_r_list[:len_of_list]\n",
    "        pre_r_list = pre_r_list[:len_of_list]\n",
    "        \n",
    "        \n",
    "        # 評分用\n",
    "        eval_ent_list_true, err_count = decode_ent(true_ent, schema)\n",
    "        eval_rel_list_true = decode_rel_to_eval(true_r_list, schema, eval_ent_list_true)\n",
    "        \n",
    "        eval_ent_list_pred, err_count = decode_ent(pridict_ent, schema)\n",
    "        eval_rel_list_pred = decode_rel_to_eval(pre_r_list, schema, eval_ent_list_pred)\n",
    "        \n",
    "        if not silent:\n",
    "            print(word_list)\n",
    "            print(true_ent)\n",
    "            print(true_r_list)\n",
    "            print()\n",
    "            print('Predict output')\n",
    "            print(pridict_ent)\n",
    "            print(pre_r_list)\n",
    "            print()\n",
    "            print('True')\n",
    "            print(eval_ent_list_true)\n",
    "            print(eval_rel_list_true)\n",
    "            print('predict')\n",
    "            print(eval_ent_list_pred)\n",
    "            print(eval_rel_list_pred)\n",
    "            print(\"=====================================\")\n",
    "        \n",
    "        eval_ent_list_true_l.append(eval_ent_list_true)\n",
    "        eval_rel_list_true_l.append(eval_rel_list_true)\n",
    "        eval_ent_list_pred_l.append(eval_ent_list_pred)\n",
    "        eval_rel_list_pred_l.append(eval_rel_list_pred)\n",
    "    \n",
    "    \n",
    "    e_score, y_true_ent, y_pred_ent = get_scores(eval_ent_list_true_l, eval_ent_list_pred_l, \\\n",
    "                                                 range(len(schema['entity'])),output_y=True)\n",
    "    r_score, y_true_rel, y_pred_rel = get_scores(eval_rel_list_true_l, eval_rel_list_pred_l, \\\n",
    "                                                 range(len(schema['relation'])),output_y=True)\n",
    "    \n",
    "    tp, fp, tn, fn = relation_error_analysis(eval_rel_list_true_l, eval_rel_list_pred_l)\n",
    "    \n",
    "    if not silent:\n",
    "        print('Batch entity score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(e_score)\n",
    "        print()\n",
    "        print('Batch relation score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(r_score)\n",
    "        print()\n",
    "        print('p_r_fscore')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tp, fp, tn, fn), tp, fp, tn, fn)\n",
    "    \n",
    "    return tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def decode_ent(pred_ent, schema):\n",
    "    '''\n",
    "    Aggregate entities from predicted tags\n",
    "    Input:\n",
    "    pred_ent=a list of entity tags in a sentence\n",
    "    schema=the dictionary defining entities and relations\n",
    "    Output: \n",
    "    ent_list=[(ent_start, ent_end, ent_type=eid_in_schema)]\n",
    "    err_count=the number of bad tags\n",
    "    '''\n",
    "    ent_list = []\n",
    "    ent_start = 0\n",
    "    ent_end = 0\n",
    "    state = {\n",
    "        'ENT_SPAN': 0,\n",
    "        'NO_ENT': 1\n",
    "    }\n",
    "    err_count = 0\n",
    "    ent_type = ''\n",
    "    sid = state['NO_ENT']\n",
    "    for idx, e_tag in enumerate(pred_ent):\n",
    "        bio = e_tag[0]\n",
    "        type_tag = e_tag.split('-')[-1]\n",
    "        if sid == state['NO_ENT']:\n",
    "            if bio == 'B':\n",
    "                ent_start = idx\n",
    "                ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                sid = state['ENT_SPAN']\n",
    "            elif bio == 'I':\n",
    "                err_count += 1\n",
    "        elif sid == state['ENT_SPAN']:\n",
    "            if bio != 'I':\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                if bio == 'B':\n",
    "                    ent_start = idx\n",
    "                    ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                else:\n",
    "                    sid = state['NO_ENT']\n",
    "            elif ent_type != get_eid_from_tag(type_tag, schema):\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                err_count += 1\n",
    "                sid = state['NO_ENT']\n",
    "    if sid == state['ENT_SPAN']:\n",
    "        ent_end = len(pred_ent) - 1\n",
    "        ent_list.append((ent_start, ent_end, ent_type))\n",
    "    return ent_list, err_count\n",
    "\n",
    "def get_eid_from_tag(tag, schema):\n",
    "    '''\n",
    "    Assume schema is a dictionary in schema.txt\n",
    "    return eid or -1 if no match is found\n",
    "    '''\n",
    "    for content in schema['entity'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['eid']\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def decode_rel_to_eval(r_list, schema, ent_list):\n",
    "    \n",
    "    max_pair = 0\n",
    "    for r in r_list:\n",
    "        if type(r) is list:\n",
    "            for single_r in r:\n",
    "                if int(single_r[-3])>max_pair:\n",
    "                    max_pair = int(single_r[-3])\n",
    "    \n",
    "\n",
    "    pair_idx = {}\n",
    "    for pair in range(max_pair+1):\n",
    "        for i, r in enumerate(r_list):\n",
    "            if type(r) is list:\n",
    "                for single_r in r:\n",
    "                    if int(single_r[-3])==pair:\n",
    "                        if pair not in pair_idx:\n",
    "                            pair_idx[pair] = [i]\n",
    "                        else:\n",
    "                            pair_idx[pair].append(i)\n",
    "    \n",
    "    \n",
    "#     # 算兩兩不同tag的數目\n",
    "#     e_type_dict = {}\n",
    "#     for e_pair in ent_list:\n",
    "#         if e_pair[-1] not in e_type_dict:\n",
    "#             e_type_dict[e_pair[-1]] = 1\n",
    "#         else:\n",
    "#             e_type_dict[e_pair[-1]] += 1\n",
    "    \n",
    "#     total_pair = 0\n",
    "#     e_type_l = list(e_type_dict.values())\n",
    "#     for i, ent_type_num_1 in enumerate(e_type_l):\n",
    "#         for j, ent_type_num_2 in enumerate(e_type_l[i+1:]):\n",
    "#             pair_num = ent_type_num_1*ent_type_num_2\n",
    "#             total_pair += pair_num\n",
    "\n",
    "    pair_list = []\n",
    "    for i, e_pair_1 in enumerate(ent_list):\n",
    "        for j, e_pair_2 in enumerate(ent_list[i+1:]):\n",
    "            if e_pair_1[-1]!=e_pair_2[-1]:\n",
    "                pair_list.append([e_pair_1, e_pair_2])\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    eval_rel_list = []\n",
    "    for pair in pair_idx:\n",
    "        rel_loc = pair_idx[pair]\n",
    "        for e_pairs in pair_list:\n",
    "            check_pair = True\n",
    "            first_start = e_pairs[0][0]\n",
    "            first_end = e_pairs[0][1]\n",
    "            sec_start = e_pairs[1][0]\n",
    "            sec_end = e_pairs[1][1]\n",
    "            \n",
    "            first_l = list(range(first_start, first_end+1))\n",
    "            sec_l = list(range(sec_start, sec_end+1))\n",
    "            combine_l = first_l+sec_l\n",
    "\n",
    "            \n",
    "            check_in_entity = []\n",
    "            for x in combine_l:\n",
    "                if x in rel_loc:\n",
    "                    check_in_entity.append(True)\n",
    "                else:\n",
    "                    check_in_entity.append(False)\n",
    "                    check_pair = False\n",
    "                    break             \n",
    "\n",
    "            if all(check_in_entity)==True:\n",
    "                for r in r_list[first_start]:\n",
    "                    r_info = r.split('-')\n",
    "                    \n",
    "                    if int(r_info[1])==pair:\n",
    "                        r_tag = get_rid_from_tag(r_info[0], schema)\n",
    "                        e_pairs_copy = e_pairs\n",
    "                        e_pairs_copy.append(r_tag)\n",
    "                        eval_rel_list.append(tuple(e_pairs_copy))\n",
    "    \n",
    "    return eval_rel_list\n",
    "    \n",
    "        \n",
    "def get_rid_from_tag(tag, schema):   \n",
    "    for content in schema['relation'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['rid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rel_info(ent_output):\n",
    "    r_list = []     # 存放完整關係\n",
    "    r_dict = {}     # 記錄關係資訊\n",
    "    appear_error = False\n",
    "\n",
    "    pred_ent = index2tag(ent_output, ix_to_ent_tag)\n",
    "    \n",
    "\n",
    "    e_loc = 0       # 當前遇到的entity的位置\n",
    "    for loc, e in enumerate(pred_ent):\n",
    "        if e[0]=='B':\n",
    "            e_loc = loc\n",
    "            r_dict[loc] = {\n",
    "                '_2ndtag':e[2:],\n",
    "                'end':loc,\n",
    "            }\n",
    "            r_list.append([])\n",
    "                   \n",
    "        elif e[0]=='I':\n",
    "            # 錯誤來自於，entity預測錯誤，沒有預測到B tag，直接跳到I tag\n",
    "            # 所以沒有紀錄e_loc\n",
    "            try: \n",
    "                r_dict[e_loc]['end'] = loc\n",
    "            except KeyError:\n",
    "                appear_error = True\n",
    "                break\n",
    "            \n",
    "            r_list.append([])\n",
    "            \n",
    "        else:\n",
    "            r_list.append(\"\")\n",
    "              \n",
    "    return r_list, r_dict, appear_error\n",
    "        \n",
    "        \n",
    "def decode_rel(ent_output, rel_output):\n",
    "\n",
    "    r_list, r_dict, appear_error = create_rel_info(ent_output) \n",
    "    \n",
    "    IsB = False           # 是否遇到B tag的lock\n",
    "    IsNext = False        # 是否為B tag後面的tag 的lock\n",
    "    num_reocrd = -1       # 紀錄pair數\n",
    "    now_loc = 0\n",
    "    pre_rel_end_loc = 0\n",
    "    now_rel_end_loc = 0\n",
    "    \n",
    "    rel_keyerror = False\n",
    "    \n",
    "    for now in range(len(rel_output)):\n",
    "        for loc, rel in enumerate(rel_output[now][:now+1]):\n",
    "            rel = rel.cpu().numpy()\n",
    "            \n",
    "#             print(rel, IsB, IsNext)\n",
    "            \n",
    "            # 有關係存在，且為B tag \n",
    "            if rel!=rel_tag_to_ix[REL_NONE] and IsB==False and IsNext==False:\n",
    "\n",
    "                IsB = True\n",
    "                IsNext = True\n",
    "                tag = ix_to_rel_tag[int(rel)]\n",
    "                num_reocrd+=1\n",
    "                now_loc = loc\n",
    "                \n",
    "                # 錯誤來自於，now_loc找不到，也就是說，rel預測出來是有關係存在\n",
    "                # 但預測是'O'\n",
    "                # 而在entity中卻沒有預測出來，所以r_dict中沒有紀錄\n",
    "                try:\n",
    "                    pre_rel_end_loc = r_dict[now_loc]['end']\n",
    "\n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    now_rel_end_loc = r_dict[now]['end']\n",
    "                    \n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                second_tag = r_dict[now_loc]['_2ndtag']\n",
    "                preAorB = check_rel_loc(second_tag, schema)\n",
    "                nowAorB = 'B' if preAorB=='A' else 'A'\n",
    "                \n",
    "                pre_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+preAorB\n",
    "                now_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+nowAorB\n",
    "                \n",
    "                # 將以前的token填上關係\n",
    "                for token in range(now_loc, pre_rel_end_loc+1):\n",
    "                    \n",
    "                    # 出現以下error\n",
    "                    '''AttributeError: 'str' object has no attribute 'append'''\n",
    "                    # 為 r_list 前處理中沒有給予可能有關係的位置空的list\n",
    "                    try:\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "                    except AttributeError:\n",
    "                        r_list[token] = []\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "\n",
    "             \n",
    "                # 當前token填上關係\n",
    "                r_list[now].append(now_complete_rel)\n",
    "                \n",
    "\n",
    "            \n",
    "            # 關係前位中B tag後面的tag\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsB:\n",
    "                # 如果還在這個entity的範圍內\n",
    "                if loc<=pre_rel_end_loc:\n",
    "                    pass\n",
    "                \n",
    "                # 超出現在這個entity的範圍，改lock\n",
    "                else:\n",
    "                    IsB = False\n",
    "\n",
    "            \n",
    "            # B tag後面的tag的關係，依照前面的關係複製\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsNext:\n",
    "                r_list[now] = r_list[now-1]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if now<=now_rel_end_loc:\n",
    "                    IsB = False\n",
    "                else:\n",
    "                    IsB = False\n",
    "                    IsNext = False\n",
    "\n",
    "        \n",
    "        if rel_keyerror:\n",
    "            rel_keyerror = False\n",
    "            break\n",
    "                \n",
    "                \n",
    "    return r_list, appear_error\n",
    "                \n",
    "\n",
    "# 是三元關係中的前者還是後者                  \n",
    "def check_rel_loc(second_tag, schema):\n",
    "    convert_tag = ''\n",
    "\n",
    "    for ent_content in schema['entity']:\n",
    "        if schema['entity'][ent_content]['tag']==second_tag:\n",
    "            convert_tag = ent_content\n",
    "    \n",
    "    rel_types = schema['relation'].values()\n",
    "\n",
    "    for rel_content in schema['relation'].values():\n",
    "        for AorB in rel_content['arguments']:\n",
    "            if rel_content['arguments'][AorB]==convert_tag:\n",
    "                return AorB\n",
    "            \n",
    "\n",
    "            \n",
    "def get_scores(true_lists, pred_lists, labels, output_y=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for t_list, p_list in zip(true_lists, pred_lists):\n",
    "        yt, yp = align_yt_yp(t_list, p_list, labels)\n",
    "        y_true.extend(yt)\n",
    "        y_pred.extend(yp)\n",
    "        \n",
    "    scores = precision_recall_fscore_support(y_true, y_pred, average='micro', labels=labels)\n",
    "    return scores, y_true, y_pred if output_y else scores\n",
    "\n",
    "def align_yt_yp(truths, predictions, labels):\n",
    "    '''\n",
    "    Input:\n",
    "        truths/predictions: list of true and predicted tuples, \n",
    "        with the leading entries as the structure and the last entry as the class,\n",
    "        e.g., [(e1, e2, rel), ...]\n",
    "        labels: sequence of valid class\n",
    "    Output:\n",
    "        yt: list of true class given a structure\n",
    "        yp: list of predicted class given a structure\n",
    "    '''\n",
    "    yt, yp = [], []\n",
    "    _ID_NONE = len(labels)\n",
    "    true_dict = { t[:-1]: t[-1] for t in truths }\n",
    "    for p in predictions:\n",
    "        yt.append(true_dict.pop(p[:-1], _ID_NONE))\n",
    "        yp.append(p[-1])\n",
    "    for target in true_dict.values():\n",
    "        yt.append(target)\n",
    "        yp.append(_ID_NONE)\n",
    "    return yt, yp\n",
    "\n",
    "\n",
    "\n",
    "def is_neg_triple(t):\n",
    "    return np.imag(t[-1]) > 0\n",
    "\n",
    "def negate_triple(t):\n",
    "    # Mark negative triples with imaginary relation id\n",
    "    return (t[0], t[1], np.real(t[-1]).item() + 1j)\n",
    "\n",
    "def posit_triple(t):\n",
    "    return (t[0], t[1], np.real(t[-1]).item())\n",
    "\n",
    "def has_edge(base_ptrs, rel, e):\n",
    "    '''\n",
    "    Assume a relation exist between an entity pair, \n",
    "    if all the tokens in the base entity point to those in entity e.\n",
    "    '''\n",
    "    tok_has_ptr_to_e = [tok_ptrs[rel].ge(e[0]).dot(tok_ptrs[rel].le(e[1])).item() > 0 \n",
    "                        for tok_ptrs in base_ptrs]\n",
    "    return len(tok_has_ptr_to_e) > 0 and all(tok_has_ptr_to_e)\n",
    "\n",
    "\n",
    "def relation_error_analysis(true_rel_lists, rel_lists):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, r_list in enumerate(rel_lists):\n",
    "        true_pos = len([t for t in r_list if t in true_rel_lists[i]])\n",
    "        all_true = len([t for t in true_rel_lists[i] if not is_neg_triple(t)])\n",
    "        all_pos = len(r_list)\n",
    "        tp += true_pos\n",
    "        fn += all_true - true_pos\n",
    "        fp += all_pos - true_pos\n",
    "        tn += len([t for t in true_rel_lists[i] if is_neg_triple(t) and posit_triple(t) not in r_list])\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def p_r_fscore(tp, fp, tn, fn, beta=1, eps=1e-8):\n",
    "    p = tp / (tp + fp + eps)\n",
    "    r = tp / (tp + fn + eps)\n",
    "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r + eps))\n",
    "    return p, r, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.0917\n",
      "Relation loss : 0.0009\n",
      "\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(16, 17, 0), (24, 25, 1)]\n",
      "[((16, 17, 0), (24, 25, 1), 0)]\n",
      "=====================================\n",
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', [], [], '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], ['ApplyTo-1-B', 'ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 't', 'e', 'p', '2', '.', '強', '化', '補', '水', '-', '嫩', '白', '蠶', '絲', '面', '膜', '-', '面', '膜', '非', '常', '薄', '貼', '，', '記', '得', '要', '把', '蠶', '絲', '面', '膜', '朝', '臉', '敷', '上', '後', '再', '把', '珍', '珠', '膜', '撕', '下', '布', '料', '採', '用', '凝', '水', '蠶', '絲', '，', '清', '透', '，', '用', '天', '然', '草', '本', '植', '物', '萃', '取', '的', '精', '華', '，', '幫', '助', '保', '濕', '，', '也', '可', '以', '舒', '緩', '一', '些', '夏', '季', '保', '養', '時', '乾', '燥', '肌', '的', '狀', '況']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', [], [], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', [], [], '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(72, 73, 0), (78, 79, 0), (84, 85, 0), (87, 89, 1)]\n",
      "[((78, 79, 0), (87, 89, 1), 0)]\n",
      "predict\n",
      "[(72, 73, 0), (78, 79, 0), (84, 85, 0), (87, 89, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['極', '效', '肌', '因', '修', '護', '巨', '藻', '、', '齒', '缘', '墨', '角', '藻', '複', '合', '水', '解', '酵', '母', '提', '取', '物', '，', '浸', '透', '濕', '潤', '乾', '燥', '肌', '膚', '，', '增', '強', '防', '護', '屏', '障', '，', '協', '同', '蘆', '薈', '、', '山', '金', '車', '及', '光', '果', '甘', '草', '植', '萃', '精', '華', '，', '深', '度', '安', '撫', '同', '時', '舒', '緩', '肌', '膚', '的', '不', '適', '，', '拋', '開', '惱', '人', '的', '乾', '燥', '缺', '水', '不', '安', '讓', '肌', '膚', '穩', '定']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(28, 31, 1)]\n",
      "[]\n",
      "predict\n",
      "[(28, 31, 1), (64, 65, 0)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8604651162790697, 1.0, 0.9249999999999999, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.75, 0.25, 0.375, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7499999981250001, 0.24999999979166665, 0.37499999578125004) 3 1 0 9\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1156\n",
      "Relation loss : 0.0009\n",
      "\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (9, 13, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', [], [], [], [], [], '', '', [], []]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1), (22, 23, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['而', '面', '膜', '的', '精', '華', '液', '不', '算', '多', '，', '但', '也', '很', '夠', '用', '了', '，', '是', '敷', '上', '之', '後', '不', '會', '滴', '下', '的', '量', '，', '剛', '剛', '好', '，', '精', '華', '液', '本', '身', '沒', '什', '麼', '香', '味', '，', '我', '這', '個', '小', '敏', '感', '的', '油', '性', '肌', '老', '實', '說', '敷', '完', '之', '後', '卻', '什', '麼', '感', '覺', '都', '沒', '有', '，', '沒', '有', '過', '敏', '、', '沒', '有', '感', '覺', '特', '別', '保', '水', '、', '緊', '緻', '.', '.', '.', '等']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '']\n",
      "\n",
      "True\n",
      "[(52, 54, 1), (85, 86, 0)]\n",
      "[]\n",
      "predict\n",
      "[(52, 54, 1), (85, 86, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['洗', '完', '臉', '後', '，', '我', '將', '「', '我', '的', '美', '麗', '日', '記', '」', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '敷', '在', '臉', '上', '，', '經', '過', '2', '0', '分', '鐘', '後', '，', '將', '面', '膜', '從', '臉', '部', '由', '下', '往', '上', '撕', '下', '，', '再', '用', '清', '水', '將', '面', '膜', '清', '洗', '乾', '淨', '後', '，', '從', '鏡', '子', '中', '我', '看', '到', '臉', '部', '肌', '膚', '乾', '燥', '缺', '水', '的', '現', '象', '消', '失', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(76, 79, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 0), (76, 79, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['以', '上', '是', '我', '不', '會', '再', '使', '用', '此', '產', '品', '，', '也', '不', '會', '推', '薦', '親', '友', '使', '用', '的', '原', '因', '，', '最', '大', '原', '因', '是', '因', '為', '；', '居', '然', '在', '使', '用', '後', '，', '肌', '膚', '反', '而', '變', '得', '乾', '到', '發', '癢', '，', '可', '見', '產', '品', '若', '無', '法', '真', '正', '提', '供', '乾', '性', '肌', '膚', '滋', '潤', '和', '保', '濕', '的', '話', '，', '添', '加', '再', '多', '吸', '引', '消', '費', '者', '的', '成', '分', '也', '不', '見', '得', '能', '得', '到', '消', '費', '者', '的', '心']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(63, 66, 1), (70, 71, 0)]\n",
      "[]\n",
      "predict\n",
      "[(63, 66, 1), (70, 71, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['精', '華', '液', '內', '含', '酵', '母', '萃', '取', '，', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '，', '可', '以', '達', '到', '保', '濕', '效', '用', '，', '質', '地', '清', '爽', '滑', '順', '，', '敷', '用', '時', '保', '濕', '滋', '潤', '度', '相', '當', '不', '錯', '，', '可', '以', '修', '護', '肌', '膚', '乾', '燥', '缺', '水', '部', '位', '，', '取', '下', '面', '膜', '後', '的', '肌', '膚', '立', '即', '透', '亮', '飽', '滿', '，', '連', '毛', '孔', '都', '明', '顯', '縮', '小']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(32, 33, 0), (47, 48, 0), (61, 64, 1)]\n",
      "[((47, 48, 0), (61, 64, 1), 0)]\n",
      "predict\n",
      "[(32, 33, 0), (47, 48, 0), (61, 64, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7297297297297297, 0.9310344827586207, 0.8181818181818181, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5, 0.16666666666666666, 0.25, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.4999999975, 0.16666666638888888, 0.24999999562500003) 1 1 0 5\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1992\n",
      "Relation loss : 0.0010\n",
      "\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], '', [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['效', '果', '方', '面', '我', '覺', '得', '還', '不', '錯', ',', '因', '為', '我', '是', '混', '合', '性', '肌', '膚', ',', '敷', '完', '了', '之', '後', '有', '覺', '得', '還', '滿', '保', '濕', '的', ',', '隔', '天', '早', '上', '起', '來', '比', '較', '會', '出', '油', '的', '地', '方', ',', '出', '油', '狀', '況', '就', '比', '較', '沒', '有', '那', '麼', '嚴', '重', '了', ',', '整', '題', '來', '說', '還', '滿', '推', '薦', '的', '喔']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(15, 19, 1), (31, 32, 0)]\n",
      "[((15, 19, 1), (31, 32, 0), 0)]\n",
      "predict\n",
      "[(15, 19, 1), (31, 32, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1), (14, 15, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(6, 7, 0), (29, 30, 0), (43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 0), (30, 33, 1)]\n",
      "[((25, 26, 0), (30, 33, 1), 0)]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7222222222222222, 1.0, 0.8387096774193548, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(1.0, 0.2, 0.33333333333333337, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.9999999900000002, 0.1999999996, 0.33333332944444444) 1 0 0 4\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7857142857142857, 0.9746835443037974, 0.8700564971751412, None)\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7142857142857143, 0.21739130434782608, 0.3333333333333333, None)\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7142857132653061, 0.21739130425330813, 0.33333332953333333) 5 2 0 18\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = root+'facial_r2.test'\n",
    "input_test, ent_test, rel_test, raw_index_test, raw_input_test = dev_preprocess(test_data)\n",
    "test_loader = dataload(input_test, ent_test, rel_test, raw_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.1361\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0847\n",
      "Relation loss : 0.0015\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1096\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.2003\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1366\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.2103\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0957\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0595\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1123\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1365\n",
      "Relation loss : 0.0008\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1781\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1178\n",
      "Relation loss : 0.0009\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1071\n",
      "Relation loss : 0.0013\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1161\n",
      "Relation loss : 0.0008\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1473\n",
      "Relation loss : 0.0009\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1969\n",
      "Relation loss : 0.0012\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1005\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1215\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1980\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1584\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1161\n",
      "Relation loss : 0.0010\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1784\n",
      "Relation loss : 0.0011\n",
      "\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7749419953596288, 0.9766081871345029, 0.8641655886157826, None)\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5113636363636364, 0.2631578947368421, 0.34749034749034746, None)\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.511363636305527, 0.26315789472145273, 0.347490342976998) 45 43 0 126\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果結果不好\n",
    "# 多繼續train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
