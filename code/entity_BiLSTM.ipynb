{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "\n",
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def schema_load(schema_root):\n",
    "    raw_dict = \"\".join(readfile(schema_root))\n",
    "    dict2json = \"\".join(raw_dict.split()[2:])\n",
    "\n",
    "    json_acceptable_string = dict2json.replace(\"'\", \"\\\"\")\n",
    "    schema = json.loads(json_acceptable_string)\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def define_entity(schema):\n",
    "    tag_type = list(schema['tagging'])\n",
    "    \n",
    "    entity_tag = []\n",
    "    for k in list(schema['entity'].keys()):\n",
    "        entity_tag.append(schema['entity'][k]['tag'])\n",
    "        \n",
    "    TAG = []\n",
    "    for t in tag_type:\n",
    "        for e in entity_tag:\n",
    "            if t!='O':\n",
    "                TAG.append(t+'-'+e)  \n",
    "                \n",
    "    TAG = [UNKOWN_TAG, PAD_TAG] + TAG + ['O']   \n",
    "\n",
    "    return TAG\n",
    "\n",
    "def tag2ix(TAG):\n",
    "    tag_to_ix={t:i for i,t in enumerate(TAG)}\n",
    "    return tag_to_ix\n",
    "\n",
    "def define_relation(schema):\n",
    "    relation_type = list(schema['relation'])\n",
    "    \n",
    "    relation_tag = []\n",
    "    for k in list(schema['relation'].keys()):\n",
    "        relation_tag.append(schema['relation'][k]['tag'])\n",
    "    \n",
    "    relation_tag = [REL_PAD] + [REL_NONE] + relation_tag\n",
    "        \n",
    "    return relation_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_set = word_set.split()\n",
    "        if len(word_set)==1:\n",
    "            word_list.append(' ')\n",
    "            ent_list.append('O')\n",
    "            rel_list.append(REL_NONE)\n",
    "        \n",
    "        else:\n",
    "            word_list.append(word_set[0])\n",
    "            ent_list.append(word_set[1])\n",
    "\n",
    "            try:\n",
    "                testerror = word_set[2]\n",
    "            except IndexError:\n",
    "                rel_list.append(REL_NONE)\n",
    "            else:\n",
    "                rel_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    ent_list = []\n",
    "    rel_list = []\n",
    "\n",
    "    for now_token, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, ents, rels = get_word_and_label(content, init, now_token)\n",
    "            init = now_token+1\n",
    "            word_list.append(words)\n",
    "            ent_list.append(ents)\n",
    "            rel_list.append(rels)\n",
    "            \n",
    "    return word_list, ent_list, rel_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, ent_list, rel_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_ent = list(ent_list[i] for i in reserved_index)\n",
    "    filter_rel = list(rel_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_ent, filter_rel\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq, isrel):\n",
    "    if isrel:\n",
    "        seq += [REL_NONE for i in range(MAX_LEN-len(seq))]\n",
    "    else:\n",
    "        seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_ent, filter_rel):\n",
    "    input_padded = [pad_seq(s, False) for s in filter_word]\n",
    "    ent_padded = [pad_seq(s, False) for s in filter_ent]\n",
    "    rel_padded = [pad_seq(s, True) for s in filter_rel]\n",
    "    \n",
    "    return input_padded, ent_padded, rel_padded\n",
    "\n",
    "def deep_copy_lists(filter_word, filter_ent, filter_rel):\n",
    "    f_w = copy.deepcopy(filter_word)\n",
    "    f_e = copy.deepcopy(filter_ent)\n",
    "    f_r = copy.deepcopy(filter_rel)\n",
    "    \n",
    "    return f_w, f_e, f_r\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "\n",
    "\n",
    "def prepare_rel(rel_padded, to_ix):\n",
    "    \n",
    "    rel_ptr = torch.zeros(len(rel_padded), MAX_LEN, MAX_LEN, dtype=torch.long) \n",
    "    \n",
    "    # 對當前的token，去比較之前所有出現過的entity，是否有關係，建成矩陣\n",
    "    # [B*ML*ML]，第二維ML是當前token，第三維ML是根據當前token對之前出現過的entity紀錄關係，以index紀錄\n",
    "    for i, rel_seq in enumerate(rel_padded):\n",
    "        rel_dict = {}\n",
    "        for j, token_seq in enumerate(rel_seq):\n",
    "            rel_ptr[i][j][:j+1] = 1\n",
    "            if token_seq != REL_NONE:\n",
    "                for k, rel in enumerate(token_seq):\n",
    "\n",
    "                    # if 是第一次出現，紀錄後面數字(標第幾對)和關係位置(A OR B)\n",
    "                    # 假如下次出現又是同個關係位置(A)，依然紀錄\n",
    "                    # 直到下次出現關係位置B，依照之前紀錄的A位置的字，然後在第三維去標關係\n",
    "\n",
    "                    rel_token = rel.split('-')\n",
    "                    if rel_token[1] not in rel_dict:\n",
    "                        rel_dict[rel_token[1]] = {'rel':rel_token[0], 'loc':rel_token[2], 'idx':[j]}\n",
    "\n",
    "                    elif rel_token[1] in rel_dict and rel_dict[rel_token[1]]['loc']==rel_token[2]:\n",
    "                        rel_dict[rel_token[1]]['idx'].append(j)\n",
    "\n",
    "                    else:\n",
    "                        record_loc = rel_dict[rel_token[1]]['idx']\n",
    "                        for idxx in record_loc:\n",
    "                            rel_ptr[i][j][idxx] = to_ix[rel_token[0]]\n",
    "                            \n",
    "    return rel_ptr\n",
    "                \n",
    "\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def dataload(input_var, ent_var, rel_var, raw_input):\n",
    "    torch_dataset = Data.TensorDataset(input_var, ent_var, rel_var, raw_input)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=0,       \n",
    "#         drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_entity(entity):\n",
    "    entity = entity.view(BATCH_SIZE,ent_size).argmax(1)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output, rel_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        self.rel_size = rel_size\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, self.attn_output, )# bias=False)\n",
    "        self.w2 = nn.Linear(self.attn_input, self.attn_output, )# bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(self.attn_output, self.rel_size, bias=False)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, encoder_outputs):\n",
    "        \n",
    "        decoder = encoder_outputs[:,-1,:].unsqueeze(1)                       #B*1*(ts+LE) [128,1,8]\n",
    "        encoder_score = self.w1(encoder_outputs)                             #B*now len*ATTN_OUT\n",
    "        decoder_score = self.w2(decoder)                                     #B*1*ATTN_OUT\n",
    "        energy = self.tanh(encoder_score+decoder_score)                      #B*now len*ATTN_OUT            \n",
    "        \n",
    "        energy = self.v(energy)                                              #B*now len*rel_size\n",
    "        \n",
    "        \n",
    "        # 針對每個entity做softmax，去顯示他們的關係權重\n",
    "        # 主要都會是rel_none\n",
    "        # 對第二維(rel)做softmax\n",
    "        p = self.softmax(energy)                                         #B*now len*rel_size\n",
    "        \n",
    "        return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, ent_tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim, rel_tag_to_ix):\n",
    "        \n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.ent_to_ix = ent_tag_to_ix\n",
    "        self.ent_size = len(ent_tag_to_ix)                   #es\n",
    "        self.rel_to_ix = rel_tag_to_ix\n",
    "        self.rel_size = len(rel_tag_to_ix)                   #rs           \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim1, momentum=0.5, affine=False)\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "#         self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "#                             num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)        \n",
    "        self.bilstm = nn.GRU(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.ent_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.ent_size, self.label_embed_dim)\n",
    "        \n",
    "        self.attn = Attn(ATTN_IN, ATTN_OUT, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, self.batch, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(self.batch, self.hidden_dim2)              #B*h2\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(self.batch, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_entity(self):\n",
    "        output_tensor = torch.zeros(self.batch, MAX_LEN, self.ent_size)  #B*ML*es\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "    \n",
    "    def create_rel_matrix(self):\n",
    "        rel_tensor = torch.zeros(self.batch, MAX_LEN, MAX_LEN, self.rel_size)  #B*ML*ML*rs\n",
    "        return rel_tensor.cuda()if USE_CUDA else rel_tensor\n",
    "    \n",
    "    \n",
    "        \n",
    "    def forward(self, sentence, batch_ent, isTrain=True):\n",
    "        \n",
    "        self.batch = sentence.size(0)\n",
    "#         self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        entity_tensor = self.create_entity()                    #B*ML*es\n",
    "        rel_tensor = self.create_rel_matrix()                   #B*ML*ML*rs\n",
    "        \n",
    "        \n",
    "\n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "#         bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        bilstm_out, hidden1 = self.bilstm(embeds)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        # bn\n",
    "        bilstm_out = self.bn(bilstm_out)\n",
    "        bilstm_out = torch.transpose(bilstm_out, 1, 2)\n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence_l = [] \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            \n",
    "            if length==0:\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*es,[128, 5]            \n",
    "            ent_output = self.softmax(to_tags)                               #B*es,[128, 5]  \n",
    "            s_ent_output = self.softmax_entity(ent_output)\n",
    "            ent_onehot = self.one_hot(s_ent_output)\n",
    "            \n",
    "            \n",
    "            if isTrain:\n",
    "                label = self.label_embed(ent_onehot)                             #B*LE,[128, 3]\n",
    "#                 label = self.label_embed(ent_output) \n",
    "            else:\n",
    "                batch_ent_onehot = self.one_hot(batch_ent[:,length])\n",
    "                label = self.label_embed(batch_ent_onehot)\n",
    "            \n",
    "     \n",
    "            \n",
    "            # Assignments to Variables are in-place operations.\n",
    "            # Use that variable in lots of other contexts \n",
    "            # and some of the functions require it to not change. \n",
    "            to_tags_clone = to_tags.clone()\n",
    "            label_clone = label.clone()\n",
    "            \n",
    "            \n",
    "#             for i, tag in enumerate(s_ent_output):\n",
    "#                 if tag==ent_tag_to_ix['O']:\n",
    "#                     to_tags_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "#                     label_clone[i] = torch.FloatTensor([-999999 * self.ent_size])\n",
    "                    \n",
    "            # relation layer\n",
    "#             encoder_sequence_l.append(torch.cat((to_tags,label),1)) \n",
    "            encoder_sequence_l.append(torch.cat((h_next,label),1))  \n",
    "            encoder_sequence = torch.stack(encoder_sequence_l).t()     #B*len*(es+LE), [128,1,8]          \n",
    "\n",
    "            # Calculate attention weights \n",
    "            attn_weights = self.attn(encoder_sequence)\n",
    "\n",
    "        \n",
    "            entity_tensor[:,length,:] = ent_output\n",
    "            \n",
    "            # rel_tensor[:,length, 頭~當前 ,:]\n",
    "            rel_tensor[:,length,:length+1,:] = attn_weights\n",
    "\n",
    "        \n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return entity_tensor.view(self.batch*MAX_LEN, self.ent_size), \\\n",
    "               rel_tensor.view(self.batch*MAX_LEN*MAX_LEN, self.rel_size)\n",
    "        \n",
    "        \n",
    "    def softmax_entity(self, entity):\n",
    "        entity = entity.view(self.batch,ent_size).argmax(1)\n",
    "        return entity\n",
    "    \n",
    "    \n",
    "    def one_hot(self, batch_ent):   \n",
    "        batchsize = batch_ent.size(0)\n",
    "        nb_digits = len(ent_tag_to_ix)\n",
    "        batch_ent = torch.unsqueeze(batch_ent, 1)\n",
    "        y_onehot = torch.cuda.FloatTensor(batchsize, nb_digits)        \n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, batch_ent, 1)    \n",
    "\n",
    "        return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "\n",
    "# schema_root = root+'schema_2.txt'\n",
    "# relation_data = root+'facial_r3.train'\n",
    "# dev_data = root+'facial_r3.dev'\n",
    "# test_data = root+'skincare.dev'\n",
    "\n",
    "# schema_root = root+'schema_2.txt'\n",
    "# relation_data = root+'facial_r3_len60.train'\n",
    "# dev_data = root+'facial_r3_len60.dev'\n",
    "# test_data = root+'facial_r3_len60.test'\n",
    "\n",
    "schema_root = root+'schema_2.txt'\n",
    "relation_data = root+'facial_r3_len70.train'\n",
    "dev_data = root+'facial_r3_len70.dev'\n",
    "test_data = root+'facial_r3_len70.test'\n",
    "\n",
    "# schema_root = root+'schema_2.txt'\n",
    "# relation_data = root+'facial_r3_len80.train'\n",
    "# dev_data = root+'facial_r3_len80.dev'\n",
    "# test_data = root+'facial_r3_len80.test'\n",
    "\n",
    "\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "REL_NONE = 'Rel-None'\n",
    "REL_PAD = 'Rel-Pad'\n",
    "\n",
    "schema = schema_load(schema_root)\n",
    "ENT_TAG = define_entity(schema)\n",
    "REL_TAG = define_relation(schema)\n",
    "ent_tag_to_ix = tag2ix(ENT_TAG)\n",
    "'''{'<PAD>': 1,\n",
    " '<UNKNOWN>': 0,\n",
    " 'B-FUNC': 2,\n",
    " 'B-STAT': 3,\n",
    " 'I-FUNC': 4,\n",
    " 'I-STAT': 5,\n",
    " 'O': 6}'''\n",
    "rel_tag_to_ix = tag2ix(REL_TAG)\n",
    "'''{'ApplyTo': 2, 'Rel-None': 1, 'Rel-Pad': 0}'''\n",
    "\n",
    "# ========hyper-parameter-set==========\n",
    "\n",
    "ent_size = len(ent_tag_to_ix)\n",
    "rel_size = len(rel_tag_to_ix)\n",
    "MAX_LEN = 70     # original 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "EMBEDDING_DIM = 40   # original 20\n",
    "HIDDEN_DIM1 = 20     # original 10\n",
    "HIDDEN_DIM2 = 16     # original 8\n",
    "LABEL_EMBED_DIM = ent_size\n",
    "DENSE_OUT = 100\n",
    "\n",
    "# ATTN_IN = ent_size+LABEL_EMBED_DIM\n",
    "ATTN_IN = HIDDEN_DIM2+LABEL_EMBED_DIM\n",
    "ATTN_OUT = 6        # original 6       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    content = readfile(data)\n",
    "    word_list, ent_list, rel_list = split_to_list(content)\n",
    "    word_to_ix = word2index(word_list)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    #================================================\n",
    "    vocab_size = len(word_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, vocab_size, word_to_ix, reserved_index, word_list\n",
    "\n",
    "def dev_preprocess(dev_data):\n",
    "    dev_content = readfile(dev_data)\n",
    "    word_list, ent_list, rel_list = split_to_list(dev_content)\n",
    "    reserved_index = filter_len(word_list)\n",
    "    filter_word, filter_ent, filter_rel = filter_sentence(reserved_index, word_list, ent_list, rel_list)\n",
    "    f_w, f_e, f_r = deep_copy_lists(filter_word, filter_ent, filter_rel)\n",
    "    input_padded, ent_padded, rel_padded = pad_all(f_w, f_e, f_r)\n",
    "    #================================================\n",
    "    input_var = prepare_all(input_padded, word_to_ix)\n",
    "    ent_var = prepare_all(ent_padded, ent_tag_to_ix)\n",
    "    rel_var = prepare_rel(rel_padded, rel_tag_to_ix)\n",
    "    \n",
    "    reserved_index = torch.from_numpy(np.asarray(reserved_index))\n",
    "    \n",
    "    return input_var, ent_var, rel_var, reserved_index, word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_ent_tag = dict_inverse(ent_tag_to_ix)\n",
    "ix_to_rel_tag = dict_inverse(rel_tag_to_ix)\n",
    "#===============================================\n",
    "input_var, ent_var, rel_var, vocab_size, word_to_ix, raw_index, raw_input = preprocess(relation_data)\n",
    "loader = dataload(input_var, ent_var, rel_var, raw_index)\n",
    "\n",
    "input_dev, ent_dev, rel_dev, raw_index_dev, raw_input_dev = dev_preprocess(dev_data)\n",
    "dev_loader = dataload(input_dev, ent_dev, rel_dev, raw_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "criterion_rel = nn.NLLLoss(ignore_index=rel_tag_to_ix[REL_PAD])\n",
    "# criterion_rel = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:04<15:38,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | ent loss 0.6797 | rel loss 0.1380 | total loss 0.8177\n",
      "         | val ent loss 0.6880 | val rel loss 0.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/200 [00:09<15:32,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | ent loss 0.2662 | rel loss 0.0427 | total loss 0.3089\n",
      "         | val ent loss 0.2753 | val rel loss 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/200 [00:14<15:33,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | ent loss 0.3252 | rel loss 0.0236 | total loss 0.3488\n",
      "         | val ent loss 0.2640 | val rel loss 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/200 [00:19<15:39,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | ent loss 0.3039 | rel loss 0.0239 | total loss 0.3278\n",
      "         | val ent loss 0.3773 | val rel loss 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 5/200 [00:24<15:45,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | ent loss 0.2034 | rel loss 0.0198 | total loss 0.2231\n",
      "         | val ent loss 0.1436 | val rel loss 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/200 [00:29<15:42,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | ent loss 0.1432 | rel loss 0.0157 | total loss 0.1589\n",
      "         | val ent loss 0.2671 | val rel loss 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 7/200 [00:34<15:41,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | ent loss 0.1047 | rel loss 0.0151 | total loss 0.1197\n",
      "         | val ent loss 0.2415 | val rel loss 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/200 [00:39<15:42,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | ent loss 0.1002 | rel loss 0.0154 | total loss 0.1156\n",
      "         | val ent loss 0.2204 | val rel loss 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/200 [00:44<15:38,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | ent loss 0.0959 | rel loss 0.0160 | total loss 0.1119\n",
      "         | val ent loss 0.1155 | val rel loss 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 10/200 [00:49<15:35,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | ent loss 0.0487 | rel loss 0.0200 | total loss 0.0687\n",
      "          | val ent loss 0.1750 | val rel loss 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 11/200 [00:53<15:25,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | ent loss 0.0776 | rel loss 0.0175 | total loss 0.0950\n",
      "          | val ent loss 0.0856 | val rel loss 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 12/200 [00:58<15:23,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | ent loss 0.0640 | rel loss 0.0166 | total loss 0.0806\n",
      "          | val ent loss 0.0790 | val rel loss 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 13/200 [01:04<15:21,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | ent loss 0.0441 | rel loss 0.0142 | total loss 0.0583\n",
      "          | val ent loss 0.0422 | val rel loss 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 14/200 [01:09<15:19,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | ent loss 0.0170 | rel loss 0.0139 | total loss 0.0309\n",
      "          | val ent loss 0.0872 | val rel loss 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 15/200 [01:14<15:12,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | ent loss 0.0196 | rel loss 0.0140 | total loss 0.0336\n",
      "          | val ent loss 0.0616 | val rel loss 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 16/200 [01:18<15:05,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | ent loss 0.0414 | rel loss 0.0106 | total loss 0.0520\n",
      "          | val ent loss 0.0569 | val rel loss 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 17/200 [01:23<15:04,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | ent loss 0.0227 | rel loss 0.0109 | total loss 0.0336\n",
      "          | val ent loss 0.0282 | val rel loss 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 18/200 [01:28<14:59,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | ent loss 0.0098 | rel loss 0.0093 | total loss 0.0191\n",
      "          | val ent loss 0.0089 | val rel loss 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 19/200 [01:33<14:50,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | ent loss 0.0148 | rel loss 0.0122 | total loss 0.0271\n",
      "          | val ent loss 0.1127 | val rel loss 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 20/200 [01:37<14:36,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | ent loss 0.0108 | rel loss 0.0082 | total loss 0.0190\n",
      "          | val ent loss 0.0698 | val rel loss 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 21/200 [01:42<14:29,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | ent loss 0.0203 | rel loss 0.0116 | total loss 0.0319\n",
      "          | val ent loss 0.0617 | val rel loss 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 22/200 [01:46<14:23,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | ent loss 0.0270 | rel loss 0.0068 | total loss 0.0338\n",
      "          | val ent loss 0.1835 | val rel loss 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 23/200 [01:51<14:19,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | ent loss 0.0472 | rel loss 0.0052 | total loss 0.0524\n",
      "          | val ent loss 0.1696 | val rel loss 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 24/200 [01:56<14:15,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | ent loss 0.0344 | rel loss 0.0085 | total loss 0.0429\n",
      "          | val ent loss 0.0367 | val rel loss 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 25/200 [02:01<14:11,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | ent loss 0.0092 | rel loss 0.0092 | total loss 0.0184\n",
      "          | val ent loss 0.0057 | val rel loss 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 26/200 [02:06<14:06,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | ent loss 0.0040 | rel loss 0.0066 | total loss 0.0106\n",
      "          | val ent loss 0.0987 | val rel loss 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 27/200 [02:11<14:03,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | ent loss 0.0091 | rel loss 0.0083 | total loss 0.0174\n",
      "          | val ent loss 0.0235 | val rel loss 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 28/200 [02:16<13:56,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | ent loss 0.0042 | rel loss 0.0060 | total loss 0.0103\n",
      "          | val ent loss 0.1700 | val rel loss 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 29/200 [02:21<13:52,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | ent loss 0.0148 | rel loss 0.0047 | total loss 0.0195\n",
      "          | val ent loss 0.0040 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 30/200 [02:26<13:48,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | ent loss 0.0065 | rel loss 0.0072 | total loss 0.0136\n",
      "          | val ent loss 0.0196 | val rel loss 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 31/200 [02:31<13:45,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 | ent loss 0.0102 | rel loss 0.0051 | total loss 0.0152\n",
      "          | val ent loss 0.0566 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 32/200 [02:36<13:41,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 | ent loss 0.0052 | rel loss 0.0045 | total loss 0.0097\n",
      "          | val ent loss 0.1679 | val rel loss 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 33/200 [02:41<13:37,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 | ent loss 0.0193 | rel loss 0.0050 | total loss 0.0243\n",
      "          | val ent loss 0.0589 | val rel loss 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 34/200 [02:46<13:34,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 | ent loss 0.0049 | rel loss 0.0029 | total loss 0.0078\n",
      "          | val ent loss 0.1417 | val rel loss 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 35/200 [02:52<13:31,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 | ent loss 0.0556 | rel loss 0.0047 | total loss 0.0603\n",
      "          | val ent loss 0.0832 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 36/200 [02:57<13:28,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 | ent loss 0.0034 | rel loss 0.0038 | total loss 0.0071\n",
      "          | val ent loss 0.0736 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 37/200 [03:02<13:25,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 | ent loss 0.0468 | rel loss 0.0053 | total loss 0.0521\n",
      "          | val ent loss 0.1695 | val rel loss 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 38/200 [03:07<13:21,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 | ent loss 0.0111 | rel loss 0.0043 | total loss 0.0154\n",
      "          | val ent loss 0.1554 | val rel loss 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 39/200 [03:13<13:17,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 | ent loss 0.0258 | rel loss 0.0051 | total loss 0.0309\n",
      "          | val ent loss 0.1334 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 40/200 [03:18<13:13,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 | ent loss 0.0045 | rel loss 0.0029 | total loss 0.0074\n",
      "          | val ent loss 0.1110 | val rel loss 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 41/200 [03:22<13:06,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 | ent loss 0.0031 | rel loss 0.0036 | total loss 0.0067\n",
      "          | val ent loss 0.2181 | val rel loss 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 42/200 [03:28<13:03,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 | ent loss 0.0128 | rel loss 0.0024 | total loss 0.0152\n",
      "          | val ent loss 0.1996 | val rel loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 43/200 [03:33<12:58,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 | ent loss 0.0025 | rel loss 0.0024 | total loss 0.0049\n",
      "          | val ent loss 0.0676 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 44/200 [03:38<12:53,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 | ent loss 0.0033 | rel loss 0.0028 | total loss 0.0061\n",
      "          | val ent loss 0.0032 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 45/200 [03:42<12:45,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 | ent loss 0.0079 | rel loss 0.0034 | total loss 0.0113\n",
      "          | val ent loss 0.1434 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 46/200 [03:47<12:40,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 | ent loss 0.0046 | rel loss 0.0033 | total loss 0.0079\n",
      "          | val ent loss 0.0040 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 47/200 [03:52<12:35,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 | ent loss 0.0020 | rel loss 0.0022 | total loss 0.0042\n",
      "          | val ent loss 0.1512 | val rel loss 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 48/200 [03:57<12:31,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 | ent loss 0.0040 | rel loss 0.0024 | total loss 0.0064\n",
      "          | val ent loss 0.2449 | val rel loss 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 49/200 [04:02<12:26,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 | ent loss 0.0226 | rel loss 0.0031 | total loss 0.0257\n",
      "          | val ent loss 0.1260 | val rel loss 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 50/200 [04:06<12:20,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 | ent loss 0.0043 | rel loss 0.0025 | total loss 0.0067\n",
      "          | val ent loss 0.1378 | val rel loss 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 51/200 [04:11<12:14,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 | ent loss 0.0333 | rel loss 0.0029 | total loss 0.0363\n",
      "          | val ent loss 0.0644 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 52/200 [04:15<12:07,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 | ent loss 0.0075 | rel loss 0.0024 | total loss 0.0100\n",
      "          | val ent loss 0.0057 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 53/200 [04:20<12:01,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 | ent loss 0.0061 | rel loss 0.0022 | total loss 0.0083\n",
      "          | val ent loss 0.0553 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 54/200 [04:25<11:57,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54 | ent loss 0.0018 | rel loss 0.0019 | total loss 0.0036\n",
      "          | val ent loss 0.1237 | val rel loss 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 55/200 [04:29<11:51,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55 | ent loss 0.0234 | rel loss 0.0023 | total loss 0.0258\n",
      "          | val ent loss 0.1357 | val rel loss 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 56/200 [04:34<11:45,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56 | ent loss 0.0015 | rel loss 0.0022 | total loss 0.0037\n",
      "          | val ent loss 0.0131 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 57/200 [04:39<11:40,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57 | ent loss 0.0017 | rel loss 0.0017 | total loss 0.0034\n",
      "          | val ent loss 0.0811 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 58/200 [04:43<11:34,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58 | ent loss 0.0029 | rel loss 0.0026 | total loss 0.0055\n",
      "          | val ent loss 0.0566 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 59/200 [04:46<11:25,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59 | ent loss 0.0022 | rel loss 0.0023 | total loss 0.0045\n",
      "          | val ent loss 0.0143 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 60/200 [04:49<11:15,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 | ent loss 0.0078 | rel loss 0.0021 | total loss 0.0099\n",
      "          | val ent loss 0.0037 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 61/200 [04:52<11:05,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61 | ent loss 0.0151 | rel loss 0.0024 | total loss 0.0175\n",
      "          | val ent loss 0.0511 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 62/200 [04:54<10:55,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62 | ent loss 0.0037 | rel loss 0.0015 | total loss 0.0051\n",
      "          | val ent loss 0.0389 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 63/200 [04:57<10:46,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63 | ent loss 0.0030 | rel loss 0.0019 | total loss 0.0049\n",
      "          | val ent loss 0.0791 | val rel loss 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 64/200 [04:59<10:37,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64 | ent loss 0.0108 | rel loss 0.0026 | total loss 0.0135\n",
      "          | val ent loss 0.2179 | val rel loss 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 65/200 [05:02<10:27,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65 | ent loss 0.0033 | rel loss 0.0015 | total loss 0.0049\n",
      "          | val ent loss 0.1736 | val rel loss 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 66/200 [05:04<10:19,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66 | ent loss 0.0107 | rel loss 0.0027 | total loss 0.0134\n",
      "          | val ent loss 0.0546 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 67/200 [05:07<10:10,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67 | ent loss 0.0079 | rel loss 0.0022 | total loss 0.0101\n",
      "          | val ent loss 0.0984 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 68/200 [05:10<10:01,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68 | ent loss 0.0032 | rel loss 0.0020 | total loss 0.0052\n",
      "          | val ent loss 0.1005 | val rel loss 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 69/200 [05:12<09:53,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69 | ent loss 0.0265 | rel loss 0.0039 | total loss 0.0303\n",
      "          | val ent loss 0.0346 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 70/200 [05:15<09:45,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70 | ent loss 0.0627 | rel loss 0.0037 | total loss 0.0664\n",
      "          | val ent loss 0.1042 | val rel loss 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 71/200 [05:17<09:37,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71 | ent loss 0.0037 | rel loss 0.0026 | total loss 0.0063\n",
      "          | val ent loss 0.2842 | val rel loss 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 72/200 [05:20<09:29,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72 | ent loss 0.0014 | rel loss 0.0015 | total loss 0.0029\n",
      "          | val ent loss 0.0658 | val rel loss 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 73/200 [05:22<09:21,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73 | ent loss 0.0015 | rel loss 0.0021 | total loss 0.0036\n",
      "          | val ent loss 0.2114 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 74/200 [05:25<09:14,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 74 | ent loss 0.0055 | rel loss 0.0027 | total loss 0.0082\n",
      "          | val ent loss 0.0436 | val rel loss 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 75/200 [05:28<09:06,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75 | ent loss 0.0036 | rel loss 0.0018 | total loss 0.0055\n",
      "          | val ent loss 0.0688 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 76/200 [05:30<08:59,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76 | ent loss 0.0037 | rel loss 0.0028 | total loss 0.0065\n",
      "          | val ent loss 0.2103 | val rel loss 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 77/200 [05:33<08:52,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 77 | ent loss 0.0067 | rel loss 0.0025 | total loss 0.0092\n",
      "          | val ent loss 0.0566 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 78/200 [05:35<08:45,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78 | ent loss 0.0011 | rel loss 0.0014 | total loss 0.0025\n",
      "          | val ent loss 0.0376 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 79/200 [05:38<08:38,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 | ent loss 0.0079 | rel loss 0.0014 | total loss 0.0093\n",
      "          | val ent loss 0.0202 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 80/200 [05:40<08:31,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 80 | ent loss 0.0015 | rel loss 0.0015 | total loss 0.0030\n",
      "          | val ent loss 0.1301 | val rel loss 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 81/200 [05:43<08:24,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81 | ent loss 0.0009 | rel loss 0.0013 | total loss 0.0023\n",
      "          | val ent loss 0.0070 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 82/200 [05:46<08:17,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82 | ent loss 0.0053 | rel loss 0.0025 | total loss 0.0078\n",
      "          | val ent loss 0.0034 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 83/200 [05:48<08:11,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83 | ent loss 0.0019 | rel loss 0.0025 | total loss 0.0044\n",
      "          | val ent loss 0.0595 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 84/200 [05:52<08:06,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84 | ent loss 0.0105 | rel loss 0.0017 | total loss 0.0123\n",
      "          | val ent loss 0.0008 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 85/200 [05:57<08:03,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85 | ent loss 0.0052 | rel loss 0.0021 | total loss 0.0073\n",
      "          | val ent loss 0.1461 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 86/200 [06:01<07:59,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86 | ent loss 0.0016 | rel loss 0.0016 | total loss 0.0031\n",
      "          | val ent loss 0.2434 | val rel loss 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 87/200 [06:06<07:55,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 87 | ent loss 0.0129 | rel loss 0.0016 | total loss 0.0145\n",
      "          | val ent loss 0.1282 | val rel loss 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 88/200 [06:11<07:52,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88 | ent loss 0.0042 | rel loss 0.0017 | total loss 0.0059\n",
      "          | val ent loss 0.0644 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 89/200 [06:16<07:49,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89 | ent loss 0.0089 | rel loss 0.0017 | total loss 0.0106\n",
      "          | val ent loss 0.0683 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 90/200 [06:21<07:45,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90 | ent loss 0.0195 | rel loss 0.0023 | total loss 0.0218\n",
      "          | val ent loss 0.0058 | val rel loss 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 91/200 [06:25<07:42,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91 | ent loss 0.0042 | rel loss 0.0029 | total loss 0.0071\n",
      "          | val ent loss 0.1767 | val rel loss 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 92/200 [06:31<07:39,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 92 | ent loss 0.0103 | rel loss 0.0054 | total loss 0.0158\n",
      "          | val ent loss 0.1701 | val rel loss 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 93/200 [06:36<07:35,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93 | ent loss 0.0217 | rel loss 0.0043 | total loss 0.0260\n",
      "          | val ent loss 0.0464 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 94/200 [06:40<07:31,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 | ent loss 0.0013 | rel loss 0.0017 | total loss 0.0030\n",
      "          | val ent loss 0.0043 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 95/200 [06:45<07:28,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95 | ent loss 0.0021 | rel loss 0.0012 | total loss 0.0034\n",
      "          | val ent loss 0.0705 | val rel loss 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 96/200 [06:50<07:24,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 96 | ent loss 0.0144 | rel loss 0.0011 | total loss 0.0155\n",
      "          | val ent loss 0.1871 | val rel loss 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 97/200 [06:55<07:20,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97 | ent loss 0.0017 | rel loss 0.0012 | total loss 0.0029\n",
      "          | val ent loss 0.0450 | val rel loss 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 98/200 [06:59<07:17,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98 | ent loss 0.0026 | rel loss 0.0012 | total loss 0.0038\n",
      "          | val ent loss 0.0013 | val rel loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 99/200 [07:04<07:12,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 | ent loss 0.0030 | rel loss 0.0019 | total loss 0.0049\n",
      "          | val ent loss 0.1419 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 100/200 [07:08<07:08,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 | ent loss 0.0015 | rel loss 0.0011 | total loss 0.0026\n",
      "           | val ent loss 0.0663 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 101/200 [07:13<07:05,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 101 | ent loss 0.0157 | rel loss 0.0023 | total loss 0.0180\n",
      "           | val ent loss 0.1123 | val rel loss 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 102/200 [07:18<07:01,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 102 | ent loss 0.0024 | rel loss 0.0025 | total loss 0.0049\n",
      "           | val ent loss 0.0957 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 103/200 [07:23<06:57,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103 | ent loss 0.0024 | rel loss 0.0015 | total loss 0.0040\n",
      "           | val ent loss 0.0053 | val rel loss 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 104/200 [07:28<06:53,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 104 | ent loss 0.0226 | rel loss 0.0012 | total loss 0.0238\n",
      "           | val ent loss 0.1418 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 105/200 [07:32<06:49,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 105 | ent loss 0.0022 | rel loss 0.0013 | total loss 0.0035\n",
      "           | val ent loss 0.0408 | val rel loss 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 106/200 [07:37<06:45,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106 | ent loss 0.0015 | rel loss 0.0012 | total loss 0.0027\n",
      "           | val ent loss 0.0021 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 107/200 [07:42<06:42,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107 | ent loss 0.0062 | rel loss 0.0011 | total loss 0.0073\n",
      "           | val ent loss 0.1353 | val rel loss 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 108/200 [07:47<06:38,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108 | ent loss 0.0012 | rel loss 0.0009 | total loss 0.0020\n",
      "           | val ent loss 0.0700 | val rel loss 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 109/200 [07:52<06:34,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109 | ent loss 0.0020 | rel loss 0.0013 | total loss 0.0033\n",
      "           | val ent loss 0.0021 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 110/200 [07:57<06:30,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 110 | ent loss 0.0120 | rel loss 0.0017 | total loss 0.0137\n",
      "           | val ent loss 0.3903 | val rel loss 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 111/200 [08:02<06:26,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 111 | ent loss 0.0203 | rel loss 0.0019 | total loss 0.0222\n",
      "           | val ent loss 0.0193 | val rel loss 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 112/200 [08:06<06:22,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 | ent loss 0.0016 | rel loss 0.0019 | total loss 0.0034\n",
      "           | val ent loss 0.0115 | val rel loss 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 113/200 [08:11<06:18,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113 | ent loss 0.0044 | rel loss 0.0018 | total loss 0.0062\n",
      "           | val ent loss 0.0568 | val rel loss 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 114/200 [08:16<06:14,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 114 | ent loss 0.0029 | rel loss 0.0019 | total loss 0.0047\n",
      "           | val ent loss 0.1751 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 115/200 [08:20<06:10,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115 | ent loss 0.0010 | rel loss 0.0011 | total loss 0.0022\n",
      "           | val ent loss 0.0039 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 116/200 [08:25<06:06,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116 | ent loss 0.0014 | rel loss 0.0012 | total loss 0.0026\n",
      "           | val ent loss 0.2181 | val rel loss 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 117/200 [08:30<06:02,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 117 | ent loss 0.0011 | rel loss 0.0017 | total loss 0.0028\n",
      "           | val ent loss 0.0943 | val rel loss 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 118/200 [08:35<05:58,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118 | ent loss 0.0068 | rel loss 0.0022 | total loss 0.0091\n",
      "           | val ent loss 0.1561 | val rel loss 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 119/200 [08:40<05:54,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119 | ent loss 0.0020 | rel loss 0.0016 | total loss 0.0036\n",
      "           | val ent loss 0.0402 | val rel loss 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 120/200 [08:45<05:50,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120 | ent loss 0.0083 | rel loss 0.0022 | total loss 0.0105\n",
      "           | val ent loss 0.2539 | val rel loss 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 121/200 [08:50<05:46,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121 | ent loss 0.0345 | rel loss 0.0041 | total loss 0.0387\n",
      "           | val ent loss 0.0682 | val rel loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 122/200 [08:55<05:42,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 122 | ent loss 0.0055 | rel loss 0.0015 | total loss 0.0070\n",
      "           | val ent loss 0.2151 | val rel loss 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 123/200 [09:00<05:38,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 123 | ent loss 0.0011 | rel loss 0.0013 | total loss 0.0024\n",
      "           | val ent loss 0.0676 | val rel loss 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 124/200 [09:04<05:33,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124 | ent loss 0.0017 | rel loss 0.0013 | total loss 0.0030\n",
      "           | val ent loss 0.1796 | val rel loss 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 125/200 [09:08<05:29,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 125 | ent loss 0.0014 | rel loss 0.0012 | total loss 0.0025\n",
      "           | val ent loss 0.0041 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 126/200 [09:13<05:25,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 126 | ent loss 0.0008 | rel loss 0.0009 | total loss 0.0016\n",
      "           | val ent loss 0.0016 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 127/200 [09:18<05:20,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127 | ent loss 0.0199 | rel loss 0.0020 | total loss 0.0218\n",
      "           | val ent loss 0.1488 | val rel loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 128/200 [09:23<05:16,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 128 | ent loss 0.0094 | rel loss 0.0014 | total loss 0.0109\n",
      "           | val ent loss 0.0070 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 129/200 [09:28<05:12,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 129 | ent loss 0.0072 | rel loss 0.0025 | total loss 0.0097\n",
      "           | val ent loss 0.0622 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 130/200 [09:32<05:08,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130 | ent loss 0.0069 | rel loss 0.0012 | total loss 0.0081\n",
      "           | val ent loss 0.2331 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 131/200 [09:37<05:04,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 131 | ent loss 0.0018 | rel loss 0.0012 | total loss 0.0030\n",
      "           | val ent loss 0.0669 | val rel loss 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 132/200 [09:42<05:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132 | ent loss 0.0007 | rel loss 0.0020 | total loss 0.0028\n",
      "           | val ent loss 0.1111 | val rel loss 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 133/200 [09:47<04:55,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133 | ent loss 0.0134 | rel loss 0.0011 | total loss 0.0145\n",
      "           | val ent loss 0.0644 | val rel loss 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 134/200 [09:52<04:51,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 134 | ent loss 0.0009 | rel loss 0.0029 | total loss 0.0038\n",
      "           | val ent loss 0.0851 | val rel loss 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 135/200 [09:57<04:47,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135 | ent loss 0.0034 | rel loss 0.0015 | total loss 0.0049\n",
      "           | val ent loss 0.2026 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 136/200 [10:02<04:43,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136 | ent loss 0.0034 | rel loss 0.0020 | total loss 0.0054\n",
      "           | val ent loss 0.1952 | val rel loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 137/200 [10:07<04:39,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137 | ent loss 0.0011 | rel loss 0.0015 | total loss 0.0026\n",
      "           | val ent loss 0.0640 | val rel loss 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 138/200 [10:12<04:34,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138 | ent loss 0.0013 | rel loss 0.0016 | total loss 0.0029\n",
      "           | val ent loss 0.0381 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 139/200 [10:16<04:30,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 139 | ent loss 0.0031 | rel loss 0.0024 | total loss 0.0055\n",
      "           | val ent loss 0.1795 | val rel loss 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 140/200 [10:21<04:26,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140 | ent loss 0.0060 | rel loss 0.0022 | total loss 0.0083\n",
      "           | val ent loss 0.1844 | val rel loss 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 141/200 [10:26<04:22,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 141 | ent loss 0.0032 | rel loss 0.0016 | total loss 0.0048\n",
      "           | val ent loss 0.1397 | val rel loss 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 142/200 [10:31<04:17,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 142 | ent loss 0.0056 | rel loss 0.0017 | total loss 0.0072\n",
      "           | val ent loss 0.0521 | val rel loss 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 143/200 [10:36<04:13,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143 | ent loss 0.0084 | rel loss 0.0019 | total loss 0.0103\n",
      "           | val ent loss 0.0503 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 144/200 [10:41<04:09,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 144 | ent loss 0.0013 | rel loss 0.0022 | total loss 0.0035\n",
      "           | val ent loss 0.0116 | val rel loss 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 145/200 [10:46<04:05,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 145 | ent loss 0.0017 | rel loss 0.0027 | total loss 0.0044\n",
      "           | val ent loss 0.0154 | val rel loss 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 146/200 [10:52<04:01,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 146 | ent loss 0.0235 | rel loss 0.0024 | total loss 0.0259\n",
      "           | val ent loss 0.0013 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 147/200 [10:57<03:57,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 147 | ent loss 0.0422 | rel loss 0.0010 | total loss 0.0431\n",
      "           | val ent loss 0.1599 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 148/200 [11:02<03:52,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 148 | ent loss 0.0062 | rel loss 0.0016 | total loss 0.0079\n",
      "           | val ent loss 0.0628 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 149/200 [11:07<03:48,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 149 | ent loss 0.0146 | rel loss 0.0012 | total loss 0.0158\n",
      "           | val ent loss 0.1122 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 150/200 [11:12<03:44,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150 | ent loss 0.0013 | rel loss 0.0010 | total loss 0.0023\n",
      "           | val ent loss 0.0288 | val rel loss 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 151/200 [11:17<03:39,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 151 | ent loss 0.0012 | rel loss 0.0023 | total loss 0.0035\n",
      "           | val ent loss 0.0707 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 152/200 [11:22<03:35,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 152 | ent loss 0.0010 | rel loss 0.0015 | total loss 0.0026\n",
      "           | val ent loss 0.1860 | val rel loss 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 153/200 [11:27<03:31,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 153 | ent loss 0.0010 | rel loss 0.0028 | total loss 0.0038\n",
      "           | val ent loss 0.0059 | val rel loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 154/200 [11:33<03:27,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 154 | ent loss 0.0008 | rel loss 0.0005 | total loss 0.0013\n",
      "           | val ent loss 0.0543 | val rel loss 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 155/200 [11:38<03:22,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 155 | ent loss 0.0029 | rel loss 0.0015 | total loss 0.0044\n",
      "           | val ent loss 0.1391 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 156/200 [11:43<03:18,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 156 | ent loss 0.0021 | rel loss 0.0026 | total loss 0.0047\n",
      "           | val ent loss 0.0862 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 157/200 [11:48<03:14,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 157 | ent loss 0.0008 | rel loss 0.0014 | total loss 0.0022\n",
      "           | val ent loss 0.1031 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 158/200 [11:53<03:09,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 158 | ent loss 0.0011 | rel loss 0.0014 | total loss 0.0025\n",
      "           | val ent loss 0.0686 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 159/200 [11:58<03:05,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 159 | ent loss 0.0302 | rel loss 0.0020 | total loss 0.0322\n",
      "           | val ent loss 0.3147 | val rel loss 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 160/200 [12:03<03:00,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160 | ent loss 0.0019 | rel loss 0.0016 | total loss 0.0035\n",
      "           | val ent loss 0.1608 | val rel loss 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 161/200 [12:09<02:56,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 161 | ent loss 0.0024 | rel loss 0.0008 | total loss 0.0032\n",
      "           | val ent loss 0.0028 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 162/200 [12:14<02:52,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 162 | ent loss 0.0115 | rel loss 0.0020 | total loss 0.0135\n",
      "           | val ent loss 0.2642 | val rel loss 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 163/200 [12:19<02:47,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 163 | ent loss 0.0019 | rel loss 0.0013 | total loss 0.0032\n",
      "           | val ent loss 0.0641 | val rel loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 164/200 [12:24<02:43,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164 | ent loss 0.0028 | rel loss 0.0013 | total loss 0.0042\n",
      "           | val ent loss 0.1825 | val rel loss 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 165/200 [12:29<02:38,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 165 | ent loss 0.0031 | rel loss 0.0007 | total loss 0.0038\n",
      "           | val ent loss 0.0772 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 166/200 [12:34<02:34,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 166 | ent loss 0.0020 | rel loss 0.0030 | total loss 0.0050\n",
      "           | val ent loss 0.0152 | val rel loss 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 167/200 [12:40<02:30,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 167 | ent loss 0.0012 | rel loss 0.0018 | total loss 0.0030\n",
      "           | val ent loss 0.1487 | val rel loss 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 168/200 [12:45<02:25,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 168 | ent loss 0.0009 | rel loss 0.0019 | total loss 0.0028\n",
      "           | val ent loss 0.1983 | val rel loss 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 169/200 [12:50<02:21,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 169 | ent loss 0.0176 | rel loss 0.0024 | total loss 0.0200\n",
      "           | val ent loss 0.0376 | val rel loss 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 170/200 [12:55<02:16,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170 | ent loss 0.0030 | rel loss 0.0023 | total loss 0.0053\n",
      "           | val ent loss 0.1112 | val rel loss 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 171/200 [13:00<02:12,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 171 | ent loss 0.0011 | rel loss 0.0013 | total loss 0.0023\n",
      "           | val ent loss 0.0022 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 172/200 [13:05<02:07,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 172 | ent loss 0.0020 | rel loss 0.0010 | total loss 0.0030\n",
      "           | val ent loss 0.0697 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 173/200 [13:11<02:03,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 173 | ent loss 0.0013 | rel loss 0.0014 | total loss 0.0027\n",
      "           | val ent loss 0.0477 | val rel loss 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 174/200 [13:16<01:58,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 174 | ent loss 0.0342 | rel loss 0.0017 | total loss 0.0359\n",
      "           | val ent loss 0.0107 | val rel loss 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 175/200 [13:21<01:54,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175 | ent loss 0.0048 | rel loss 0.0020 | total loss 0.0067\n",
      "           | val ent loss 0.1361 | val rel loss 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 176/200 [13:26<01:49,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 176 | ent loss 0.0022 | rel loss 0.0024 | total loss 0.0046\n",
      "           | val ent loss 0.1188 | val rel loss 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 177/200 [13:31<01:45,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 177 | ent loss 0.0012 | rel loss 0.0023 | total loss 0.0035\n",
      "           | val ent loss 0.1064 | val rel loss 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 178/200 [13:36<01:40,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 178 | ent loss 0.0010 | rel loss 0.0011 | total loss 0.0022\n",
      "           | val ent loss 0.0286 | val rel loss 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 179/200 [13:41<01:36,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 179 | ent loss 0.0013 | rel loss 0.0013 | total loss 0.0026\n",
      "           | val ent loss 0.0259 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 180/200 [13:45<01:31,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180 | ent loss 0.0024 | rel loss 0.0020 | total loss 0.0044\n",
      "           | val ent loss 0.0820 | val rel loss 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 181/200 [13:50<01:27,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181 | ent loss 0.0023 | rel loss 0.0021 | total loss 0.0044\n",
      "           | val ent loss 0.1062 | val rel loss 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 182/200 [13:55<01:22,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 182 | ent loss 0.0149 | rel loss 0.0023 | total loss 0.0173\n",
      "           | val ent loss 0.0545 | val rel loss 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 183/200 [14:00<01:18,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 183 | ent loss 0.0366 | rel loss 0.0022 | total loss 0.0388\n",
      "           | val ent loss 0.1710 | val rel loss 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 184/200 [14:05<01:13,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 184 | ent loss 0.0102 | rel loss 0.0012 | total loss 0.0114\n",
      "           | val ent loss 0.0892 | val rel loss 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 185/200 [14:10<01:08,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 | ent loss 0.0056 | rel loss 0.0021 | total loss 0.0077\n",
      "           | val ent loss 0.0911 | val rel loss 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 186/200 [14:15<01:04,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 186 | ent loss 0.0056 | rel loss 0.0010 | total loss 0.0066\n",
      "           | val ent loss 0.0913 | val rel loss 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 187/200 [14:20<00:59,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 187 | ent loss 0.0206 | rel loss 0.0022 | total loss 0.0229\n",
      "           | val ent loss 0.0716 | val rel loss 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 188/200 [14:25<00:55,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 188 | ent loss 0.0015 | rel loss 0.0017 | total loss 0.0032\n",
      "           | val ent loss 0.0039 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 189/200 [14:30<00:50,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 189 | ent loss 0.0017 | rel loss 0.0013 | total loss 0.0030\n",
      "           | val ent loss 0.1545 | val rel loss 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 190/200 [14:35<00:46,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 190 | ent loss 0.0010 | rel loss 0.0024 | total loss 0.0034\n",
      "           | val ent loss 0.1565 | val rel loss 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 191/200 [14:40<00:41,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191 | ent loss 0.0008 | rel loss 0.0007 | total loss 0.0015\n",
      "           | val ent loss 0.0143 | val rel loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 192/200 [14:45<00:36,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 192 | ent loss 0.0009 | rel loss 0.0019 | total loss 0.0029\n",
      "           | val ent loss 0.0110 | val rel loss 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 193/200 [14:49<00:32,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 193 | ent loss 0.0014 | rel loss 0.0015 | total loss 0.0029\n",
      "           | val ent loss 0.0263 | val rel loss 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 194/200 [14:55<00:27,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 194 | ent loss 0.0008 | rel loss 0.0015 | total loss 0.0023\n",
      "           | val ent loss 0.0325 | val rel loss 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 195/200 [15:00<00:23,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195 | ent loss 0.0008 | rel loss 0.0020 | total loss 0.0028\n",
      "           | val ent loss 0.1303 | val rel loss 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 196/200 [15:05<00:18,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 196 | ent loss 0.0017 | rel loss 0.0013 | total loss 0.0029\n",
      "           | val ent loss 0.1512 | val rel loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 197/200 [15:10<00:13,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 197 | ent loss 0.0010 | rel loss 0.0012 | total loss 0.0023\n",
      "           | val ent loss 0.2532 | val rel loss 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 198/200 [15:15<00:09,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 198 | ent loss 0.0009 | rel loss 0.0008 | total loss 0.0016\n",
      "           | val ent loss 0.0662 | val rel loss 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 199/200 [15:20<00:04,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199 | ent loss 0.0008 | rel loss 0.0010 | total loss 0.0018\n",
      "           | val ent loss 0.0970 | val rel loss 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 200/200 [15:25<00:00,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200 | ent loss 0.0015 | rel loss 0.0010 | total loss 0.0025\n",
      "           | val ent loss 0.1484 | val rel loss 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 200\n",
    "print_every = 12\n",
    "\n",
    "train_entloss_l = []\n",
    "val_entloss_l = []\n",
    "train_relloss_l = []\n",
    "val_relloss_l = []\n",
    "\n",
    "loss = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(n_iters)):  \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "        batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "        \n",
    "        entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "        relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "        loss = entloss+relloss\n",
    "        \n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    train_entloss_l.append(entloss.cpu())\n",
    "    train_relloss_l.append(relloss.cpu())\n",
    "    #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "        \n",
    "    for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "        model.eval()\n",
    "        ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                       if USE_CUDA else batch_ent, isTrain=True)\n",
    "        \n",
    "        batchsize = batch_x.size(0)\n",
    "        \n",
    "        val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "        val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "        \n",
    "    val_entloss_l.append(val_entloss.cpu())\n",
    "    val_relloss_l.append(val_relloss.cpu())\n",
    "    \n",
    "    \n",
    "    print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "          % (epoch+1, entloss, relloss, loss))\n",
    "    print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "          % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "torch.save(model.state_dict(), 'relation_extraction_1_new.pkl')\n",
    "\n",
    "# model = Entity_Typing(vocab_size, ent_tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "#               LABEL_EMBED_DIM, rel_tag_to_ix).cuda()\n",
    "# model.load_state_dict(torch.load('relation_extraction.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(train_entloss_l, label='train_ent_loss')\n",
    "plt.plot(val_entloss_l, label='val_ent_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entity Loss\") \n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(train_relloss_l, label='train_rel_loss')\n",
    "plt.plot(val_relloss_l, label='val_rel_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Relation Loss\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_choose(input_var):\n",
    "    r_choose = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        r_choose.append(random.randint(0,len(input_var)))\n",
    "    return r_choose\n",
    "        \n",
    "def ent_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,ent_size).argmax(2)\n",
    "    return output\n",
    "\n",
    "def rel_argmax(output, batchsize):\n",
    "    output = output.view(batchsize,MAX_LEN,MAX_LEN,rel_size).argmax(3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check predictions after training\n",
    "# with torch.no_grad():\n",
    "#     r_choose = random_choose(input_var)\n",
    "#     model.eval()\n",
    "#     ent_output, rel_output = model(input_var[r_choose].cuda() if USE_CUDA else input_var, batch_ent.cuda() \\\n",
    "#                                        if USE_CUDA else batch_ent, isTrain=True)\n",
    "    \n",
    "#     batchsize = input_var[r_choose].size(0)\n",
    "    \n",
    "#     ent_loss = criterion_tag(ent_output.cpu(), ent_var[r_choose].view(BATCH_SIZE*MAX_LEN))\n",
    "#     ent_output = ent_argmax(ent_output, batchsize)\n",
    "    \n",
    "#     rel_loss = criterion_rel(rel_output.cpu(), rel_var[r_choose].view(BATCH_SIZE*MAX_LEN*MAX_LEN))\n",
    "    \n",
    "#     print()\n",
    "#     print('predict :', index2tag(ent_output[0], ix_to_ent_tag))\n",
    "#     print('true :', index2tag(ent_var[r_choose[0]], ix_to_ent_tag))\n",
    "    \n",
    "#     print()\n",
    "#     print(\"Entity loss : %.4f\" % ent_loss)\n",
    "#     print(\"Relation loss : %.4f\" % rel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "def evaluate_data(data_loader, raw_input, isTrain=False, silent=False):\n",
    "    tps, fps, tns, fns = 0, 0, 0, 0\n",
    "    y_ent_true_all, y_ent_pred_all = [], []\n",
    "    y_rel_true_all, y_rel_pred_all = [], []\n",
    "    print_every_batch = 5\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(data_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            ent_loss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN))\n",
    "            ent_output = ent_argmax(ent_output, batchsize)\n",
    "\n",
    "            rel_loss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "            rel_output = rel_argmax(rel_output, batchsize)\n",
    "\n",
    "            \n",
    "            if not silent:\n",
    "                print()    \n",
    "                print(\"Entity loss : %.4f\" % ent_loss)\n",
    "                print(\"Relation loss : %.4f\" % rel_loss)\n",
    "                print()\n",
    "                print('===========================================')\n",
    "                \n",
    "#             elif step%print_every_batch==0:\n",
    "#                 print()    \n",
    "#                 print(\"Entity loss : %.4f\" % ent_loss)\n",
    "#                 print(\"Relation loss : %.4f\" % rel_loss)\n",
    "#                 print()\n",
    "#                 print('===========================================')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel = \\\n",
    "            batch_decode(ent_output, rel_output, batch_index, raw_input, batch_ent, batch_rel, silent)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            y_ent_true_all.extend(y_true_ent)\n",
    "            y_ent_pred_all.extend(y_pred_ent)\n",
    "\n",
    "            y_rel_true_all.extend(y_true_rel)\n",
    "            y_rel_pred_all.extend(y_pred_rel)\n",
    "            \n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            tns += tn\n",
    "            fns += fn\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"Entity detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_ent_true_all, y_ent_pred_all, average='micro', \n",
    "                                                  labels=range(len(schema['entity'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"Relation detection score\")\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        p_r_f1 = precision_recall_fscore_support(y_rel_true_all, y_rel_pred_all, average='micro', \n",
    "                                              labels=range(len(schema['relation'])))\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t' % (p_r_f1[0], p_r_f1[1], p_r_f1[2]))\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"ReferenceEntity+Relation score\")\n",
    "        print(\"%s \\t %s \\t %s \\t    %s %s %s %s\" % ('precision ', 'recall ', 'fbeta_score ', 'tp', 'fp', 'tn', 'fn'))\n",
    "        p_r_f1 = p_r_fscore(tps, fps, tns, fns)\n",
    "        print('%.3f \\t\\t %.3f \\t\\t %.3f \\t\\t    %d %d %d %d' % (p_r_f1[0], p_r_f1[1], p_r_f1[2], tps, fps, tns, fns))\n",
    "\n",
    "            \n",
    "            \n",
    "def batch_decode(ent_output, rel_output, batch_index, word_lists, true_ent, true_rel, silent):\n",
    "    \n",
    "    eval_ent_list_true_l, eval_rel_list_true_l = [], []\n",
    "    eval_ent_list_pred_l, eval_rel_list_pred_l = [], []\n",
    "    \n",
    "    for e,r,i,te,tr in zip(ent_output, rel_output, batch_index, true_ent, true_rel):\n",
    "        \n",
    "        # 算句子長度\n",
    "        len_of_list = len(word_lists[i])\n",
    "        word_list = word_lists[i]\n",
    "        true_ent = index2tag(te, ix_to_ent_tag)[:len_of_list]\n",
    "        pridict_ent = index2tag(e, ix_to_ent_tag)[:len_of_list]     \n",
    "        \n",
    "        # 單句decode關係\n",
    "        true_r_list, appear_error = decode_rel(te, tr)   # true\n",
    "        pre_r_list, appear_error = decode_rel(e, r)      # predict\n",
    "        \n",
    "        true_r_list = [list(set(i)) if type(i) is list else i for i in true_r_list]\n",
    "        pre_r_list = [list(set(i)) if type(i) is list else i for i in pre_r_list]\n",
    "        \n",
    "        # 出現error，跳過這句\n",
    "        if appear_error:\n",
    "            continue\n",
    "        \n",
    "        true_r_list = true_r_list[:len_of_list]\n",
    "        pre_r_list = pre_r_list[:len_of_list]\n",
    "        \n",
    "        \n",
    "        # 評分用\n",
    "        eval_ent_list_true, err_count = decode_ent(true_ent, schema)\n",
    "        eval_rel_list_true = decode_rel_to_eval(true_r_list, schema, eval_ent_list_true)\n",
    "        \n",
    "        eval_ent_list_pred, err_count = decode_ent(pridict_ent, schema)\n",
    "        eval_rel_list_pred = decode_rel_to_eval(pre_r_list, schema, eval_ent_list_pred)\n",
    "        \n",
    "        if not silent:\n",
    "            print(word_list)\n",
    "            print(true_ent)\n",
    "            print(true_r_list)\n",
    "            print()\n",
    "            print('Predict output')\n",
    "            print(pridict_ent)\n",
    "            print(pre_r_list)\n",
    "            print()\n",
    "            print('True')\n",
    "            print(eval_ent_list_true)\n",
    "            print(eval_rel_list_true)\n",
    "            print('predict')\n",
    "            print(eval_ent_list_pred)\n",
    "            print(eval_rel_list_pred)\n",
    "            print(\"=====================================\")\n",
    "        \n",
    "        eval_ent_list_true_l.append(eval_ent_list_true)\n",
    "        eval_rel_list_true_l.append(eval_rel_list_true)\n",
    "        eval_ent_list_pred_l.append(eval_ent_list_pred)\n",
    "        eval_rel_list_pred_l.append(eval_rel_list_pred)\n",
    "    \n",
    "    \n",
    "    e_score, y_true_ent, y_pred_ent = get_scores(eval_ent_list_true_l, eval_ent_list_pred_l, \\\n",
    "                                                 range(len(schema['entity'])),output_y=True)\n",
    "    r_score, y_true_rel, y_pred_rel = get_scores(eval_rel_list_true_l, eval_rel_list_pred_l, \\\n",
    "                                                 range(len(schema['relation'])),output_y=True)\n",
    "    \n",
    "    tp, fp, tn, fn = relation_error_analysis(eval_rel_list_true_l, eval_rel_list_pred_l)\n",
    "    \n",
    "    if not silent:\n",
    "        print('Batch entity score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(e_score)\n",
    "        print()\n",
    "        print('Batch relation score')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(r_score)\n",
    "        print()\n",
    "        print('p_r_fscore')\n",
    "        print(\"%s \\t %s \\t %s \\t\" % ('precision ', 'recall ', 'fbeta_score '))\n",
    "        print(p_r_fscore(tp, fp, tn, fn), tp, fp, tn, fn)\n",
    "        print('===========================================')\n",
    "    \n",
    "    return tp, fp, tn, fn, y_true_ent, y_pred_ent, y_true_rel, y_pred_rel\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def decode_ent(pred_ent, schema):\n",
    "    '''\n",
    "    Aggregate entities from predicted tags\n",
    "    Input:\n",
    "    pred_ent=a list of entity tags in a sentence\n",
    "    schema=the dictionary defining entities and relations\n",
    "    Output: \n",
    "    ent_list=[(ent_start, ent_end, ent_type=eid_in_schema)]\n",
    "    err_count=the number of bad tags\n",
    "    '''\n",
    "    ent_list = []\n",
    "    ent_start = 0\n",
    "    ent_end = 0\n",
    "    state = {\n",
    "        'ENT_SPAN': 0,\n",
    "        'NO_ENT': 1\n",
    "    }\n",
    "    err_count = 0\n",
    "    ent_type = ''\n",
    "    sid = state['NO_ENT']\n",
    "    for idx, e_tag in enumerate(pred_ent):\n",
    "        bio = e_tag[0]\n",
    "        type_tag = e_tag.split('-')[-1]\n",
    "        if sid == state['NO_ENT']:\n",
    "            if bio == 'B':\n",
    "                ent_start = idx\n",
    "                ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                sid = state['ENT_SPAN']\n",
    "            elif bio == 'I':\n",
    "                err_count += 1\n",
    "        elif sid == state['ENT_SPAN']:\n",
    "            if bio != 'I':\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                if bio == 'B':\n",
    "                    ent_start = idx\n",
    "                    ent_type = get_eid_from_tag(type_tag, schema)\n",
    "                else:\n",
    "                    sid = state['NO_ENT']\n",
    "            elif ent_type != get_eid_from_tag(type_tag, schema):\n",
    "                ent_end = idx - 1\n",
    "                ent_list.append((ent_start, ent_end, ent_type))\n",
    "                err_count += 1\n",
    "                sid = state['NO_ENT']\n",
    "    if sid == state['ENT_SPAN']:\n",
    "        ent_end = len(pred_ent) - 1\n",
    "        ent_list.append((ent_start, ent_end, ent_type))\n",
    "    return ent_list, err_count\n",
    "\n",
    "def get_eid_from_tag(tag, schema):\n",
    "    '''\n",
    "    Assume schema is a dictionary in schema.txt\n",
    "    return eid or -1 if no match is found\n",
    "    '''\n",
    "    for content in schema['entity'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['eid']\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def decode_rel_to_eval(r_list, schema, ent_list):\n",
    "    \n",
    "    max_pair = 0\n",
    "    for r in r_list:\n",
    "        if type(r) is list:\n",
    "            for single_r in r:\n",
    "                if int(single_r[-3])>max_pair:\n",
    "                    max_pair = int(single_r[-3])\n",
    "    \n",
    "\n",
    "    pair_idx = {}\n",
    "    for pair in range(max_pair+1):\n",
    "        for i, r in enumerate(r_list):\n",
    "            if type(r) is list:\n",
    "                for single_r in r:\n",
    "                    if int(single_r[-3])==pair:\n",
    "                        if pair not in pair_idx:\n",
    "                            pair_idx[pair] = [i]\n",
    "                        else:\n",
    "                            pair_idx[pair].append(i)\n",
    "    \n",
    "    \n",
    "#     # 算兩兩不同tag的數目\n",
    "#     e_type_dict = {}\n",
    "#     for e_pair in ent_list:\n",
    "#         if e_pair[-1] not in e_type_dict:\n",
    "#             e_type_dict[e_pair[-1]] = 1\n",
    "#         else:\n",
    "#             e_type_dict[e_pair[-1]] += 1\n",
    "    \n",
    "#     total_pair = 0\n",
    "#     e_type_l = list(e_type_dict.values())\n",
    "#     for i, ent_type_num_1 in enumerate(e_type_l):\n",
    "#         for j, ent_type_num_2 in enumerate(e_type_l[i+1:]):\n",
    "#             pair_num = ent_type_num_1*ent_type_num_2\n",
    "#             total_pair += pair_num\n",
    "\n",
    "    pair_list = []\n",
    "    for i, e_pair_1 in enumerate(ent_list):\n",
    "        for j, e_pair_2 in enumerate(ent_list[i+1:]):\n",
    "            if e_pair_1[-1]!=e_pair_2[-1]:\n",
    "                pair_list.append([e_pair_1, e_pair_2])\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    eval_rel_list = []\n",
    "    for pair in pair_idx:\n",
    "        rel_loc = pair_idx[pair]\n",
    "        for e_pairs in pair_list:\n",
    "            check_pair = True\n",
    "            first_start = e_pairs[0][0]\n",
    "            first_end = e_pairs[0][1]\n",
    "            sec_start = e_pairs[1][0]\n",
    "            sec_end = e_pairs[1][1]\n",
    "            \n",
    "            first_l = list(range(first_start, first_end+1))\n",
    "            sec_l = list(range(sec_start, sec_end+1))\n",
    "            combine_l = first_l+sec_l\n",
    "\n",
    "            \n",
    "            check_in_entity = []\n",
    "            for x in combine_l:\n",
    "                if x in rel_loc:\n",
    "                    check_in_entity.append(True)\n",
    "                else:\n",
    "                    check_in_entity.append(False)\n",
    "                    check_pair = False\n",
    "                    break             \n",
    "\n",
    "            if all(check_in_entity)==True:\n",
    "                for r in r_list[first_start]:\n",
    "                    r_info = r.split('-')\n",
    "                    \n",
    "                    if int(r_info[1])==pair:\n",
    "                        r_tag = get_rid_from_tag(r_info[0], schema)\n",
    "                        e_pairs_copy = e_pairs\n",
    "                        e_pairs_copy.append(r_tag)\n",
    "                        eval_rel_list.append(tuple(e_pairs_copy))\n",
    "    \n",
    "    return eval_rel_list\n",
    "    \n",
    "        \n",
    "def get_rid_from_tag(tag, schema):   \n",
    "    for content in schema['relation'].values():\n",
    "        if content['tag'] == tag:\n",
    "            return content['rid']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_rel_info(ent_output):\n",
    "    r_list = []     # 存放完整關係\n",
    "    r_dict = {}     # 記錄關係資訊\n",
    "    appear_error = False\n",
    "\n",
    "    pred_ent = index2tag(ent_output, ix_to_ent_tag)\n",
    "    \n",
    "\n",
    "    e_loc = 0       # 當前遇到的entity的位置\n",
    "    for loc, e in enumerate(pred_ent):\n",
    "        if e[0]=='B':\n",
    "            e_loc = loc\n",
    "            r_dict[loc] = {\n",
    "                '_2ndtag':e[2:],\n",
    "                'end':loc,\n",
    "            }\n",
    "            r_list.append([])\n",
    "                   \n",
    "        elif e[0]=='I':\n",
    "            # 錯誤來自於，entity預測錯誤，沒有預測到B tag，直接跳到I tag\n",
    "            # 所以沒有紀錄e_loc\n",
    "            try: \n",
    "                r_dict[e_loc]['end'] = loc\n",
    "            except KeyError:\n",
    "                appear_error = True\n",
    "                break\n",
    "            \n",
    "            r_list.append([])\n",
    "            \n",
    "        else:\n",
    "            r_list.append(\"\")\n",
    "              \n",
    "    return r_list, r_dict, appear_error\n",
    "        \n",
    "        \n",
    "def decode_rel(ent_output, rel_output):\n",
    "\n",
    "    r_list, r_dict, appear_error = create_rel_info(ent_output) \n",
    "    \n",
    "    IsB = False           # 是否遇到B tag的lock\n",
    "    IsNext = False        # 是否為B tag後面的tag 的lock\n",
    "    num_reocrd = -1       # 紀錄pair數\n",
    "    now_loc = 0\n",
    "    pre_rel_end_loc = 0\n",
    "    now_rel_end_loc = 0\n",
    "    \n",
    "    rel_keyerror = False\n",
    "    \n",
    "    for now in range(len(rel_output)):\n",
    "        for loc, rel in enumerate(rel_output[now][:now+1]):\n",
    "            rel = rel.cpu().numpy()\n",
    "            \n",
    "#             print(rel, IsB, IsNext)\n",
    "            \n",
    "            # 有關係存在，且為B tag \n",
    "            if rel!=rel_tag_to_ix[REL_NONE] and IsB==False and IsNext==False:\n",
    "\n",
    "                IsB = True\n",
    "                IsNext = True\n",
    "                tag = ix_to_rel_tag[int(rel)]\n",
    "                num_reocrd+=1\n",
    "                now_loc = loc\n",
    "                \n",
    "                # 錯誤來自於，now_loc找不到，也就是說，rel預測出來是有關係存在\n",
    "                # 但預測是'O'\n",
    "                # 而在entity中卻沒有預測出來，所以r_dict中沒有紀錄\n",
    "                try:\n",
    "                    pre_rel_end_loc = r_dict[now_loc]['end']\n",
    "\n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "                try:\n",
    "                    now_rel_end_loc = r_dict[now]['end']\n",
    "                    \n",
    "                except KeyError:\n",
    "                    rel_keyerror = True\n",
    "                    break\n",
    "            \n",
    "             \n",
    "                second_tag = r_dict[now_loc]['_2ndtag']\n",
    "                preAorB = check_rel_loc(second_tag, schema)\n",
    "                nowAorB = 'B' if preAorB=='A' else 'A'\n",
    "                \n",
    "                pre_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+preAorB\n",
    "                now_complete_rel = tag+\"-\"+str(num_reocrd)+\"-\"+nowAorB\n",
    "                \n",
    "                # 將以前的token填上關係\n",
    "                for token in range(now_loc, pre_rel_end_loc+1):\n",
    "                    \n",
    "                    # 出現以下error\n",
    "                    '''AttributeError: 'str' object has no attribute 'append'''\n",
    "                    # 為 r_list 前處理中沒有給予可能有關係的位置空的list\n",
    "                    try:\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "                    except AttributeError:\n",
    "                        r_list[token] = []\n",
    "                        r_list[token].append(pre_complete_rel)\n",
    "\n",
    "             \n",
    "                # 當前token填上關係\n",
    "                r_list[now].append(now_complete_rel)\n",
    "                \n",
    "\n",
    "            \n",
    "            # 關係前位中B tag後面的tag\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsB:\n",
    "                # 如果還在這個entity的範圍內\n",
    "                if loc<=pre_rel_end_loc:\n",
    "                    pass\n",
    "                \n",
    "                # 超出現在這個entity的範圍，改lock\n",
    "                else:\n",
    "                    IsB = False\n",
    "\n",
    "            \n",
    "            # B tag後面的tag的關係，依照前面的關係複製\n",
    "            elif rel!=rel_tag_to_ix[REL_NONE] and IsNext:\n",
    "                r_list[now] = r_list[now-1]\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if now<=now_rel_end_loc:\n",
    "                    IsB = False\n",
    "                else:\n",
    "                    IsB = False\n",
    "                    IsNext = False\n",
    "\n",
    "        \n",
    "        if rel_keyerror:\n",
    "            rel_keyerror = False\n",
    "            break\n",
    "                \n",
    "                \n",
    "    return r_list, appear_error\n",
    "                \n",
    "\n",
    "# 是三元關係中的前者還是後者                  \n",
    "def check_rel_loc(second_tag, schema):\n",
    "    convert_tag = ''\n",
    "\n",
    "    for ent_content in schema['entity']:\n",
    "        if schema['entity'][ent_content]['tag']==second_tag:\n",
    "            convert_tag = ent_content\n",
    "    \n",
    "    rel_types = schema['relation'].values()\n",
    "\n",
    "    for rel_content in schema['relation'].values():\n",
    "        for AorB in rel_content['arguments']:\n",
    "            if rel_content['arguments'][AorB]==convert_tag:\n",
    "                return AorB\n",
    "            \n",
    "\n",
    "            \n",
    "def get_scores(true_lists, pred_lists, labels, output_y=False):\n",
    "    y_true, y_pred = [], []\n",
    "    for t_list, p_list in zip(true_lists, pred_lists):\n",
    "        yt, yp = align_yt_yp(t_list, p_list, labels)\n",
    "        y_true.extend(yt)\n",
    "        y_pred.extend(yp)\n",
    "        \n",
    "    scores = precision_recall_fscore_support(y_true, y_pred, average='micro', labels=labels)\n",
    "    return scores, y_true, y_pred if output_y else scores\n",
    "\n",
    "def align_yt_yp(truths, predictions, labels):\n",
    "    '''\n",
    "    Input:\n",
    "        truths/predictions: list of true and predicted tuples, \n",
    "        with the leading entries as the structure and the last entry as the class,\n",
    "        e.g., [(e1, e2, rel), ...]\n",
    "        labels: sequence of valid class\n",
    "    Output:\n",
    "        yt: list of true class given a structure\n",
    "        yp: list of predicted class given a structure\n",
    "    '''\n",
    "    yt, yp = [], []\n",
    "    _ID_NONE = len(labels)\n",
    "    true_dict = { t[:-1]: t[-1] for t in truths }\n",
    "    for p in predictions:\n",
    "        yt.append(true_dict.pop(p[:-1], _ID_NONE))\n",
    "        yp.append(p[-1])\n",
    "    for target in true_dict.values():\n",
    "        yt.append(target)\n",
    "        yp.append(_ID_NONE)\n",
    "    return yt, yp\n",
    "\n",
    "\n",
    "\n",
    "def is_neg_triple(t):\n",
    "    return np.imag(t[-1]) > 0\n",
    "\n",
    "def negate_triple(t):\n",
    "    # Mark negative triples with imaginary relation id\n",
    "    return (t[0], t[1], np.real(t[-1]).item() + 1j)\n",
    "\n",
    "def posit_triple(t):\n",
    "    return (t[0], t[1], np.real(t[-1]).item())\n",
    "\n",
    "def has_edge(base_ptrs, rel, e):\n",
    "    '''\n",
    "    Assume a relation exist between an entity pair, \n",
    "    if all the tokens in the base entity point to those in entity e.\n",
    "    '''\n",
    "    tok_has_ptr_to_e = [tok_ptrs[rel].ge(e[0]).dot(tok_ptrs[rel].le(e[1])).item() > 0 \n",
    "                        for tok_ptrs in base_ptrs]\n",
    "    return len(tok_has_ptr_to_e) > 0 and all(tok_has_ptr_to_e)\n",
    "\n",
    "\n",
    "def relation_error_analysis(true_rel_lists, rel_lists):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, r_list in enumerate(rel_lists):\n",
    "        true_pos = len([t for t in r_list if t in true_rel_lists[i]])\n",
    "        all_true = len([t for t in true_rel_lists[i] if not is_neg_triple(t)])\n",
    "        all_pos = len(r_list)\n",
    "        tp += true_pos\n",
    "        fn += all_true - true_pos\n",
    "        fp += all_pos - true_pos\n",
    "        tn += len([t for t in true_rel_lists[i] if is_neg_triple(t) and posit_triple(t) not in r_list])\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def p_r_fscore(tp, fp, tn, fn, beta=1, eps=1e-8):\n",
    "    p = tp / (tp + fp + eps)\n",
    "    r = tp / (tp + fn + eps)\n",
    "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r + eps))\n",
    "    return p, r, f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.0894\n",
      "Relation loss : 0.0049\n",
      "\n",
      "===========================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[((2, 3, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[((17, 18, 0), (29, 32, 1), 0)]\n",
      "=====================================\n",
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (35, 36, 0)]\n",
      "[((10, 14, 1), (35, 36, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[((5, 7, 1), (29, 30, 0), 0)]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[((15, 18, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((21, 22, 0), (25, 26, 1), 0), ((25, 26, 1), (32, 33, 0), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.84375, 0.9642857142857143, 0.8999999999999999, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.38461538461538464, 0.8333333333333334, 0.5263157894736842, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.3846153843195266, 0.8333333319444445, 0.5263157845983379) 5 8 0 1\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1051\n",
      "Relation loss : 0.0046\n",
      "\n",
      "===========================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(33, 35, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[((8, 12, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 9, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 9, 1), (23, 24, 0), 0), ((7, 9, 1), (36, 37, 0), 0)]\n",
      "=====================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[((25, 27, 1), (48, 49, 0), 0)]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(37, 38, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.8620689655172413, 0.8064516129032258, 0.8333333333333334, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5555555555555556, 0.5, 0.5263157894736842, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.5555555549382716, 0.49999999949999996, 0.5263157839335181) 5 4 0 5\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0026\n",
      "Relation loss : 0.0025\n",
      "\n",
      "===========================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(1.0, 1.0, 1.0, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6666666666666666, 0.6666666666666666, 0.6666666666666666, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6666666644444444, 0.6666666644444444, 0.6666666594444445) 2 1 0 1\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.871 \t\t 0.897 \t\t 0.884 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.480 \t\t 0.632 \t\t 0.545 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.480 \t\t 0.632 \t\t 0.545 \t\t    12 13 0 7\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "\n",
    "input_test, ent_test, rel_test, raw_index_test, raw_input_test = dev_preprocess(test_data)\n",
    "test_loader = dataload(input_test, ent_test, rel_test, raw_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.802 \t\t 0.941 \t\t 0.866 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.557 \t\t 0.819 \t\t 0.663 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.557 \t\t 0.819 \t\t 0.663 \t\t    118 94 0 26\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_train():\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    criterion_tag = nn.NLLLoss(ignore_index=ent_tag_to_ix[PAD_TAG])\n",
    "    criterion_rel = nn.NLLLoss()\n",
    "    \n",
    "    n_iters = 1\n",
    "    print_every = 12\n",
    "\n",
    "    train_entloss_l = []\n",
    "    val_entloss_l = []\n",
    "    train_relloss_l = []\n",
    "    val_relloss_l = []\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for epoch in tqdm(range(n_iters)):  \n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            batch_ent = batch_ent.view(batchsize*MAX_LEN)\n",
    "            batch_rel = batch_rel.view(batchsize*MAX_LEN*MAX_LEN)\n",
    "\n",
    "            entloss = criterion_tag(ent_output, batch_ent.cuda() if USE_CUDA else batch_ent)\n",
    "            relloss = criterion_rel(rel_output, batch_rel.cuda() if USE_CUDA else batch_rel)\n",
    "            loss = entloss+relloss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        train_entloss_l.append(entloss.cpu())\n",
    "        train_relloss_l.append(relloss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "\n",
    "        for step, (batch_x, batch_ent, batch_rel, batch_index) in enumerate(dev_loader):\n",
    "            model.eval()\n",
    "            ent_output, rel_output = model(batch_x.cuda() if USE_CUDA else batch_x, batch_ent.cuda() \\\n",
    "                                           if USE_CUDA else batch_ent, isTrain=True)\n",
    "\n",
    "            batchsize = batch_x.size(0)\n",
    "\n",
    "            val_entloss = criterion_tag(ent_output.cpu(), batch_ent.view(batchsize*MAX_LEN)) \n",
    "            val_relloss = criterion_rel(rel_output.cpu(), batch_rel.view(batchsize*MAX_LEN*MAX_LEN))\n",
    "\n",
    "        val_entloss_l.append(val_entloss.cpu())\n",
    "        val_relloss_l.append(val_relloss.cpu())\n",
    "\n",
    "        \n",
    "        \n",
    "        evaluate_data(loader, raw_input, isTrain=True, silent=True)\n",
    "        \n",
    "        print()\n",
    "        print(\"epoch: %d | ent loss %.4f | rel loss %.4f | total loss %.4f\" \\\n",
    "              % (epoch+1, entloss, relloss, loss))\n",
    "        print(\"      %s  | val ent loss %.4f | val rel loss %.4f\"\n",
    "              % (\" \"*len(str(epoch+1)), val_entloss, val_relloss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(dev_loader, raw_input_dev, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_data(test_loader, raw_input_test, isTrain=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity loss : 0.0640\n",
      "Relation loss : 0.0033\n",
      "\n",
      "===========================================\n",
      "['這', '次', '試', '用', '的', '是', '\"', '南', '極', '冰', '河', '醣', '蛋', '白', '滲', '透', '保', '濕', '面', '膜', '\"', '，', '對', '於', '乾', '肌', '的', '我', '來', '說', '，', '再', '適', '合', '不', '過', '了']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 25, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '覺', '得', '這', '面', '膜', '在', '這', '價', '位', '還', '可', '以', '接', '受', '，', '尤', '其', '是', '很', '會', '過', '敏', '的', '人', '來', '說', '，', '能', '使', '用', '的', '產', '品', '不', '多', '，', '保', '濕', '度', '對', '乾', '性', '肌', '的', '我', '來', '說', '也', '還', '可', '以', '，', '這', '款', '我', '覺', '得', '可', '以', '再', '回', '購']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "predict\n",
      "[(37, 39, 0), (41, 43, 1)]\n",
      "[((37, 39, 0), (41, 43, 1), 0)]\n",
      "=====================================\n",
      "['可', '視', '膚', '況', '/', '氣', '候', '選', '擇', '厚', '敷', 'o', 'r', '薄', '敷', '，', '不', '論', '是', '救', '急', '保', '養', '或', '是', '乾', '肌', '日', '常', '補', '水', '，', '保', '濕', '效', '果', '皆', '相', '當', '顯', '著', '，', '簡', '直', '宜', '家', '宜', '室', '四', '季', '皆', '宜', '齁', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "predict\n",
      "[(21, 22, 0), (25, 26, 1), (32, 33, 0)]\n",
      "[((25, 26, 1), (32, 33, 0), 0)]\n",
      "=====================================\n",
      "['有', '些', '保', '濕', '面', '膜', '，', '我', '的', '敏', '感', '性', '膚', '質', '如', '果', '敷', '太', '久', '，', '就', '會', '開', '始', '發', '癢', '，', '這', '款', '一', '直', '敷', '到', '最', '後', '都', '很', '舒', '服', '呢']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 13, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['但', '對', '皮', '膚', '乾', '癢', '保', '濕', '及', '透', '亮', '很', '有', '幫', '助', '的', '喲']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "predict\n",
      "[(2, 4, 1), (6, 7, 0)]\n",
      "[((2, 4, 1), (6, 7, 0), 0)]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['在', '這', '一', '下', '冷', '一', '下', '又', '熱', '的', '氣', '候', ',', '對', '於', '乾', '性', '肌', '膚', '的', '我', '來', '說', ',', '真', '是', '相', '當', '需', '要', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(15, 18, 1)]\n",
      "[]\n",
      "predict\n",
      "[(15, 18, 1), (30, 31, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['本', '產', '品', '適', '合', '一', '般', '膚', '質', '及', '敏', '感', '性', '膚', '質', '的', '日', '常', '保', '養', '，', '也', '很', '適', '合', '急', '救', '乾', '荒', '缺', '水', '的', '肌', '膚', '，', '保', '濕', '效', '果', '能', '立', '即', '見', '效']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(10, 14, 1), (18, 19, 0), (35, 36, 0)]\n",
      "[((10, 14, 1), (18, 19, 0), 0)]\n",
      "predict\n",
      "[(10, 14, 1), (35, 36, 0)]\n",
      "[((10, 14, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['高', '效', '保', '濕', '，', '舒', '緩', '肌', '膚', '，', '溫', '和', '修', '復', '，', '重', '塑', '晶', '透', '的', '的', '亮', '顏', '全', '效', '保', '濕', '，', '改', '善', '乾', '性', '肌', '膚', '問', '題', '，', '使', '肌', '膚', '亮', '透', '有', '光', '澤']\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 0), (5, 6, 0), (25, 26, 0), (30, 33, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '屬', '於', '油', '性', '敏', '感', '肌', '，', '用', '太', '刺', '激', '的', '保', '養', '品', '會', '有', '側', '痛', '和', '肌', '膚', '發', '紅', '的', '感', '覺']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 11, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['像', '我', '本', '身', '有', '輕', '微', '過', '敏', '膚', '質', '的', '情', '況', '，', '只', '要', '在', '悶', '熱', '的', '環', '境', '中', '肌', '膚', '就', '容', '易', '產', '生', '泛', '紅', '的', '情', '形', '，', '這', '幾', '天', '都', '靠', '蠟', '菊', '純', '露', '面', '膜', '來', '舒', '緩', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[((7, 10, 1), (49, 50, 0), 0)]\n",
      "predict\n",
      "[(7, 10, 1), (49, 50, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['露', '珠', '草', '萃', '取', '液', '晶', '華', '能', '舒', '緩', '肌', '膚', '乾', '燥', '不', '適', '並', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0), ((11, 14, 1), (20, 21, 0), 0)]\n",
      "predict\n",
      "[(9, 10, 0), (11, 14, 1), (20, 21, 0)]\n",
      "[((9, 10, 0), (11, 14, 1), 0)]\n",
      "=====================================\n",
      "['第', '三', '種', '方', '式', '是', '每', '週', '1', '-', '2', '次', '，', '夜', '間', '所', '有', '保', '養', '程', '序', '後', '，', '以', '厚', '敷', '來', '加', '強', '肌', '膚', '乾', '燥', '部', '位', '的', '照', '顧']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 32, 1)]\n",
      "[]\n",
      "predict\n",
      "[(17, 18, 0), (29, 32, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '美', '麗', '日', '記', '一', '直', '是', '我', '的', '愛', '用', '品', '之', '一', '，', '對', '於', '健', '康', '膚', '色', '油', '性', '混', '合', '肌', '的', '我', '，', '挑', '選', '面', '膜', '的', '重', '點', '就', '是', '-', '-', '-', '可', '以', '變', '白', '、', '保', '濕', '、', '不', '會', '黏', '黏', '的', '(', '很', '重', '要', ')']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-FUNC', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[]\n",
      "predict\n",
      "[(25, 27, 1), (48, 49, 0)]\n",
      "[((25, 27, 1), (48, 49, 0), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不', '過', '乾', '性', '肌', '膚', '敷', '完', '後', '可', '能', '要', '馬', '上', '擦', '點', '保', '濕', '的', '保', '養', '品', '不', '然', '皮', '膚', '會', '緊', '緊', '繃', '繃', '的', '喔']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(2, 5, 1), (16, 17, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 1, 1), (2, 5, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['本', '身', '是', '極', '乾', '的', '膚', '質', ',', '常', '需', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 7, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.875, 0.9333333333333333, 0.9032258064516129, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7142857142857143, 0.625, 0.6666666666666666, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.7142857132653061, 0.6249999992187499, 0.6666666608) 5 2 0 3\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.0879\n",
      "Relation loss : 0.0042\n",
      "\n",
      "===========================================\n",
      "['顧', '名', '思', '義', '這', '是', '一', '款', '晚', '安', '凍', '膜', '，', '乾', '肌', '我', '本', '人', '於', '晚', '上', '卸', '妝', '洗', '臉', '洗', '澡', '後', '睡', '前', '保', '養', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "predict\n",
      "[(13, 14, 1), (30, 31, 0)]\n",
      "[((13, 14, 1), (30, 31, 0), 0)]\n",
      "=====================================\n",
      "['不', '過', '每', '次', '敷', '完', '臉', ',', '保', '濕', '的', '效', '果', '非', '常', '好', ',', '因', '為', '是', '敏', '感', '膚', '質', ',', '有', '時', '候', '臉', '上', '會', '有', '過', '敏', '現', '象', ',']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[]\n",
      "predict\n",
      "[(8, 9, 0), (20, 23, 1)]\n",
      "[((8, 9, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['增', '加', '肌', '膚', '彈', '性', '及', '含', '水', '量', '，', '提', '高', '保', '濕', '效', '果', '，', '防', '止', '肌', '膚', '乾', '燥', '，', '去', '除', '細', '小', '皺', '紋', '，']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "predict\n",
      "[(13, 14, 0), (20, 23, 1)]\n",
      "[((13, 14, 0), (20, 23, 1), 0)]\n",
      "=====================================\n",
      "['保', '濕', '效', '果', '超', '優', '的', '，', '暗', '沉', '和', '乾', '燥', '肌', '也', '統', '統', 'O', 'U', 'T', '了', '，']\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "predict\n",
      "[(0, 1, 0), (11, 13, 1)]\n",
      "[((0, 1, 0), (11, 13, 1), 0)]\n",
      "=====================================\n",
      "['夏', '日', '將', '到', '了', '，', '保', '濕', '不', '是', '只', '有', '在', '冬', '天', '，', '夏', '天', '會', '常', '常', '待', '在', '冷', '氣', '房', '，', '所', '以', '保', '濕', '還', '是', '很', '重', '要', '，', '而', '這', '面', '膜', '對', '於', '乾', '燥', '的', '肌', '膚', '急', '救', '補', '水', '效', '果', '還', '挺', '讓', '人', '滿', '意', '的']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (43, 47, 1)]\n",
      "[((29, 30, 0), (43, 47, 1), 0)]\n",
      "predict\n",
      "[(43, 47, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['我', '的', '皮', '膚', '是', '乾', '性', '肌', ',', '雖', '然', '在', '夏', '天', '不', '會', '乾', '到', '緊', '繃', ',', '但', '每', '天', '還', '是', '要', '加', '強', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(5, 7, 1)]\n",
      "[]\n",
      "predict\n",
      "[(5, 7, 1), (29, 30, 0)]\n",
      "[]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['當', '天', '擦', '就', '馬', '上', '覺', '得', '皮', '膚', '乾', '燥', '感', '得', '到', '舒', '緩']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(8, 11, 1), (15, 16, 0)]\n",
      "[((8, 11, 1), (15, 16, 0), 0)]\n",
      "predict\n",
      "[(8, 12, 1), (15, 16, 0)]\n",
      "[((8, 12, 1), (15, 16, 0), 0)]\n",
      "=====================================\n",
      "['溫', '柔', '而', '堅', '定', '的', '修', '護', '力', 'Z', 'e', 'p', 'h', 'y', 'r', 'i', 'n', 'e', '數', '字', '保', '養', ',', '非', '常', '溫', '和', '的', '產', '品', '即', '使', '是', '敏', '感', '肌', '也', '可', '以', '輕', '鬆', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(20, 21, 0), (33, 35, 1)]\n",
      "[((20, 21, 0), (33, 35, 1), 0)]\n",
      "predict\n",
      "[(33, 35, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['以', '前', '我', '有', '敷', '過', '別', '款', '的', '美', '白', '面', '膜', '~', '很', '容', '易', '就', '會', '讓', '我', '的', '臉', '部', '肌', '膚', '過', '敏', '，', '會', '有', '紅', '紅', '的', '臉', '出', '現']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "predict\n",
      "[(24, 27, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['“', '酵', '母', '萃', '取', '”', '搭', '配', '“', '小', '分', '子', '玻', '尿', '酸', '”', '及', '“', '牛', '奶', '蛋', '白', '”', '使', '乾', '燥', '肌', '膚', '充', '滿', '水', '分', '，', '長', '效', '保', '濕']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "predict\n",
      "[(24, 27, 1), (35, 36, 0)]\n",
      "[((24, 27, 1), (35, 36, 0), 0)]\n",
      "=====================================\n",
      "['使', '用', '完', '後', '肌', '膚', '乾', '淨', '舒', '服', ',', '休', '息', '一', '下', '後', '就', '可', '以', '上', '平', '日', '保', '養', '步', '驟', '~']\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "predict\n",
      "[(4, 6, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['皮', '珂', '兒', '是', '韓', '國', '製', '造', '的', '保', '養', '品', '，', '有', '可', '愛', '的', '火', '山', '插', '圖', '，', '鐵', '罐', '包', '裝', '，', '是', '很', '特', '殊', '的', '慕', '絲', '質', '地', '，', '需', '沖', '洗', '的', '清', '潔', '面', '膜', '，', '很', '適', '合', '油', '性', '肌', '膚', '來', '使', '用']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], '', '', '']\n",
      "\n",
      "True\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "predict\n",
      "[(49, 52, 1)]\n",
      "[]\n",
      "=====================================\n",
      "['適', '用', '族', '群', '為', '乾', '燥', '肌', '、', '缺', '水', '保', '濕', '、', '2', '5', '歲', '以', '上', '肌', '膚']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "predict\n",
      "[(5, 7, 1), (11, 12, 0)]\n",
      "[((5, 7, 1), (11, 12, 0), 0)]\n",
      "=====================================\n",
      "['溫', '和', '的', '成', '份', '讓', '敏', '感', '的', '肌', '膚', '也', '能', '輕', '鬆', '的', '美', '白']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A']]\n",
      "\n",
      "True\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "predict\n",
      "[(6, 10, 1), (16, 17, 0)]\n",
      "[((6, 10, 1), (16, 17, 0), 0)]\n",
      "=====================================\n",
      "['看', '品', '名', '就', '知', '道', '是', '首', '重', '保', '濕', '效', '果', '的', '面', '膜', ',', '對', '於', '我', '這', '缺', '水', '易', '出', '油', '的', '肌', '膚', ',', '當', '然', '是', '迫', '不', '及', '待', '地', '使', '用', '啦', '~']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], [], [], [], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[]\n",
      "predict\n",
      "[(9, 10, 0), (24, 28, 1)]\n",
      "[((9, 10, 0), (24, 28, 1), 0)]\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['使', '用', '了', '幾', '次', '，', '效', '果', '都', '不', '太', '令', '人', '滿', '意', '，', '也', '許', '是', '這', '款', '面', '膜', '主', '要', '強', '調', '的', '是', '緊', '緻', '功', '能', '，', '我', '的', '超', '乾', '肌', '得', '先', '把', '缺', '水', '問', '題', '解', '決', '了', '才', '能', '看', '出', '效', '果', '吧', '∼']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(29, 30, 0), (37, 38, 1)]\n",
      "[]\n",
      "predict\n",
      "[(37, 38, 1)]\n",
      "[]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.9230769230769231, 0.8571428571428571, 0.888888888888889, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6666666666666666, 0.6666666666666666, 0.6666666666666666, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.6666666659259258, 0.6666666659259258, 0.666666660925926) 6 3 0 3\n",
      "===========================================\n",
      "\n",
      "Entity loss : 0.1483\n",
      "Relation loss : 0.0041\n",
      "\n",
      "===========================================\n",
      "['很', '適', '合', '油', '性', '膚', '質', '使', '用', '，', '但', '對', '於', '乾', '性', '肌', '膚', '就', '要', '加', '強', '後', '續', '的', '保', '濕']\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC']\n",
      "['', '', '', [], [], [], [], '', '', '', '', '', '', [], [], [], [], '', '', '', '', '', '', '', [], []]\n",
      "\n",
      "True\n",
      "[(3, 6, 1), (13, 16, 1)]\n",
      "[]\n",
      "predict\n",
      "[(3, 6, 1), (13, 16, 1), (24, 25, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['這', '款', '面', '膜', '它', '強', '調', '乾', '肌', '及', '肌', '膚', '鬆', '弛', '.', '.', '.', '等', ',', '但', '我', '發', '現', '緊', '緻', '的', '部', '份', '不', '是', '那', '麼', '明', '顯', ',', '但', '保', '濕', '部', '分', '我', '倒', '是', '很']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], ['ApplyTo-0-B', 'ApplyTo-1-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-1-A'], ['ApplyTo-1-A'], '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(7, 8, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 8, 1), (36, 37, 0), 0)]\n",
      "predict\n",
      "[(7, 9, 1), (23, 24, 0), (36, 37, 0)]\n",
      "[((7, 9, 1), (23, 24, 0), 0), ((7, 9, 1), (36, 37, 0), 0)]\n",
      "=====================================\n",
      "['補', '充', '說', '明', ',', '因', '為', '我', '本', '身', '肌', '膚', '屬', '於', '敏', '感', '性', '肌', '膚', ',', '用', '此', '款', '面', '膜', '不', '會', '過', '敏', '喔', '~', '~', '而', '且', '保', '濕', '效', '果', '很', '強', '喔', '~', '^', '^']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '', '', '', '', '', '', '']\n",
      "\n",
      "True\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "predict\n",
      "[(14, 18, 1), (34, 35, 0)]\n",
      "[((14, 18, 1), (34, 35, 0), 0)]\n",
      "=====================================\n",
      "['建', '議', '乾', '肌', '的', '朋', '友', '們', '還', '是', '要', '勤', '做', '後', '續', '的', '保', '養', '動', '作']\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', '', [], [], '', '', '', '', '', '', '', '', '', '', '', '', [], [], '', '']\n",
      "\n",
      "True\n",
      "[(2, 3, 1)]\n",
      "[]\n",
      "predict\n",
      "[(2, 3, 1), (16, 17, 0)]\n",
      "[]\n",
      "=====================================\n",
      "['若', '乾', '性', '肌', '膚', '使', '用', '會', '保', '濕', '度', '不', '足']\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', [], [], [], [], '', '', '', [], [], [], '', '']\n",
      "\n",
      "Predict output\n",
      "['O', 'B-STAT', 'I-STAT', 'I-STAT', 'I-STAT', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'O', 'O']\n",
      "['', ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], ['ApplyTo-0-B'], '', '', '', ['ApplyTo-0-A'], ['ApplyTo-0-A'], ['ApplyTo-0-A'], '', '']\n",
      "\n",
      "True\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[]\n",
      "predict\n",
      "[(1, 4, 1), (8, 10, 0)]\n",
      "[((1, 4, 1), (8, 10, 0), 0)]\n",
      "=====================================\n",
      "Batch entity score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.75, 0.9, 0.8181818181818182, None)\n",
      "\n",
      "Batch relation score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.25, 0.5, 0.3333333333333333, None)\n",
      "\n",
      "p_r_fscore\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "(0.249999999375, 0.4999999975, 0.33333332777777785) 1 3 0 1\n",
      "===========================================\n",
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.871 \t\t 0.897 \t\t 0.884 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.600 \t\t 0.632 \t\t 0.615 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.600 \t\t 0.632 \t\t 0.615 \t\t    12 8 0 7\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(dev_loader, raw_input_dev, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entity detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.805 \t\t 0.945 \t\t 0.869 \t\n",
      "\n",
      "Relation detection score\n",
      "precision  \t recall  \t fbeta_score  \t\n",
      "0.702 \t\t 0.825 \t\t 0.759 \t\n",
      "\n",
      "ReferenceEntity+Relation score\n",
      "precision  \t recall  \t fbeta_score  \t    tp fp tn fn\n",
      "0.702 \t\t 0.825 \t\t 0.759 \t\t    118 50 0 25\n"
     ]
    }
   ],
   "source": [
    "evaluate_data(test_loader, raw_input_test, isTrain=False, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 37, 297)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_var), len(input_dev), len(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
