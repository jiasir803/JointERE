{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "tag_to_ix = {START_TAG: 0, STOP_TAG: 1, PAD_TAG:2, \"B-Func\": 3, \"I-Func\": 4, \"O\": 5}\n",
    "\n",
    "tagset_size = len(tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_list.append(word_set[0])\n",
    "        tag_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, tag_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "\n",
    "    for i, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, tags = get_word_and_label(content, init, i)\n",
    "            init = i+1\n",
    "            word_list.append(words)\n",
    "            tag_list.append(tags)\n",
    "            \n",
    "    return word_list, tag_list\n",
    "    \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "    \n",
    "#     if USE_CUDA:\n",
    "#         seq_list = seq_list.cuda()\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<START>\":0, \"<STOP>\":1, \"<PAD>\":2}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, tag_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_tag = list(tag_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_tag\n",
    "\n",
    "def pad_seq(seq):\n",
    "    seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_tag):\n",
    "    input_padded = [pad_seq(s) for s in filter_word]\n",
    "    target_padded = [pad_seq(s) for s in filter_tag]\n",
    "    \n",
    "    return input_padded, target_padded\n",
    "\n",
    "#======================================\n",
    "def dataload(input_var, target_var):\n",
    "    torch_dataset = Data.TensorDataset(input_var, target_var)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=2,              \n",
    "    )\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = readfile(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, tag_list = split_to_list(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = word2index(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "         15,  16,  17,  18,  19,   3,   4,   5,   6,  20,   3,  21,\n",
       "         22,  23,  24,  25,  26,  27,  28,   7,  29])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sequence(word_list[0], word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = find_max_len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved_index = filter_len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word, filter_tag = filter_sentence(reserved_index, word_list, tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_padded, target_padded = pad_all(filter_word, filter_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataload(input_var, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  161,   162,   165,  ...,     2,     2,     2],\n",
      "        [   15,   114,    21,  ...,     2,     2,     2],\n",
      "        [  203,   165,   559,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [  301,     9,    22,  ...,     2,     2,     2],\n",
      "        [  301,     9,   633,  ...,     2,     2,     2],\n",
      "        [    5,    35,   203,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[  116,   116,    15,  ...,     2,     2,     2],\n",
      "        [    5,    35,   203,  ...,     2,     2,     2],\n",
      "        [  727,    62,    49,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [   13,    14,    45,  ...,     2,     2,     2],\n",
      "        [  161,    56,    23,  ...,     2,     2,     2],\n",
      "        [   12,   259,     4,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[  406,   232,   373,  ...,     2,     2,     2],\n",
      "        [  281,   161,   162,  ...,     2,     2,     2],\n",
      "        [   43,   135,   282,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [  244,   259,   165,  ...,     2,     2,     2],\n",
      "        [  130,    21,   270,  ...,     2,     2,     2],\n",
      "        [    5,     6,   174,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[   81,    82,   128,  ...,     2,     2,     2],\n",
      "        [  468,   429,    13,  ...,     2,     2,     2],\n",
      "        [  244,   259,    56,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [   23,    43,     7,  ...,     2,     2,     2],\n",
      "        [  663,   514,   116,  ...,     2,     2,     2],\n",
      "        [   51,    13,    14,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[ 1512,    30,   289,  ...,     2,     2,     2],\n",
      "        [   15,   114,   325,  ...,     2,     2,     2],\n",
      "        [  270,   271,     7,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [   21,   421,   333,  ...,     2,     2,     2],\n",
      "        [  286,   287,   684,  ...,     2,     2,     2],\n",
      "        [   15,   163,    22,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[  161,   162,    49,  ...,     2,     2,     2],\n",
      "        [   66,    67,    35,  ...,     2,     2,     2],\n",
      "        [  400,    68,   121,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [   13,    14,    22,  ...,     2,     2,     2],\n",
      "        [   39,    56,    15,  ...,     2,     2,     2],\n",
      "        [  245,    36,    37,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[   33,   342,   219,  ...,     2,     2,     2],\n",
      "        [  130,    21,   161,  ...,     2,     2,     2],\n",
      "        [   13,    14,     8,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [  490,   413,    20,  ...,     2,     2,     2],\n",
      "        [  882,   799,   187,  ...,     2,     2,     2],\n",
      "        [   43,     7,    36,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[   15,   114,   325,  ...,     2,     2,     2],\n",
      "        [  215,   259,    14,  ...,     2,     2,     2],\n",
      "        [   13,    14,     7,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [    5,    35,   203,  ...,     2,     2,     2],\n",
      "        [  161,   162,    64,  ...,     2,     2,     2],\n",
      "        [   35,    36,   121,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[  644,   645,   392,  ...,     2,     2,     2],\n",
      "        [    3,     4,   120,  ...,     2,     2,     2],\n",
      "        [   73,   584,   668,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [    5,     6,     7,  ...,     2,     2,     2],\n",
      "        [  269,     8,   104,  ...,     2,     2,     2],\n",
      "        [  333,    22,    23,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n",
      "tensor([[  389,    26,   676,  ...,     2,     2,     2],\n",
      "        [   43,   851,   178,  ...,     2,     2,     2],\n",
      "        [  108,   109,   466,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [  121,   514,    67,  ...,     2,     2,     2],\n",
      "        [  406,   407,    35,  ...,     2,     2,     2],\n",
      "        [   20,   322,   323,  ...,     2,     2,     2]])\n",
      "torch.Size([128, 100])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        print(batch_x)\n",
    "        print(batch_x.size())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
