{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/notebooks/sinica/dataset/'\n",
    "train_data = root+'facial.train'\n",
    "dev_data = root+'facial.dev'\n",
    "test_data = root+'facial.test'\n",
    "\n",
    "UNKOWN_TAG = \"<UNKNOWN>\"\n",
    "PAD_TAG = \"<PAD>\"\n",
    "tag_to_ix = {UNKOWN_TAG: 0, PAD_TAG:1, \"B-Func\": 2, \"I-Func\": 3, \"O\": 4}\n",
    "\n",
    "tagset_size = len(tag_to_ix)\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "EMBEDDING_DIM = 20\n",
    "HIDDEN_DIM1 = 10\n",
    "HIDDEN_DIM2 = 8\n",
    "LABEL_EMBED_DIM = 3\n",
    "DENSE_OUT = 100\n",
    "\n",
    "ATTN_IN = tagset_size+LABEL_EMBED_DIM\n",
    "ATTN_OUT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(data):\n",
    "    with open(data, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "        \n",
    "    return content\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def get_word_and_label(_content, start_w, end_w):\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for word_set in _content[start_w:end_w]:\n",
    "        word_list.append(word_set[0])\n",
    "        tag_list.append(word_set[2:])\n",
    "    \n",
    "    return word_list, tag_list\n",
    "\n",
    "def split_to_list(content):\n",
    "    init = 0\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "\n",
    "    for i, c in enumerate(content):\n",
    "        if c=='':\n",
    "            words, tags = get_word_and_label(content, init, i)\n",
    "            init = i+1\n",
    "            word_list.append(words)\n",
    "            tag_list.append(tags)\n",
    "            \n",
    "    return word_list, tag_list\n",
    "\n",
    "# ==================================================\n",
    "    \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            idxs.append(to_ix[UNKOWN_TAG])\n",
    "        else:\n",
    "            idxs.append(to_ix[w])\n",
    "    \n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all(seqs, to_ix):\n",
    "    seq_list = []\n",
    "    for i in range(len(seqs)):\n",
    "        seq_list.append(prepare_sequence(seqs[i], to_ix))\n",
    "        \n",
    "    seq_list = torch.stack(seq_list)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def word2index(word_list):\n",
    "    word_to_ix = {\"<UNKNOWN>\":0, \"<PAD>\":1}\n",
    "    for sentence in word_list:\n",
    "        for word in sentence:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                \n",
    "    return word_to_ix\n",
    "\n",
    "def dict_inverse(tag_to_ix):\n",
    "    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
    "    return ix_to_tag\n",
    "\n",
    "def index2tag(indexs, ix_to):\n",
    "    to_tags = [ix_to[i] for i in indexs.cpu().numpy()]\n",
    "    return to_tags\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def find_max_len(word_list):\n",
    "    max_len = 0\n",
    "    for i in range(len(word_list)):\n",
    "        if max_len<len(word_list[i]):\n",
    "            max_len=len(word_list[i])\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "# ====== filter the length of sentence more than MAX_LEN =======\n",
    "\n",
    "def filter_len(word_list):\n",
    "    reserved_index = []\n",
    "    for i in range(len(word_list)):\n",
    "        if len(word_list[i])<MAX_LEN:\n",
    "            reserved_index.append(i)\n",
    "            \n",
    "    return reserved_index\n",
    "\n",
    "\n",
    "def filter_sentence(reserved_index, word_list, tag_list):\n",
    "    filter_word = list(word_list[i] for i in reserved_index)\n",
    "    filter_tag = list(tag_list[i] for i in reserved_index)\n",
    "    return filter_word, filter_tag\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "def pad_seq(seq):\n",
    "    seq += [PAD_TAG for i in range(MAX_LEN-len(seq))]\n",
    "    return seq\n",
    "\n",
    "def pad_all(filter_word, filter_tag):\n",
    "    input_padded = [pad_seq(s) for s in filter_word]\n",
    "    target_padded = [pad_seq(s) for s in filter_tag]\n",
    "    \n",
    "    return input_padded, target_padded\n",
    "\n",
    "# ==================================================\n",
    "def dataload(input_var, target_var):\n",
    "    torch_dataset = Data.TensorDataset(input_var, target_var)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               \n",
    "        num_workers=2,       \n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# ==================================================\n",
    "def softmax_output(output):\n",
    "    output = output.view(BATCH_SIZE,tagset_size).argmax(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, attn_input, attn_output):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.attn_input = attn_input\n",
    "        self.attn_output = attn_output\n",
    "        \n",
    "        self.w1 = nn.Linear(self.attn_input, attn_output)\n",
    "        self.w2 = nn.Linear(self.attn_input, attn_output)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Parameter(torch.FloatTensor(1, attn_output))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        this_batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[b, :], encoder_outputs[b, i].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "\n",
    "#         energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "        e1 = self.w1(encoder_output)\n",
    "        e2 = self.w2(hidden)\n",
    "        energy = self.tanh(e1+e2)\n",
    "        energy = self.v.dot(energy)\n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Typing(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim1, hidden_dim2, \\\n",
    "                 label_embed_dim):\n",
    "        super(Entity_Typing, self).__init__()\n",
    "        self.embedding_dim = embedding_dim                   #E\n",
    "        self.hidden_dim1 = hidden_dim1                       #h1\n",
    "        self.hidden_dim2 = hidden_dim2                       #h2\n",
    "        self.label_embed_dim = label_embed_dim               #LE\n",
    "        self.vocab_size = vocab_size                         #vs\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)                    #ts\n",
    "        \n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim1 // 2,\n",
    "                            num_layers=2, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim1, DENSE_OUT)\n",
    "        \n",
    "        self.top_hidden = nn.LSTMCell(DENSE_OUT+label_embed_dim, hidden_dim2)          \n",
    "        \n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim2, self.tagset_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.label_embed = nn.Linear(self.tagset_size, self.label_embed_dim)\n",
    "        \n",
    "#         self.hidden1 = self.init_hidden1()\n",
    "#         self.hidden2 = self.init_hidden2()\n",
    "#         self.to_label_embed = self.init_label_embed()\n",
    "        \n",
    "        \n",
    "    def init_hidden1(self):       \n",
    "        hidden = torch.randn(2*2, BATCH_SIZE, self.hidden_dim1 // 2)    #4*B*(h1/2)\n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_hidden2(self):       \n",
    "        hidden = torch.randn(BATCH_SIZE, self.hidden_dim2)              #B*h2\n",
    "#         hidden = Variable(hidden.data, requires_grad=True)\n",
    "\n",
    "        return (hidden.cuda(), hidden.cuda())if USE_CUDA else (hidden,hidden)\n",
    "    \n",
    "    def init_label_embed(self):\n",
    "        hidden = torch.zeros(BATCH_SIZE, self.label_embed_dim)          #B*LE\n",
    "        return hidden.cuda()if USE_CUDA else hidden\n",
    "    \n",
    "    def create_output(self):\n",
    "        output_tensor = torch.zeros(BATCH_SIZE, MAX_LEN, self.tagset_size)  #B*ML*ts\n",
    "        return output_tensor.cuda()if USE_CUDA else output_tensor\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        self.hidden1 = self.init_hidden1()                      #4*B*(h1/2)\n",
    "        output_tensor = self.create_output()                    #B*ML*ts\n",
    "        \n",
    "        embeds = self.word_embeds(sentence)                     #B*ML*E,[128, 100, 20]\n",
    "        \n",
    "        bilstm_out, self.hidden1 = self.bilstm(embeds, self.hidden1)\n",
    "        # bilstm_out -> B*ML*h1,[128, 100, 10]\n",
    "        # self.hidden1 -> ( 4*B*(h1/2), 4*B*(h1/2) )\n",
    "        \n",
    "        dense_out = self.dense(bilstm_out)                      #B*ML*DENSE_OUT,[128, 100, 100]\n",
    "        \n",
    "        \n",
    "        encoder_sequence = []\n",
    "        decoder_sequence = [] \n",
    "        \n",
    "\n",
    "        for length in range(MAX_LEN):\n",
    "            now_token = dense_out[:,length,:]\n",
    "            now_token = torch.squeeze(now_token, 1)\n",
    "            if length==0:\n",
    "                \n",
    "#                 fake_hidden=(100)\n",
    "#                 noise_x = random(100)\n",
    "                self.hidden2 = self.init_hidden2()\n",
    "                self.zero_label_embed = self.init_label_embed()\n",
    "                combine_x = torch.cat((now_token, self.zero_label_embed),1)  #B*(DENSE_OUT+LE),[128, 103]\n",
    "                \n",
    "            else:\n",
    "#                 fake_hidden=h\n",
    "                self.hidden2 = (h_next, c_next)\n",
    "                combine_x = torch.cat((now_token, label),1)\n",
    "\n",
    "            h_next, c_next = self.top_hidden(combine_x, self.hidden2)    #B*h2,[128, 8]           \n",
    "            to_tags = self.hidden2tag(h_next)                            #B*ts,[128, 5]            \n",
    "            output = self.softmax(to_tags)                               #B*ts,[128, 5]             \n",
    "            label = self.label_embed(output)                             #B*LE,[128, 3]\n",
    "            \n",
    "            s_output = softmax_output(output)            \n",
    "            encoder_sequence.append(torch.cat((to_tags,label),1))\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "            output_tensor[:,length,:] = output\n",
    "        \n",
    "        encoder_sequence = torch.stack(encoder_sequence).t()\n",
    "        print(encoder_sequence)\n",
    "        \n",
    "        '''NLLLoss input: Input: (N,C) where C = number of classes'''\n",
    "        return output_tensor.view(BATCH_SIZE*MAX_LEN, self.tagset_size), encoder_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relation_Extraction(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Relation_Extraction, self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_tag = dict_inverse(tag_to_ix)\n",
    "#===============================================\n",
    "content = readfile(train_data)\n",
    "word_list, tag_list = split_to_list(content)\n",
    "word_to_ix = word2index(word_list)\n",
    "reserved_index = filter_len(word_list)\n",
    "filter_word, filter_tag = filter_sentence(reserved_index, word_list, tag_list)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "#================================================\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)\n",
    "#================================================\n",
    "vocab_size = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dataload(input_var, target_var)\n",
    "entity_typing = Entity_Typing(vocab_size, tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, \\\n",
    "              LABEL_EMBED_DIM).cuda()\n",
    "optimizer = optim.Adam(entity_typing.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0612,  0.2233, -0.1513,  ...,  2.1325,  1.3992,  0.1936],\n",
      "         [ 0.0283,  0.2599, -0.1621,  ...,  2.1024,  1.3439,  0.2751],\n",
      "         [ 0.0824,  0.2982, -0.1771,  ...,  2.0918,  1.3375,  0.3075],\n",
      "         ...,\n",
      "         [ 0.1286,  0.3304, -0.2004,  ...,  2.0813,  1.3260,  0.3491],\n",
      "         [ 0.1259,  0.3323, -0.1996,  ...,  2.0818,  1.3276,  0.3485],\n",
      "         [ 0.1168,  0.3300, -0.2037,  ...,  2.0828,  1.3307,  0.3470]],\n",
      "\n",
      "        [[-0.2803, -0.0597, -0.4952,  ...,  2.1489,  1.3499,  0.3479],\n",
      "         [-0.1928,  0.0049, -0.4168,  ...,  2.1209,  1.3198,  0.3502],\n",
      "         [-0.0538,  0.0930, -0.3594,  ...,  2.0937,  1.3121,  0.3409],\n",
      "         ...,\n",
      "         [ 0.1328,  0.3395, -0.1855,  ...,  2.0811,  1.3203,  0.3535],\n",
      "         [ 0.1342,  0.3463, -0.1762,  ...,  2.0812,  1.3174,  0.3568],\n",
      "         [ 0.1304,  0.3507, -0.1684,  ...,  2.0815,  1.3136,  0.3619]],\n",
      "\n",
      "        [[-0.1545,  0.0364, -0.4031,  ...,  2.1116,  1.3691,  0.2737],\n",
      "         [-0.0633,  0.0981, -0.3736,  ...,  2.0971,  1.3466,  0.3064],\n",
      "         [ 0.0104,  0.1751, -0.3180,  ...,  2.0888,  1.3384,  0.3191],\n",
      "         ...,\n",
      "         [ 0.1182,  0.3103, -0.2162,  ...,  2.0807,  1.3233,  0.3498],\n",
      "         [ 0.1151,  0.3000, -0.2264,  ...,  2.0803,  1.3234,  0.3487],\n",
      "         [ 0.1088,  0.2806, -0.2465,  ...,  2.0800,  1.3255,  0.3450]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1716,  0.0758, -0.4768,  ...,  2.1553,  1.5424,  0.1301],\n",
      "         [-0.0905,  0.0540, -0.4344,  ...,  2.1079,  1.3979,  0.2484],\n",
      "         [-0.0055,  0.1380, -0.3541,  ...,  2.0923,  1.3554,  0.2943],\n",
      "         ...,\n",
      "         [ 0.1112,  0.3074, -0.2228,  ...,  2.0814,  1.3271,  0.3484],\n",
      "         [ 0.1028,  0.2964, -0.2338,  ...,  2.0815,  1.3275,  0.3481],\n",
      "         [ 0.0931,  0.2817, -0.2469,  ...,  2.0813,  1.3266,  0.3482]],\n",
      "\n",
      "        [[-0.2660, -0.1940, -0.4968,  ...,  2.1204,  1.3315,  0.2375],\n",
      "         [-0.1919, -0.1386, -0.5099,  ...,  2.1092,  1.3138,  0.2951],\n",
      "         [-0.0975, -0.0072, -0.4294,  ...,  2.0962,  1.3134,  0.3162],\n",
      "         ...,\n",
      "         [ 0.1146,  0.3097, -0.2182,  ...,  2.0811,  1.3246,  0.3499],\n",
      "         [ 0.1083,  0.2988, -0.2276,  ...,  2.0808,  1.3234,  0.3507],\n",
      "         [ 0.1016,  0.2834, -0.2374,  ...,  2.0801,  1.3187,  0.3531]],\n",
      "\n",
      "        [[-0.1311,  0.1495, -0.2814,  ...,  2.2082,  1.5911,  0.0018],\n",
      "         [-0.0386,  0.1170, -0.2059,  ...,  2.1492,  1.4130,  0.1228],\n",
      "         [ 0.0121,  0.1391, -0.1968,  ...,  2.1184,  1.3507,  0.1973],\n",
      "         ...,\n",
      "         [ 0.1274,  0.3254, -0.2082,  ...,  2.0814,  1.3287,  0.3472],\n",
      "         [ 0.1252,  0.3254, -0.2096,  ...,  2.0817,  1.3300,  0.3471],\n",
      "         [ 0.1210,  0.3223, -0.2113,  ...,  2.0817,  1.3289,  0.3484]]], device='cuda:0')\n",
      "epoch: 0 | loss 1.3913\n"
     ]
    }
   ],
   "source": [
    "n_iters = 10\n",
    "print_every = 12\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in tqdm(range(10)):  \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        output, ee = entity_typing(batch_x.cuda() if USE_CUDA else batch_x)\n",
    "        batch_y = batch_y.view(BATCH_SIZE*MAX_LEN)\n",
    "        loss = criterion(output, batch_y.cuda() if USE_CUDA else batch_y)\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        break\n",
    "\n",
    "        \n",
    "        if step % print_every == 1:\n",
    "            all_losses.append(loss.cpu())\n",
    "        #    print('%.4f| epoch: %d| step: %d| %s' % (loss, epoch, step, timeSince(start)))\n",
    "    print(\"epoch: %d | loss %.4f\" % (epoch,loss))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100, 8])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_losses[:100])\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one input\n",
    "def easy_pad(easy_sent, easy_tar):\n",
    "    easy_sent += [PAD_TAG for i in range(MAX_LEN-len(easy_sent))]\n",
    "    easy_tar += [PAD_TAG for i in range(MAX_LEN-len(easy_tar))]\n",
    "    \n",
    "    return easy_sent, easy_tar\n",
    "\n",
    "def easy_test(_input):\n",
    "    _input = torch.unsqueeze(_input, 0).expand(128,100)\n",
    "    return _input\n",
    "\n",
    "def easy_output(output):\n",
    "    output = output.view(128,100,5)[0].argmax(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = readfile(test_data)\n",
    "word_list_test, tag_list_test = split_to_list(test_content)\n",
    "\n",
    "#===================================\n",
    "easy_sent, easy_tar = easy_pad(word_list_test[3],tag_list_test[3])\n",
    "input_test = prepare_sequence(easy_sent, word_to_ix)\n",
    "# input_test = prepare_sequence(t_sentence, word_to_ix)\n",
    "\n",
    "target_test = prepare_sequence(easy_tar, tag_to_ix)\n",
    "\n",
    "_input = easy_test(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  3,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = entity_typing(_input.cuda() if USE_CUDA else _input)\n",
    "    output = easy_output(output)\n",
    "    \n",
    "    print('predict :', output)\n",
    "    print('true :', target_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence__(seq, to_ix):\n",
    "    gg = []\n",
    "    \n",
    "    for w in seq:\n",
    "        if w not in to_ix:\n",
    "            return seq\n",
    "\n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "#     return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_all__(seqs, to_ix):\n",
    "    get_index = []\n",
    "    notinseq = []\n",
    "    for i in range(len(seqs)):\n",
    "        a = prepare_sequence__(seqs[i], to_ix)\n",
    "        if a != None:\n",
    "            notinseq.append( a)\n",
    "            get_index.append(i)\n",
    "#         seq_list.append(prepare_sequence__(seqs[i], to_ix))\n",
    "        \n",
    "#     notinseq = torch.stack(notinseq)\n",
    "        \n",
    "    return notinseq, get_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch input\n",
    "reserved_index_test = filter_len(word_list_test[:143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reserved_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word, filter_tag = filter_sentence(reserved_index_test, word_list_test, tag_list_test)\n",
    "input_padded, target_padded = pad_all(filter_word, filter_tag)\n",
    "input_var = prepare_all(input_padded, word_to_ix)\n",
    "target_var = prepare_all(target_padded, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_output(output):\n",
    "    output = output.view(BATCH_SIZE,MAX_LEN,tagset_size).argmax(2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  2,  3,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='cuda:0')\n",
      "true : tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1])\n",
      "\n",
      "predict : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Func', 'I-Func', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "true : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "Loss : 0.0151\n"
     ]
    }
   ],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    output = entity_typing(input_var.cuda() if USE_CUDA else _input)\n",
    "    \n",
    "    loss = criterion(output.cpu(), target_var.view(128*100))\n",
    "    output = total_output(output)\n",
    "    \n",
    "    print('predict :', output[37])\n",
    "    print('true :', target_var[37])\n",
    "    print()\n",
    "    print('predict :', index2tag(output[37], ix_to_tag))\n",
    "    print('true :', index2tag(target_var[37], ix_to_tag))\n",
    "    print()\n",
    "    \n",
    "    print(\"Loss : %.4f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.Tensor([0] * 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1ac12e211e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'cat'"
     ]
    }
   ],
   "source": [
    "encoder_sequence = Variable(torch.zeros([10, 1]))\n",
    "encoder_sequence[1].cat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = list(a)\n",
    "torch.stack(g,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
